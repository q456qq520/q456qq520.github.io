<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKECAT</title>
    <updated>2025-05-11T03:14:48.244Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2025, LIKECAT</rights>
    <entry>
        <title type="html"><![CDATA[Redis 分布式锁如何自动续期？]]></title>
        <id>https://q456qq520.github.io/post/redis-fen-bu-shi-suo-ru-he-zi-dong-xu-qi/</id>
        <link href="https://q456qq520.github.io/post/redis-fen-bu-shi-suo-ru-he-zi-dong-xu-qi/">
        </link>
        <updated>2025-05-10T15:38:03.000Z</updated>
        <content type="html"><![CDATA[<h2 id="redis-实现分布式锁">Redis 实现分布式锁</h2>
<ol>
<li>指定一个 key 作为锁标记，存入 Redis 中，指定一个 唯一的用户标识作为 value。</li>
<li>当 key 不存在时才能设置值，确保同一时间只有一个客户端进程获得锁，满足互斥性特性。</li>
<li>设置一个过期时间，防止因系统异常导致没能删除这个 key，满足防死锁特性。</li>
<li>当处理完业务之后需要清除这个 key 来释放锁，清除 key 时需要校验 value 值，需要满足只有加锁的人才能释放锁 。</li>
</ol>
<h2 id="存在问题">存在问题</h2>
<p>如果这个锁的过期时间是30秒，但是业务运行超过了30秒，比如40秒，当业务运行到30秒的时候，锁过期了，其他客户端拿到了这个锁，怎么办<br>
我们可以设置一个合理的过期时间，让业务能够在这个时间内完成业务逻辑，但LockTime的设置原本就很不容易。</p>
<pre><code>LockTime设置过小，锁自动超时的概率就会增加，锁异常失效的概率也就会增加；
LockTime设置过大，万一服务出现异常无法正常释放锁，那么出现这种异常锁的时间也就越长。
</code></pre>
<p>我们只能通过经验去配置，一个可以接受的值，基本上是这个服务历史上的平均耗时再增加一定的buff。总体来说，设置一个合理的过期时间并不容易<br>
我们也可以不设置过期时间，让业务运行结束后解锁，但是如果客户端出现了异常结束了或宕机了，那么这个锁就无法解锁，变成死锁；</p>
<h2 id="自动续期">自动续期</h2>
<p>我们可以先给锁设置一个LockTime，然后启动一个守护线程，让守护线程在一段时间后，重新去设置这个锁的LockTime。</p>
<ol>
<li>和释放锁的情况一样，我们需要先判断持有锁客户端是否有变化。否则会造成无论谁持有锁，守护线程都会去重新设置锁的LockTime。</li>
<li>守护线程要在合理的时间再去重新设置锁的LockTime，否则会造成资源的浪费。不能动不动就去续。</li>
<li>如果持有锁的线程已经处理完业务了，那么守护线程也应该被销毁。不能业务运行结束了，守护者还在那里继续运行，浪费资源。</li>
</ol>
<h2 id="redisson的看门狗机制">Redisson的看门狗机制</h2>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1746891777926.jpg" alt="" loading="lazy"></figure>
<p>Redisson 锁的加锁机制如上图所示，线程去获取锁，获取成功则执行lua脚本，保存数据到redis数据库。如果获取失败: 一直通过while循环尝试获取锁(可自定义等待时间，超时后返回失败)，获取成功后，执行lua脚本，保存数据到redis数据库。Redisson提供的分布式锁是支持锁自动续期的，也就是说，如果线程仍旧没有执行完，那么redisson会自动给redis中的目标key延长超时时间，这在Redisson中称之为 Watch Dog 机制。同时 redisson 还有公平锁、读写锁的实现。</p>
<pre><code class="language-java">public void test() throws Exception{
        RLock lock = redissonClient.getLock(&quot;guodong&quot;);    // 拿锁失败时会不停的重试
        // 具有Watch Dog 自动延期机制 默认续30s 每隔30/3=10 秒续到30s
        lock.lock();
        // 尝试拿锁10s后停止重试,返回false 具有Watch Dog 自动延期机制 默认续30s
        boolean res1 = lock.tryLock(10, TimeUnit.SECONDS); 
        // 没有Watch Dog ，10s后自动释放
        lock.lock(10, TimeUnit.SECONDS);
        // 尝试拿锁100s后停止重试,返回false 没有Watch Dog ，10s后自动释放
        boolean res2 = lock.tryLock(100, 10, TimeUnit.SECONDS);
        Thread.sleep(40000L);
        lock.unlock();
    }

</code></pre>
<p>Redissson tryLock流程如下：</p>
<pre><code class="language-java">   public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException {
        long time = unit.toMillis(waitTime);
        long current = System.currentTimeMillis();
        long threadId = Thread.currentThread().getId();  // 1.尝试获取锁 
        Long ttl = tryAcquire(leaseTime, unit, threadId);  // lock acquired 
        if (ttl == null) {
            return true;
        }
        // 申请锁的耗时如果大于等于最大等待时间，则申请锁失败.  
        time -= System.currentTimeMillis() - current;
        if (time &lt;= 0) {
            acquireFailed(threadId);
            return false;
        }
        current = System.currentTimeMillis();
        /**  * 2.订阅锁释放事件，并通过 await 方法阻塞等待锁释放，有效的解决了无效的锁申请浪费资源的问题：  * 基于信息量，当锁被其它资源占用时，当前线程通过 Redis 的 channel 订阅锁的释放事件，一旦锁释放会发消息通知待等待的线程进行竞争.  *  * 当 this.await 返回 false，说明等待时间已经超出获取锁最大等待时间，取消订阅并返回获取锁失败.  * 当 this.await 返回 true，进入循环尝试获取锁.  */
        RFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId);  
        // await 方法内部是用 CountDownLatch 来实现阻塞，获取 subscribe 异步执行的结果（应用了 Netty 的 Future）  
        if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) {
            if (!subscribeFuture.cancel(false)) {
                subscribeFuture.onComplete((res, e) -&gt; {
                    if (e == null) {
                        unsubscribe(subscribeFuture, threadId);
                    }
                });
            }
            acquireFailed(threadId);
            return false;
        }
        try {
            // 计算获取锁的总耗时，如果大于等于最大等待时间，则获取锁失败.    
            time -= System.currentTimeMillis() - current;
            if (time &lt;= 0) {
                acquireFailed(threadId);
                return false;
            }
            /**    * 3.收到锁释放的信号后，在最大等待时间之内，循环一次接着一次的尝试获取锁    * 获取锁成功，则立马返回 true，    * 若在最大等待时间之内还没获取到锁，则认为获取锁失败，返回 false 结束循环    */
            while (true) {
                long currentTime = System.currentTimeMillis();        // 再次尝试获取锁    
                ttl = tryAcquire(leaseTime, unit, threadId);      // lock acquired     
                if (ttl == null) {
                    return true;
                }
                // 超过最大等待时间则返回 false 结束循环，获取锁失败     
                time -= System.currentTimeMillis() - currentTime;
                if (time &lt;= 0) {
                    acquireFailed(threadId);
                    return false;
                }
                /**      * 6.阻塞等待锁（通过信号量(共享锁)阻塞,等待解锁消息）：      */
                currentTime = System.currentTimeMillis();
                if (ttl &gt;= 0 &amp;&amp; ttl &lt; time) {
                    //如果剩余时间(ttl)小于wait time ,就在 ttl 时间内，从Entry的信号量获取一个许可(除非被中断或者一直没有可用的许可)。     
                    getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
                } else {
                    //则就在wait time 时间范围内等待可以通过信号量      
                    getEntry(threadId).getLatch().tryAcquire(time, TimeUnit.MILLISECONDS);
                }
                // 更新剩余的等待时间(最大等待时间-已经消耗的阻塞时间)      
                time -= System.currentTimeMillis() - currentTime;
                if (time &lt;= 0) {
                    acquireFailed(threadId);
                    return false;
                }
            }
        } finally {
            // 7.无论是否获得锁,都要取消订阅解锁消息  
            unsubscribe(subscribeFuture, threadId);
        }
        return get(tryLockAsync(waitTime, leaseTime, unit));
    }
</code></pre>
<ol>
<li>尝试获取锁，返回 null 则说明加锁成功，返回一个数值，则说明已经存在该锁，ttl 为锁的剩余存活时间。</li>
<li>如果此时客户端 2 进程获取锁失败，那么使用客户端 2 的线程 id（其实本质上就是进程 id）通过 Redis 的 channel 订阅锁释放的事件。如果等待的过程中一直未等到锁的释放事件通知，当超过最大等待时间则获取锁失败，返回 false，如果等到了锁的释放事件的通知，则开始进入一个不断重试获取锁的循环。</li>
<li>循环中每次都先试着获取锁，并得到已存在的锁的剩余存活时间。如果在重试中拿到了锁，则直接返回。如果锁当前还是被占用的，那么等待释放锁的消息，具体实现使用了信号量 Semaphore 来阻塞线程，当锁释放并发布释放锁的消息后，信号量的 release() 方法会被调用，此时被信号量阻塞的等待队列中的一个线程就可以继续尝试获取锁了。</li>
<li>当锁正在被占用时，等待获取锁的进程并不是通过一个 while(true) 死循环去获取锁，而是利用了 Redis 的发布订阅机制,通过 await 方法阻塞等待锁的进程，有效的解决了无效的锁申请浪费资源的问题。</li>
</ol>
<h2 id="看门狗如何自动续期">看门狗如何自动续期</h2>
<p>Redisson看门狗机制， 只要客户端加锁成功，就会启动一个 Watch Dog。</p>
<pre><code class="language-java">  private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) {
        if (leaseTime != -1) {
            return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
        }
        RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);
        ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; {
            if (e != null) {
                return;
            }        // lock acquired       
            if (ttlRemaining == null) {
                scheduleExpirationRenewal(threadId);
            }
        });
        return ttlRemainingFuture;
    }
</code></pre>
<p>⚠️同时需要注意的是：</p>
<ol>
<li>watchDog 只有在未显示指定加锁时间（leaseTime）时才会生效。（这点很重要）</li>
<li>lockWatchdogTimeout设定的时间不要太小 ，比如我之前设置的是 100毫秒，由于网络直接导致加锁完后，watchdog去延期时，这个key在redis中已经被删除了。</li>
</ol>
<h2 id="续期原理">续期原理</h2>
<p>续期原理其实就是用lua脚本，将锁的时间重置为30s</p>
<pre><code class="language-java">   private void scheduleExpirationRenewal(long threadId) {
        ExpirationEntry entry = new ExpirationEntry();
        ExpirationEntry oldEntry = EXPIRATION_RENEWAL_MAP.putIfAbsent(getEntryName(), entry);
        if (oldEntry != null) {
            oldEntry.addThreadId(threadId);
        } else {
            entry.addThreadId(threadId);
            renewExpiration();
        }
    }

    protected RFuture&lt;Boolean&gt; renewExpirationAsync(long threadId) {
        return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, &quot;if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then &quot; + &quot;redis.call('pexpire', KEYS[1], ARGV[1]); &quot; + &quot;return 1; &quot; + &quot;end; &quot; + &quot;return 0;&quot;, Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
    }
</code></pre>
<p>Watch Dog 机制其实就是一个后台定时任务线程，获取锁成功之后，会将持有锁的线程放入到一个 RedissonLock.EXPIRATION_RENEWAL_MAP里面，然后每隔 10 秒 （internalLockLeaseTime / 3） 检查一下，如果客户端 还持有锁 key（判断客户端是否还持有 key，其实就是遍历 EXPIRATION_RENEWAL_MAP 里面线程 id 然后根据线程 id 去 Redis 中查，如果存在就会延长 key 的时间），那么就会不断的延长锁 key 的生存时间。</p>
<p>如果服务宕机了，Watch Dog 机制线程也就没有了，此时就不会延长 key 的过期时间，到了 30s 之后就会自动过期了，其他线程就可以获取到锁。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis选举流程]]></title>
        <id>https://q456qq520.github.io/post/redis-xuan-ju-liu-cheng/</id>
        <link href="https://q456qq520.github.io/post/redis-xuan-ju-liu-cheng/">
        </link>
        <updated>2025-05-10T03:17:28.000Z</updated>
        <content type="html"><![CDATA[<p>为了实现Redis读写分离的方式实现高可靠，我们使用redis集群模式，而且为了防止主节点压力过大，假设优化成了主-从-从模式。</p>
<p><strong>思考一个问题，主节点此时挂了怎么办</strong></p>
<p>这里主从模式下涉及到的几个问题：</p>
<ol>
<li>主库真的挂了吗？</li>
<li>我们应当选择哪个从库作为主库？</li>
<li>怎样让其他从库知道新的主库信息呢？</li>
<li>中断的数据如何恢复？</li>
</ol>
<p>所以我们引入哨兵机制</p>
<h2 id="什么是哨兵机制">什么是哨兵机制？</h2>
<p>在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这几个问题。</p>
<p>Redis引入哨兵（Sentinel）机制的主要目的是为了增强其高可用性和自动故障恢复能力。在分布式系统中，特别是用作数据存储的数据库系统中，保障高可用性是至关重要的，以确保系统在面对节点故障等情况时能够继续提供服务。</p>
<p><strong>哨兵实现了什么功能呢？</strong><br>
下面是Redis官方文档的描述：</p>
<ul>
<li>监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。</li>
<li>自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。</li>
<li>配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。</li>
<li>通知（Notification）：哨兵可以将故障转移的结果发送给客户端。</li>
</ul>
<h2 id="哨兵机制的基本流程">哨兵机制的基本流程</h2>
<p>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1746849001674.png" alt="" loading="lazy"></figure>
<h3 id="监控">监控</h3>
<p>Redis哨兵的监控流程涉及多个步骤，用于实时监控Redis集群中各个节点的状态并采取必要的措施来确保集群的可用性和稳定性。</p>
<ol>
<li>
<p>节点发现和配置： 哨兵通过配置文件指定要监控的主节点和从节点。启动哨兵后，它会连接到指定的节点，并获取有关其他节点的信息，形成一个初始的监控拓扑。</p>
</li>
<li>
<p>心跳检测： 哨兵会定期向监控的节点发送PING命令来检测节点是否存活。这些节点可以是主节点、从节点或其他哨兵节点。如果哨兵在一定时间内没有收到响应，它会认为节点不可用。</p>
</li>
<li>
<p>节点状态变更： 当哨兵连续多次无法连接到一个节点时，它会将该节点标记为主观下线。当多个哨兵都将节点标记为主观下线时，这个节点会被认为是客观下线。</p>
</li>
<li>
<p>故障判断和选举： 当主节点被标记为客观下线时，哨兵会执行故障判断。它会从剩余的健康主节点中选举一个作为新的主节点，并将该信息广播给其他哨兵和客户端。故障判断的逻辑考虑了多个因素，包括优先级、最近一次复制偏移量等。</p>
</li>
<li>
<p>自动故障切换： 如果主节点被标记为客观下线，哨兵会通知从节点晋升为新的主节点。同时，哨兵会更新其他从节点的配置，使其复制新的主节点。这确保了即使主节点发生故障，集群仍然可以继续提供服务。</p>
</li>
<li>
<p>监控从节点： 哨兵还会监控从节点的状态，包括从节点是否与主节点保持同步，以及从节点的复制延迟情况。如果从节点无法同步或者复制延迟过高，哨兵会将其标记为不健康。</p>
</li>
<li>
<p>节点恢复： 如果一个节点从客观下线状态恢复，哨兵会将其标记为健康，并将其重新纳入集群中。从节点恢复后，它会重新同步主节点的数据。</p>
</li>
<li>
<p>配置更新： 如果集群的拓扑发生变化，例如添加或移除节点，哨兵会自动更新配置，以便客户端能够正确连接到集群。</p>
</li>
<li>
<p>事件通知： 哨兵通过发布订阅机制向订阅者（通常是客户端）发送有关集群状态变化的消息。这使得应用程序能够根据实时的集群状态做出相应的决策。</p>
</li>
<li>
<p>持续监控： 哨兵会持续地监控集群中的节点，定期执行心跳检测、状态更新和故障判断，以确保集群的稳定运行。</p>
</li>
</ol>
<h3 id="主观下线与客观下线">主观下线与客观下线</h3>
<p>在Redis的哨兵监控机制中，有两个关键概念：<code>主观下线（Subjective Down）</code>和<code>客观下线（Objective Down）</code>。这些概念帮助哨兵判断节点的可用性和故障状态。</p>
<ol>
<li>
<p>主观下线（Subjective Down）： 主观下线是指单个哨兵节点认为一个特定的Redis节点（主节点、从节点或其他哨兵）不可用。主观下线是一种主观的判断，是基于单个哨兵节点的观察结果得出的。当一个哨兵无法连接到某个Redis节点，它会将该节点标记为主观下线。多个哨兵节点可能会对同一个节点发出主观下线标记。</p>
</li>
<li>
<p>客观下线（Objective Down）： 客观下线是指在整个哨兵集合中达成一致，认为某个特定的Redis节点不可用。客观下线是一种更客观的判断，需要多个哨兵节点共同达成一致。当多个哨兵节点都主观下线同一个Redis节点时，这个节点会被认为是客观下线。</p>
</li>
</ol>
<p>举例说明：</p>
<ul>
<li>
<p>假设有三个哨兵节点：Sentinel A、Sentinel B 和 Sentinel C，以及一个主节点 Master 和一个从节点 Slave。如果 Sentinel A 无法连接到 Master 节点，它会将 Master 标记为主观下线。同样地，如果 Sentinel B 也无法连接到 Master 节点，它也会将 Master 标记为主观下线。但这还不足以让 Master 被认为是客观下线。</p>
</li>
<li>
<p>当 Sentinel A 和 Sentinel B 都主观下线了 Master 节点，并且他们相互通信时发现了这个情况，他们就会在达成一致意见后将 Master 节点标记为客观下线。这时，整个哨兵集合达成一致，认为 Master 节点已下线。</p>
</li>
</ul>
<p>客观下线是一个更严格的判断，需要多个哨兵节点一致认为某个节点不可用，才会触发后续的故障判断和自动故障切换等动作。这种机制确保了在一个哨兵节点认为某节点下线时，不会立即触发故障切换，以避免误判造成不必要的切换。只有多个哨兵节点一致认为节点下线，才会触发后续的故障处理流程。</p>
<h3 id="如何选定新主库">如何选定新主库</h3>
<p>在Redis Sentinel模式中，当主节点（Master）发生故障导致下线后，哨兵会通过选举过程选择一个新的主节点（Master）来取代原来的主节点。选定新主库的过程如下：</p>
<ol>
<li>
<p>主观下线和客观下线判断： 当哨兵节点主观下线（单个哨兵认为不可用）一个主节点时，如果多数哨兵都主观下线了同一个主节点，那么这个主节点会被标记为客观下线（多数派共识）。</p>
</li>
<li>
<p>选举新主节点： 当一个主节点被标记为客观下线后，哨兵节点会开始选举一个新的主节点。选举过程如下：<br>
哨兵会在所有没有下线的从节点（Slaves）中选择一个作为新主节点。哨兵会选择一个延迟最小、复制偏移量最大的从节点作为新主节点。这确保了新主节点是最接近原主节点的从节点。<br>
如果没有合适的从节点，哨兵会选择一个具备最高优先级的从节点，将其升级为主节点。如果优先级相同，那么哨兵会选择一个复制偏移量最大的从节点。</p>
</li>
<li>
<p>故障转移和切换： 一旦新主节点被选定，哨兵会发起故障转移操作。旧主节点会变成新主节点的一个从节点。其他从节点会重新配置，指向新的主节点。这个过程会保证尽量不丢失数据，并且保证整个集群的高可用性。</p>
</li>
</ol>
<p>选定新主库的过程是一个由哨兵节点协同工作的流程，确保了在主节点故障的情况下，尽可能地选择一个合适的从节点作为新的主节点，实现集群的高可用性和数据完整性。</p>
<h3 id="如何配置哨兵">如何配置哨兵</h3>
<ol>
<li>哨兵配置文件： 在Redis 6.x版本中，哨兵的配置文件名称默认为redis-sentinel.conf。</li>
<li>配置变化： Redis 6.x版本引入了一些新的哨兵配置选项，以适应新的功能和改进。以下是一些常见的配置选项：<br>
sentinel monitor mymaster 127.0.0.1 6379 2   # 监控名为 &quot;mymaster&quot; 的主节点，2表示至少需要2个哨兵同意主观下线才会执行故障转移<br>
sentinel down-after-milliseconds mymaster 5000   # 主观下线判定为5秒无响应<br>
sentinel parallel-syncs mymaster 1   # 执行故障转移时同时同步的从节点数量<br>
sentinel failover-timeout mymaster 10000   # 故障转移超时时间为10秒<br>
sentinel auth-pass mymaster mypassword   # 主节点的访问密码</li>
<li>启动哨兵节点： 在Redis 6.x版本中，启动哨兵节点的命令为：<br>
redis-server /path/to/redis-sentinel.conf --sentinel</li>
<li>查看哨兵状态： 使用以下命令查看Redis 6.x版本哨兵节点的状态：<br>
redis-cli -p 26379<br>
sentinel master mymaster   # 查看主节点的信息<br>
sentinel slaves mymaster   # 查看从节点的信息<br>
sentinel sentinels mymaster   # 查看其他哨兵节点的信息</li>
</ol>
<h3 id="哨兵是如何互相发现的">哨兵是如何互相发现的？</h3>
<p>我们查看配置可以看到，我们并没有配置从节点的哨兵，我们只配置了主节点地址。</p>
<p>那么哨兵之间是如何互相发现通信的呢？</p>
<p>在Redis Sentinel（哨兵）集群中，哨兵节点之间通过发布订阅机制来互相发现和通信。这种方式使得哨兵节点能够监控主节点和从节点的状态，并进行故障检测和故障转移。</p>
<p>以下是哨兵集群如何通过发布订阅机制互相发现的工作流程：</p>
<ol>
<li>
<p>初始连接： 在启动时，每个哨兵节点会尝试连接到指定的主节点。这些哨兵节点通过配置文件中的sentinel monitor命令指定要监控的主节点信息。</p>
</li>
<li>
<p>Sentinel命令发布： 当一个哨兵节点成功连接到主节点后，它会开始定期向主节点发送PING命令，以确保主节点处于活跃状态。如果哨兵节点检测到主节点不可用，它会将一个+switch-master命令发布到频道中，通知其他哨兵节点。</p>
</li>
<li>
<p>发布订阅机制： Redis的发布订阅机制允许一个节点（发布者）向一个或多个节点（订阅者）广播消息。在哨兵集群中，每个哨兵节点都订阅了一个名为__sentinel__:hello的频道，用于接收其他哨兵节点发送的信息。<br>
<img src="https://q456qq520.github.io/post-images/1746851281045.png" alt="" loading="lazy"></p>
</li>
<li>
<p>发现其他哨兵节点： 当一个哨兵节点成功连接到主节点后，它会向__sentinel__:hello频道发布一个&quot;Hello&quot;消息，其中包含它自己的信息（如IP地址和端口号）。其他哨兵节点通过订阅这个频道，可以获取所有其他哨兵节点的信息。</p>
</li>
<li>
<p>收集哨兵信息： 每个哨兵节点通过订阅__sentinel__:hello频道，收集到其他哨兵节点的信息。这使得每个哨兵节点都知道了集群中其他哨兵节点的存在。</p>
</li>
<li>
<p>故障检测和转移： 当一个哨兵节点检测到主节点不可用时，它会通过发布+switch-master命令来通知其他哨兵节点。这个命令包含了新的主节点信息，以及在执行故障转移时需要的其他信息。其他哨兵节点收到这个命令后，会进行判断并可能发起故障转移。</p>
</li>
</ol>
<p>通过以上机制，哨兵节点可以相互发现和通信，共同监控主节点和从节点的状态，并在主节点下线时协同执行故障转移操作。这种发布订阅机制确保了哨兵集群中节点之间的实时信息传递和协作。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1746852009500.png" alt="" loading="lazy"></figure>
<h2 id="由哪个哨兵执行主从切换">由哪个哨兵执行主从切换？</h2>
<h3 id="客观下线具体判断流程">客观下线具体判断流程</h3>
<ol>
<li>
<p>故障检测： 哨兵节点定期向集群中的所有主节点和从节点发送PING命令来检测节点的可用性。如果一个哨兵节点连续一定次数没有收到节点的回复，就会将该节点标记为可能进入客观下线状态。</p>
</li>
<li>
<p>Quorum判断： 在判断一个节点是否客观下线时，需要考虑Quorum的概念。Quorum是指一个最小的投票数，当达到或超过这个投票数时，哨兵认为节点可能进入客观下线状态。Quorum的值通常设置为哨兵节点数量的一半加一。</p>
</li>
<li>
<p>投票过程： 当哨兵节点开始怀疑某个节点可能客观下线时，它会向其他哨兵节点发送一个SENTINEL is-master-down-by-addr命令，询问其他哨兵节点是否也认为该节点客观下线。其他哨兵节点会对此做出回应，根据回应的数量来判断是否达到Quorum。</p>
</li>
<li>
<p>达到Quorum： 如果收到的回应数量达到或超过Quorum，那么哨兵节点就会认为该节点进入客观下线状态。这表示集群中有足够多的哨兵都认为该节点可能下线，进而触发后续的主从切换流程。</p>
</li>
<li>
<p>执行后续操作： 一旦一个节点被认为客观下线，哨兵节点将开始执行故障转移操作，选择新的主节点并开始同步数据。这将最终导致一个新的主节点被选出，从而实现高可用性。</p>
</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1746852276842.png" alt="" loading="lazy"></figure>
<h2 id="选举leader流程">选举Leader流程</h2>
<p>Redis Sentinel（哨兵）是用于监控和管理Redis主从复制以及自动故障切换的工具。当主节点失效时，哨兵会协调选择一个从节点作为新的主节点，这涉及到选举Leader的过程。详细流程如下：</p>
<ol>
<li>监控主节点： 哨兵持续监控Redis主节点的状态，包括主节点是否在线，主从复制是否正常，以及哨兵和其他节点的通信情况。</li>
<li>检测主节点失效： 当哨兵检测到主节点失效（例如，无法响应PING命令），它会将主节点标记为“主观下线”。</li>
<li>广播主观下线状态： 一旦主观下线状态被确认，哨兵会广播该信息给其他哨兵和节点，告知主节点已经“主观下线”。</li>
<li>投票： 当其他哨兵收到关于主观下线状态的广播时，它们会进行投票来决定是否需要进行领导者选举。</li>
<li>选举Leader： 如果多个哨兵都认为主节点失效，它们将进入领导者选举过程。选举过程使用了Raft算法的变体。</li>
<li>提议投票： 在选举过程中，哨兵会提议自己作为领导者，然后请求其他哨兵投票支持。</li>
<li>投票表决： 哨兵在收到提议后会表决是否支持该提议。通常，哨兵会投票给具有最高配置版本号的提议者。</li>
<li>Quorum判断： 在选举过程中，哨兵需要收集足够数量的投票，达到Quorum（大多数）的支持才能选举成功。</li>
<li>选出新领导者： 如果某个哨兵获得足够多的投票，超过了Quorum，那么它将被选为新的领导者。</li>
<li>通知其他节点： 新选出的Leader会向其他哨兵和节点广播其成为领导者的消息，确保集群中的所有节点都知道领导者的变更。</li>
<li>故障切换： 一旦新的Leader选举完成，哨兵会协调进行故障切换，将一个从节点提升为新的主节点，使整个集群继续正常运行。</li>
<li>恢复正常状态： 一旦故障切换完成，新的主节点将开始处理客户端请求，集群会恢复到正常运行状态。</li>
</ol>
<p>需要注意的是，Redis Sentinel的选举Leader过程受到Paxos算法和Raft算法等分布式一致性算法的影响，以保证在主节点失效时能够选择合适的节点作为新的主节点，从而保持数据的一致性和高可用性。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1746852708045.png" alt="" loading="lazy"></figure>
<p>⚠️<br>
如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。</p>
<p>要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ThreadLocal简介]]></title>
        <id>https://q456qq520.github.io/post/threadlocal-jian-jie/</id>
        <link href="https://q456qq520.github.io/post/threadlocal-jian-jie/">
        </link>
        <updated>2025-05-07T09:45:46.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-threadlocal简介">一、ThreadLocal简介</h2>
<p><code>ThreadLocal</code>顾名思义可以根据字面意思理解成线程本地变量。也就是说如果定义了一个ThreadLocal，每个线程都可以在这个ThreadLocal中读写，这个读写是线程隔离的，线程之前不会有影响。</p>
<p>每个Thread都维护自己的一个ThreadLocalMap ，所以是线程隔离的。</p>
<pre><code class="language-java">/* ThreadLocal values pertaining to this thread. This map is maintained
 * by the ThreadLocal class. */
ThreadLocal.ThreadLocalMap threadLocals = null;
</code></pre>
<p>通过这个ThreadLocalMap实现数据的读写，既然是Map肯定有key和value，但是这个ThreadLocalMap的key可以简单的看成是ThreadLocal，实际是并不是ThreadLocal的本身，而是它的一个弱引用。</p>
<h2 id="二-threadlocal方法和成员变量">二、ThreadLocal方法和成员变量</h2>
<h3 id="api">API</h3>
<p>ThreadLocal的API很少就包含了4个，分别是get()、set()、remove()、withInitial()，源码如下：</p>
<pre><code class="language-java">public T get() {}

public void set(T value){}

public void remove(){}

public static &lt;S&gt; ThreadLocal&lt;S&gt; withInitial(Supplier&lt;? extends S&gt; supplier) {
        
}
</code></pre>
<ul>
<li>get()：获取当前线程对应的ThreadLocalMap存储的值，key为当前TheadLocal（实际为TheadLocal的弱引用），也就是获取当前线程本地变量的值。</li>
<li>set(T value)：给当前线程对应的ThreadLocalMap的设置值，也就是给当前线程本地变量设置值。</li>
<li>remove()：清除前线程对应的ThreadLocalMap存储的TheadLocal，也就是清除当前线程本地变量的值。</li>
<li>withInitial()：用于创建一个线程局部变量，变量的初始化值通过调用Supplier的get方法来确定</li>
</ul>
<h3 id="成员变量">成员变量</h3>
<pre><code class="language-java">// 调用nextHashCode()方法获取下一个hashCode值，用于计算ThreadLocalMap.tables数组下标
// key.threadLocalHashCode &amp; (len - 1)
private final int threadLocalHashCode = nextHashCode();

// 原子类，用于计算hashCode值
private staitc AmoicInteger nextHashCode = new AmoicInteger();

// hash增量值，斐波那契数也叫黄金分割数，可以让hash值分布非常均匀
private static final int HASH_INCREMENT = 0x61c88647；

// 获取下一个hashCode值方法，只用原子类操作
private static int nextHashCode () {
    return nextHashCode.getAndAdd(HASH_INCREMENT);
}
</code></pre>
<h2 id="三-threadlocalmap">三、ThreadLocalMap</h2>
<p>ThreadLocalMap是ThreadLocal类的一个静态内部类，在上面有说到每个线程都维护着一个ThreadLocalMap，这个`ThreadLocalMap 就是用来储存数据的。</p>
<p>ThreadLocalMap内部维护着一个Entry节点，这个节点继承了WeakReference类，泛型为ThreadLocal表示是弱引用，节点内部定义了一个为Object的value，这个value就是我们存放的值，Entry类的构造方法只有一个，传入key和value，这个key就是ThreadLocal，实际为ThreadLocal的弱引用。</p>
<pre><code class="language-java">static class Entry extends WeakReference&lt;ThreacLocal&lt;?&gt;&gt; {
    Object value;
    
    Entry(ThreadLocal&lt;?&gt; k, Object v){
        super(k);
        value = v;
    }
}
</code></pre>
<h3 id="thread-threadlocalmap-threadlocal结构关系">Thread、ThreadLocalMap、ThreadLocal结构关系</h3>
<p>每个Thread都有一个ThreadLocalMap变量，ThreadLocalMap内部定义了Entry节点类，这个节点继承了WeakReference类泛型为ThreacLocal类，节点类的构造方法ThreadLocal&lt;?&gt; k, Object v，所以可以得到下面的结构关系图：</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1746611761654.webp" alt="" loading="lazy"></figure>
<h3 id="gc之后key是否为null">GC之后key是否为null？</h3>
<p>既然ThreadLocalMap的key是弱引用，GC之后key是否为null？在搞清楚这个问题之前，我们需要先搞清楚Java的四种引用类型：</p>
<ul>
<li>
<p>强引用：new出来的对象就是强引用，只要强引用存在，垃圾回收器就永远不会回收被引用的对象，哪怕内存不足的时候。</p>
</li>
<li>
<p>软引用：使用SoftReference修饰的对象被称为软引用，在内存要溢出的时候软引用指向的对象会被回收。</p>
</li>
<li>
<p>弱引用：使用WeakReference修饰的对象被称为弱引用，只要发生垃圾回收，被弱引用指向的对象就会被回收。</p>
</li>
<li>
<p>虚引用：虚引用是最弱的引用，用PhantomReference进行定。唯一的作用就是用来队列接受对象即将死亡的通知。</p>
<p>**这个问题的答案是不为null **，可以看下面的图</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1746612119050.webp" alt="" loading="lazy"></figure>
<p>通过上图我们知道ThreadLocal的强引用是仍然存在的，所以不会被回收，不为null</p>
<h3 id="threadlocalmap成员变量">ThreadLocalMap成员变量</h3>
</li>
</ul>
<pre><code class="language-java">  // 初始化容量 必须为2的幂，位运算取代模运算提升计算效率，可以试hash值发生碰撞的概率更小，尽可能的使
// 元素在哈希表中均匀的散列
private static final int INITTAL_CAPACIRY = 16;

// Entry表
private Entry[] table;

// Entry表存放的元素数量
private int size = 0;

// 扩容阙值
private int threshold;
</code></pre>
<h2 id="四-threadlocalset方法源码详解">四、ThreadLocal.set()方法源码详解</h2>
<h3 id="set方法">set()方法</h3>
<pre><code class="language-java">pubic void set(T value) {
    // 获取当前线程
    Thread t = Threac.currentThread();
    // 获取当前线程的ThreadLocalMap
    ThreadLocalMap map = getMap(t);
    // 如果map不为null， 调用ThreadLocalMap.set()方法设置值
    if (map != null)
        map.set(this, value);
    else 
        // map为null，调用createMap()方法初始化创建map
        createMap(t, value);
}

// 返回线程的ThreadLocalMap.threadLocals
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}

// 调用ThreadLocalMap构造方法创建ThreadLocalMap
void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}

// ThreadLocalMap构造方法，传入firstKey, firstValue
ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) {
    // 初始化Entry表的容量 = 16
    table = new Entry[INITIAL_CAPACITY];
    // 获取ThreadLocal的hashCode值与运算得到数组下标
    int i = firsetKey.threadLocalHashCode &amp; (INITAL_CAPACITY - 1);
    // 通过下标Entry表赋值
    table[i] = new Entry(firstKey, firstValue);
    // Entry表存储元素数量初始化为1
    size = 1;
    // 设置Entry表扩容阙值 默认为 len * 2 / 3
    setThreshold(INITIAL_CAPACITY);
}

private void setThreshold(int len) {
    threshold = len * 2 / 3
}
</code></pre>
<p>ThreadLocal.set()方法还是很简单的，核心方法在ThreadLocalMap.set()方法，ThreadLocal.set()方法流程如下：</p>
<ol>
<li>获取当前线程的ThreadLocalMap map 。</li>
<li>如果map不为null则调用map.set()方法设置值。</li>
<li>如果map为null则调用createMap方法创建。</li>
<li>createMap()方法通过ThreadLocalMap的构造方法创建，构造方法主要做了初始化Entry[] table容量16，通过ThreadLocal的threadLocalHashCode调用nextHashCode()方法获取hashCode值计算出下标，table数组通过下标赋值，初始化存储的元素数量，初始化数组扩容阙值。</li>
</ol>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1746612417635.webp" alt="" loading="lazy"></figure>
<p>ThreadLocalMap在构造方法里处理的时候用到hash算法，源码如下：</p>
<pre><code class="language-java">int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);

private final int threadLocalHashCode = nextHashCode();

private static final int HASH_INCREMENT = 0x61c88647;

private static int nextHashCode() {
    return nextHashCode.getAndAdd(HASH_INCREMENT);
}
</code></pre>
<p>这里最关键的就是<code>threadLocalHashCode</code>值的计算，ThreadLocal中有一个属性为<code>HASH_INCREMENT = 0x61c88647</code>，每创建一个ThreadLocal就会调用一次nextHashCode()方法，这个HASH_INCREMENT值就会增长0x61c88647，这个值很特殊，是斐波那契数也叫黄金分割数，这个值可以让hash分布非常均匀。</p>
<p>ThreadLocalMap.set()方法分为好几种情况，主要有以下四种情况，针对不同的情况我们通过画图来说明。</p>
<blockquote>
<p>说明： 下面所有图中，绿色块Entry代表正常数据，灰色代表Entry的key值为null，已被GC回收，白色代表Entry为null。</p>
</blockquote>
<p><strong>第一种情况</strong>：通过hash计算得到的下标，该下标对应的Entry为null，这种情况直接将该数据放入该槽位即可。<br>
<img src="https://q456qq520.github.io/post-images/1746612601919.webp" alt="" loading="lazy"></p>
<p><strong>第二种情况</strong>：通过hash计算得到的下标，该下标对应的Entry不为null，但是key相同，这种情况直接更新该槽位的value值。<br>
<img src="https://q456qq520.github.io/post-images/1746612706011.webp" alt="" loading="lazy"></p>
<p><strong>第三种情况</strong>：通过hash计算得到的下标，该下标对应的Entry不为null，且key不相同，这种时候会遍历数组，线性往后查找，查找Entry为null的槽位，且在找到Entry为null之前没有遇到key过期的Entry，就该数据放入该槽位中，如果遍历过程中，遇到了key相等的槽位，直接更新value即可：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1746612782318.webp" alt="" loading="lazy"></figure>
<p>注意：每次循环查找都会判断key是否相等，如果相等则更新value直接返回。</p>
<p><strong>第四种情况</strong>：基于第三种情况，如果在找到Entry为null之前遇到了key过期的Entry，如下图：</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1746612801162.webp" alt="" loading="lazy"></figure>
<p>如上图散列数组下标为7位置对应的Entry数据key为null，说明此数据key值已经被垃圾回收掉了，此时会执行<code>replaceStaleEntry()</code>方法，该方法含义是替换过期数据的逻辑，以index=7为起点开始向前遍历，进行探测式数据清理工作。</p>
<p>初始化探测式清理过期数据扫描的开始位置：<code>slotToExpunge = stateSlot = 7</code>。</p>
<p>以当前stateSlot 开始向前迭代找到，找到其他过期的数据，然后更新过期数据起始扫描下标的slotToExpunge ，直到找到了Entry为null的槽位则结束。</p>
<p>如果找到过期数据，继续向前迭代，直到遇到Entry=null的槽位则停止迭代。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1746612982058.webp" alt="" loading="lazy"></figure>
<p>上图以当前节点index = 7向前迭代，检测是否有过期的Entry数据，如果有则更新slotToExpunge的值，遇到Entry为null则结束探测，以上图为例slotToExpunge被更新为0。</p>
<p>上面向前迭代的操作是为了更新探测清理过期数据的起始位置soltToExpunge的值，这个值是用来判断当前过期槽位staleSlot之前是否还有过期元素。</p>
<p>接着开始staleSolt位置index = 7向后迭代，如果找到了相等key的Entry的数据则更新value值，如下图：</p>
<figure data-type="image" tabindex="7"><img src="https://q456qq520.github.io/post-images/1746612994133.webp" alt="" loading="lazy"></figure>
<p>从当前节点staleSolt位置开始向后寻找key相等的Entry位置，如果找到了key相等的Entry，则会交换staleSlot元素的位置，且更新value值，然后进行过期Entry的清理工作，如下图：</p>
<figure data-type="image" tabindex="8"><img src="https://q456qq520.github.io/post-images/1746613005200.webp" alt="" loading="lazy"></figure>
<p>如果没有找到相等key的Entry的数据，如下图：</p>
<figure data-type="image" tabindex="9"><img src="https://q456qq520.github.io/post-images/1746613019830.webp" alt="" loading="lazy"></figure>
<p>从当前节点staleSlot向后查找key值相等的Entry，如果没有找到，则会继续往后查找直到找到Entry为null停止，然后创建新的Entry，替换stableSlot的位置。</p>
<p>替换完成之后也是进行过期元素的清理工作，清理工作的方法主要有两个<code>expungeStaleEntry</code>和<code>cleanSomeSlots</code>。</p>
<pre><code class="language-java">private void set(ThreadLocal&lt;?&gt; key, Object value) {
    // 获取Entry表
    Entry[] tab = table;
    // 获取表长度
    int len = tab.length;
    // 获取当前要放入元素的下标
    int i = key.threadLocalHashCode &amp; (len - 1);
    
    // 循环查找
    for (Entry e = tab[i]; 
         e != null;
         e = tab[i = nextIndex(i, len)]){
        ThreadLocal&lt;?&gt; k = e.get();
        
        // 如果查找到key相等的entry，则更新value
        if (k == key) {
            v.value = value;
            return;
        }
        
        // 如果查找到为key为null的entry，说明key过期，被GC回收
        // 这个时候要初始化探测式清理的起始位置
        // 替换过期元素
        if (k == null) {
            replaceStateEntry(key, value, i);
            return;
        }
    }
    
    // 循环查找过程中，没有找到key相等的entry，且没有key过期的entry
    // 则新建一个entry放入entry表中
    table[i] = new Entry(key, value);
    
    // 存放元素数量+1
    int sz = ++size;
    // 调用启发式清理， 且元素数量大于扩容阙值
    // 则调用rehash方法，该方法会进行key过期的entry清理工作，清理完成之后再判断是否需要扩容
    if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
        rehash();
}
</code></pre>
<p>上面代码流程主要如下：</p>
<ol>
<li>首先获取Entry表，Entry表长度，通过hashCode计算下标，然后for循环Entry表。</li>
<li>如果循环查找过程中找到了key相等的Entry则更新value对应我们上面说的第二种情况。</li>
<li>如果循环查找过程找到了key为null的Entry，说明key过期了，替换过期元素，需要初始化探测式清理的其实位置，调用replaceStaleEntry()方法，这个方法我们下面再说，这个对应我们上面说的第四种情况。</li>
<li>for循环查找完毕，说明在查找过程中该下标对应的Entry为null，则在新建一个Entry放入该槽位，然后调用启发式清理工作。</li>
<li>如果启发式清理未清理任务数据，且size超过扩容阙值(2/3)，则调用rehash()方法，该方法会先进行一次探测式清理，清理过期元素，清理完毕之后如果size &gt;= threshold - threshold / 4 ，则会进行扩容操作。</li>
</ol>
<p>接下来看核心方法<code>replaceStaleEntry()</code>，该方法在查找过程中遇到key = null数据的时候会执行，该方法提供了替换过期数据的功能，可以对应上面说第四种情况来看，源码如下：</p>
<pre><code class="language-java">private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value,
                                       int staleSlot) {
    // 获取Entry表
    Entry[] tab = table;
    // 获取Entry表长度
    int len = tab.length;
    Entry e;

    // 定义探测式清理起始位置 slotToExpunge = staleSlot
    int slotToExpunge = staleSlot;
    
    // 从staleSlot开始向前迭代查找是否有key=null的entry
    // 如果有则更新slotToExpunge
    for (int i = prevIndex(staleSlot, len);
         (e = tab[i]) != null;
         i = prevIndex(i, len))
        if (e.get() == null)
            slotToExpunge = i;

    // staleSlot开始向后循环
    for (int i = nextIndex(staleSlot, len);
         (e = tab[i]) != null;
         i = nextIndex(i, len)) {
        ThreadLocal&lt;?&gt; k = e.get();

        // 如果查找到了key相等entry
        // 则替换staleSlot和i的位置，且更新value的值
        if (k == key) {
            e.value = value;
            
               // 替换staleSlot和i的位置
            tab[i] = tab[staleSlot];
            // 更新value值
            tab[staleSlot] = e;
            
            // 如果slotToExpunge == staleSlot，说明向前循环的没有查找到key过期的entry
            // 更新slotToExpunge值
            // 则会调用启动式过期清理，先会进行一遍过期元素探测操作
            if (slotToExpunge == staleSlot)
                slotToExpunge = i;
            cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
            return;
        }

        // 如果找到了key为null 且向前循环的没有查找到key过期的entry
        // 则更新slotToExpunge
        if (k == null &amp;&amp; slotToExpunge == staleSlot)
            slotToExpunge = i;
    }

    // 说明没有找到k == key的数据，且碰到Entry为null的数据
    // 则将数据放入该槽位
    tab[staleSlot].value = null;
    tab[staleSlot] = new Entry(key, value);

    // slotToExpunge != staleSlot 说明从staleSlot开始向前迭代查找有key=null的entry
    if (slotToExpunge != staleSlot)
        // 启动式清理之前，先会进行一次过期元素探测，如果发现了有过期的数据就会先进行探测式清理
        cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);
}
</code></pre>
<p>上面代码主要流程如下：</p>
<ol>
<li>首先获取Entry表，Entry表长度，定义探测式清理起始位置 slotToExpunge = staleSlot。</li>
<li>从staleSlot开始向前迭代查找是否有key=null的entry，如果有则更新slotToExpunge。</li>
<li>staleSlot开始向后循环，如果查找到了key相等entry，则替换staleSlot和i的位置，且更新value的值，然后判断slotToExpunge == staleSlot，说明向前循环的没有查找到key过期的entry， 然后更新slotToExpunge值，则会调用启动式过期清理，先会进行一遍过期元素探测操作，如果发现了有过期的数据就会先进行探测式清理。</li>
<li>如果找到了key为null 且向前循环的没有查找到key过期的entry，则更新slotToExpunge。</li>
<li>循环结束，方法没有退出，说明没有找到k == key的数据，且碰到Entry=null的数据，则将数据放入该槽位。</li>
<li>最后判断slotToExpunge != staleSlot，说明从staleSlot开始向前迭代查找有key=null的entry，则调用启动式清理，在启动式清理之前，先会进行一次过期元素探测，如果发现了有过期的数据就会先进行探测式清理。</li>
</ol>
<h3 id="threadlocalmap过期-key-的启发式清理流程">ThreadLocalMap过期 key 的启发式清理流程</h3>
<p>ThreadLocalMap两种过期key数据清理方式：<strong>探测式清理</strong>和<strong>启发式清理</strong>。</p>
<h4 id="探测式清理">探测式清理</h4>
<p>探测式清理方法expungeStaleEntry，遍历散列数组，从开始位置向后探测清理过期数据，将过期数据的Entry设置为null，遍历过程如果遇到未过期的数据则会将此数据rehash后重新在table数组中定位，如果定位的位置已经有了元素，则会将未过期的数据放在最靠近此位置的Entry = null的桶中，使rehash后的Entry数据距离正确的桶位置更近一点。这种优化会提高整个散列表查询性能。</p>
<pre><code class="language-java">// staleSlot探测式清理起始位置
private int expungeStaleEntry(int staleSlot) {
    Entry[] tab = table;
    int len = tab.length;
    
    // 将起始位置置空
    tab[staleSlot].value = null;
    tab[staleSlot] = null;
    // 元素数量减1
    size--;

    // 重新迭代散列，直到发现空槽
    Entry e;
    int i;
    for (i = nextIndex(staleSlot, len);
         (e = tab[i]) != null;
         i = nextIndex(i, len)) {
        ThreadLocal&lt;?&gt; k = e.get();
        // 如果key过期，则清空元素，数量减1
        if (k == null) {
            e.value = null;
            tab[i] = null;
            size--;
        } else {
            // 如果key没有过期，则重新计算hash，重新获取下标
            int h = k.threadLocalHashCode &amp; (len - 1);
            // 如果当前下标存在值，则寻找离冲突key所在entry最近的空槽
            if (h != i) {
                // i位置槽置空
                tab[i] = null;

                // 寻找离冲突key所在entry最近的空槽，放入该槽
                while (tab[h] != null)
                    h = nextIndex(h, len);
                tab[h] = e;
            }
        }
    }
    return i;
}
</code></pre>
<h4 id="启发式清理">启发式清理</h4>
<pre><code class="language-java">private boolean cleanSomeSlots(int i, int n) {
    boolean removed = false;
    Entry[] tab = table;
    int len = tab.length;
    do {
        i = nextIndex(i, len); // 从下一个位置开始
        Entry e = tab[i];
        // 遍历到key==null的Entry
        if (e != null &amp;&amp; e.get() == null) {
            n = len; // 重置n
            removed = true; // 标志有清理元素
            i = expungeStaleEntry(i); // 清理
        }
    } while ( (n &gt;&gt;&gt;= 1) != 0); // log(n) 限制--对数次
    return removed;
}
</code></pre>
<p>从i的下一个位置判断元素是否需要清除，如果遇到key==null的元素则会重置n，需要清除且更新i的值，判断且清除完毕之后，n = n &gt;&gt;&gt; 1直到n = 0则退出清理。</p>
<h2 id="五-threadlocalmapget方法详解">五、ThreadLocalMap.get()方法详解</h2>
<p>主要包含两种情况，一种是hash计算出下标，该下标对应的Entry.key和我们传入的key相等的情况，另外一种就是不相等的情况。</p>
<p>相等情况：相等情况处理很简单，直接返回value，如下图：</p>
<figure data-type="image" tabindex="10"><img src="https://q456qq520.github.io/post-images/1746613556386.webp" alt="" loading="lazy"></figure>
<p>上图中比如get(ThreadLocal1)计算下标为4，且4存在Entry，且key相等，则直接返回value = 11。</p>
<p>不相等情况：</p>
<p>以get(ThreadLocal2)为例计算下标为4，且4存在Entry，但key相等，这个时候则为往后迭代寻找key相等的元素，如果寻找过程中发现了有key = null的元素则回进行探测式清理操作。如下图：</p>
<figure data-type="image" tabindex="11"><img src="https://q456qq520.github.io/post-images/1746613716653.webp" alt="" loading="lazy"></figure>
<p>迭代到index=5的数据时，此时Entry.key=null，触发一次探测式数据回收操作，执行expungeStaleEntry()方法，执行完后，index 5,8的数据都会被回收，而index 6,7的数据都会前移，此时继续往后迭代，到index = 6的时候即找到了key值相等的Entry数据，如下图：</p>
<figure data-type="image" tabindex="12"><img src="https://q456qq520.github.io/post-images/1746613647463.webp" alt="" loading="lazy"></figure>
<pre><code class="language-java">public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings(&quot;unchecked&quot;)
            T result = (T)e.value;
            return result;
        }
    }
    // 未找到的话，则调用setInitialValue()方法设置null
    return setInitialValue();
}

private Entry getEntry(ThreadLocal&lt;?&gt; key) {
    int i = key.threadLocalHashCode &amp; (table.length - 1);
    Entry e = table[i];
    // key相等直接返回
    if (e != null &amp;&amp; e.get() == key)
        return e;
    else
        // key不相等调用getEntryAfterMiss()方法
        return getEntryAfterMiss(key, i, e);
}

private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) {
    Entry[] tab = table;
    int len = tab.length;
    
    // 迭代往后查找key相等的entry
    while (e != null) {
        ThreadLocal&lt;?&gt; k = e.get();
        if (k == key)
            return e;
        // 遇到key=null的entry，先进行探测式清理工作
        if (k == null)
            expungeStaleEntry(i);
        else
            i = nextIndex(i, len);
        e = tab[i];
    }
    return null;
}
</code></pre>
<h3 id="threadlocalmap的扩容机制">ThreadLocalMap的扩容机制</h3>
<p>在ThreadLocalMap.set()方法最后，如果执行完启发式清理工作之后，未清理任何数据，且当前散列数组中元素已经超过扩容阙值len*2/3，则执行rehash()逻辑：</p>
<pre><code class="language-java">if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
    rehash();
</code></pre>
<pre><code class="language-java">private void rehash() {
    //先进行探测式清理工作
    expungeStaleEntries();

    //探测式清理完毕之后 如果size &gt;= threshold - threshold / 4
    // 也就是size &gt;= threshold * 3/4，也就是 size &gt;= len * 1/2，则扩容
    if (size &gt;= threshold - threshold / 4)
        resize();
}

private void expungeStaleEntries() {
    Entry[] tab = table;
    int len = tab.length;
    for (int j = 0; j &lt; len; j++) {
        Entry e = tab[j];
        if (e != null &amp;&amp; e.get() == null)
            expungeStaleEntry(j);
    }
}
</code></pre>
<p>rehash()方法源码流程如下：</p>
<ol>
<li>首先进行探测式清理工作</li>
<li>如果探测式清理工作完毕之后，如果size &gt;= threshold - threshold / 4， 也就是size &gt;= threshold * 3/4，也就是 size &gt;= len * 1/2，则调用resize()扩容。</li>
</ol>
<p>扩容方法resize()方法源码如下：</p>
<pre><code class="language-java">private void resize() {
    Entry[] oldTab = table;
    int oldLen = oldTab.length;
    int newLen = oldLen * 2;
    Entry[] newTab = new Entry[newLen];
    int count = 0;

    for (int j = 0; j &lt; oldLen; ++j) {
        Entry e = oldTab[j];
        if (e != null) {
            ThreadLocal&lt;?&gt; k = e.get();
            if (k == null) {
                e.value = null;
            } else {
                int h = k.threadLocalHashCode &amp; (newLen - 1);
                while (newTab[h] != null)
                    h = nextIndex(h, newLen);
                newTab[h] = e;
                count++;
            }
        }
    }

    setThreshold(newLen);
    size = count;
    table = newTab;
}
</code></pre>
<p>扩容方法执行之后tab的大小为原先的两倍oldLen * 2，然后变量老的散列表，重新计算hash位置，然后放到新的散列表中，如果出现hash冲突则往后寻找最近的entry为null的槽位放入，扩容完成之后，重新计算扩容阙值。</p>
<h2 id="六-threadlocalremove方法源码详解">六、ThreadLocal.remove()方法源码详解</h2>
<pre><code class="language-java">public void remove() {
    ThreadLocalMap m = getMap(Thread.currentThread());
    if (m != null)
        m.remove(this);
}

private void remove(ThreadLocal&lt;?&gt; key) {
    Entry[] tab = table;
    int len = tab.length;
    int i = key.threadLocalHashCode &amp; (len-1);
    
    // 从hash获取的下标开始，寻找key相等的entry元素清除
    for (Entry e = tab[i];
         e != null;
         e = tab[i = nextIndex(i, len)]) {
        if (e.get() == key) {
            e.clear();
            expungeStaleEntry(i);
            return;
        }
    }
}
</code></pre>
<p>ThreadLocal.remove()核心是调用ThreadLocalMap.remove()方法，流程如下：</p>
<ol>
<li>通过hash计算下标。</li>
<li>从散列表该下标开始往后查key相等的元素，如果找到则做清除操作，引用置为null，GC的时候key就会置为null，然后执行探测式清理处理。</li>
</ol>
<blockquote>
<p>参考地址： <a href="https://javaguide.cn/java/concurrent/threadlocal.html">ThreadLocal详解</a>。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring bean的生命周期]]></title>
        <id>https://q456qq520.github.io/post/spring-bean-de-sheng-ming-zhou-qi/</id>
        <link href="https://q456qq520.github.io/post/spring-bean-de-sheng-ming-zhou-qi/">
        </link>
        <updated>2025-04-28T03:45:03.000Z</updated>
        <content type="html"><![CDATA[<h2 id="什么是-bean">什么是 Bean</h2>
<blockquote>
<p>In Spring, the objects that form the backbone of your application and that are managed by the Spring IoC container are called beans. A bean is an object that is instantiated, assembled, and otherwise managed by a Spring IoC container. Otherwise, a bean is simply one of many objects in your application. Beans, and the dependencies among them, are reflected in the configuration metadata used by a container.</p>
</blockquote>
<p>简而言之，bean 是由 Spring IoC 容器实例化、组装和管理的对象。</p>
<h2 id="什么是-spring-bean-的生命周期">什么是 Spring Bean 的生命周期</h2>
<p>对于普通的 Java 对象，当 new 的时候创建对象，然后该对象就能够使用了。一旦该对象不再被使用，则由 Java 自动进行垃圾回收。</p>
<p>而 Spring 中的对象是 bean，bean 和普通的 Java 对象没啥大的区别，只不过 Spring 不再自己去 new 对象了，而是由 IoC 容器去帮助我们实例化对象并且管理它，我们需要哪个对象，去问 IoC 容器要即可。IoC 其实就是解决对象之间的耦合问题，Spring Bean 的生命周期完全由容器控制。</p>
<h2 id="bean生命周期">Bean生命周期</h2>
<p>⚠️这里我们说的 Spring Bean 的生命周期主要指的是 singleton bean，对于 prototype 的 bean ，Spring 在创建好交给使用者之后则不会再管理后续的生命周期。</p>
<h3 id="bean-的作用域">bean 的作用域</h3>
<ul>
<li>singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。</li>
<li>prototype : 每次请求都会创建一个新的 bean 实例。</li>
<li>request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。</li>
<li>session : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。</li>
<li>global-session： 全局 session 作用域，仅仅在基于 Portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码（例如：HTML）片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话</li>
</ul>
<h3 id="spring-singleton-bean-的生命周期">Spring Singleton Bean 的生命周期</h3>
<ol>
<li>实例化 Instantiation</li>
<li>属性赋值 Populate</li>
<li>初始化 Initialization</li>
<li>销毁 Destruction</li>
</ol>
<p>实例化 -&gt; 属性赋值 -&gt; 初始化 -&gt; 销毁</p>
<blockquote>
<p>Bean实例化的时机也分为两种，BeanFactory管理的Bean是在使用到Bean的时候才会实例化Bean，ApplicantContext管理的Bean在容器初始化的时候就会完成Bean实例化。</p>
</blockquote>
<blockquote>
<p>“实例化”和“初始化”是两个完全不同的过程，千万不要搞混，实例化只是给 Bean 分配了内存空间，而初始化则是将程序的执行权，从系统级别转换到用户级别，并开始执行用户添加的业务代码。</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1745812173127.png" alt="" loading="lazy"></figure>
<p>Bean实例化前后，可以进行一些处理，但是如果从Bean实例化前算开始，那么就要追溯到容器的初始化、beanDefiinition的加载开始。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1745812261215.png" alt="" loading="lazy"></figure>
<ol>
<li>实例化：第 1 步，实例化一个 Bean 对象</li>
<li>属性赋值：第 2 步，为 Bean 设置相关属性和依赖</li>
<li>初始化：初始化的阶段的步骤比较多，5、6步是真正的初始化，第 3、4 步为在初始化前执行，第 7 步在初始化后执行，初始化完成之后，Bean就可以被使用了</li>
<li>销毁：第 8~10步，第8步其实也可以算到销毁阶段，但不是真正意义上的销毁，而是先在使用前注册了销毁的相关调用接口，为了后面第9、10步真正销毁 Bean 时再执行相应的方法</li>
</ol>
<h3 id="spring-singleton-bean-的生命周期详解">Spring Singleton Bean 的生命周期详解</h3>
<h4 id="docreatebean">doCreateBean</h4>
<pre><code class="language-java">protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException {
    BeanWrapper instanceWrapper = null;
    if (mbd.isSingleton()) {
        instanceWrapper = (BeanWrapper)this.factoryBeanInstanceCache.remove(beanName);
    }

    if (instanceWrapper == null) {
        // 实例化阶段
        instanceWrapper = this.createBeanInstance(beanName, mbd, args);
    }

    ...

    Object exposedObject = bean;

    try {
        // 属性赋值阶段
        this.populateBean(beanName, mbd, instanceWrapper);
        // 初始化阶段
        exposedObject = this.initializeBean(beanName, exposedObject, mbd);
    } catch (Throwable var18) {
        ...
    }

    ...
}
</code></pre>
<p>至于销毁，是在容器关闭时调用的，详见<code>ConfigurableApplicationContext#close()</code></p>
<h4 id="createbeaninstance">createBeanInstance</h4>
<pre><code class="language-java">protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) {
		//首先确保bean 已经被解析过
		Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);
        // 如果beanClass 不是public 类型，那么就 抛出异常，提示   non-public access not allowed
		if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) {
			throw new BeanCreationException(mbd.getResourceDescription(), beanName,
					&quot;Bean class isn't public, and non-public access not allowed: &quot; + beanClass.getName());
		}
        // 如果存在，就返回一个  callback回调函数，在 obtainFromSupplier 方法里面
        //调用对应的具体方法 ，并转换成 BeanWrapper 类型
		Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier();
		if (instanceSupplier != null) {
		   // 这里转换成 BeanWrapper  类型
			return obtainFromSupplier(instanceSupplier, beanName);
		}
        // 如果存在对应的工厂方法，那么就使用工厂方法进行初始化
		if (mbd.getFactoryMethodName() != null) {
			return instantiateUsingFactoryMethod(beanName, mbd, args);
		}

		// Shortcut when re-creating the same bean...
		boolean resolved = false;
		boolean autowireNecessary = false;
		if (args == null) {
			synchronized (mbd.constructorArgumentLock) {
			//一个类有多个构造函数，每个构造商数都有不同的参数,所以调用前前需要先根据参数锁定构 
            //边的数或对应的工厂方法 
				if (mbd.resolvedConstructorOrFactoryMethod != null) {
				    // 设置 已经解析
					resolved = true;
					autowireNecessary = mbd.constructorArgumentsResolved;
				}
			}
		}
		//如果已经解析过则使用解析好的构造函数方法，不用再次锁定 
		if (resolved) {
		    // 构造函数参数都已经解析完
			if (autowireNecessary) {
			    // 使用构造函数自动注入
				return autowireConstructor(beanName, mbd, null, null);
			}
			else {
      			//使用其默认构造函数实例化给定的bean
				return instantiateBean(beanName, mbd);
			}
		}

		// Candidate constructors for autowiring?
		// 如果上面没有解析好对应的构造函数， 这里看看有没有指定构造函数
		/**
		  具体里面其实 是 SmartInstantiationAwareBeanPostProcessor , 这个类 继承了
		  InstantiationAwareBeanPostProcessor， 调用里面的determineCandidateConstructors 方法 
		  来确认有没有指定的构造函数
		*/
		Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);
		if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR ||
				mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) {
			// 构造函数自动注入
			return autowireConstructor(beanName, mbd, ctors, args);
		}

		// 获取确定用于默认构造的首选构造函数（如果有）。 如有必要，构造函数参数将自动装配。
		ctors = mbd.getPreferredConstructors();
		if (ctors != null) {
			return autowireConstructor(beanName, mbd, ctors, null);
		}

		// 默认使用无参构造函数
		return instantiateBean(beanName, mbd);
	}
</code></pre>
<h4 id="populatebean">populateBean</h4>
<pre><code class="language-java"> protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {
    if (bw == null) {
       // 如果beanWrapper为空，说明bean实例为null，需要跳过property值的设置
       // 但是如果beanWrapper为空而且mbd.hasPropertyValues()为true，说明bean实例为null，bean定义中存在property值，需要抛出异常
       if (mbd.hasPropertyValues()) {
          throw new BeanCreationException(
                mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;);
       }
       else {
          // Skip property population phase for null instance.
          return;
       }
    }
 ​
    // 如果Bean是记录类型，那么Spring将跳过属性填充阶段，因为记录类型的属性是不可变的，无法进行属性注入
    if (bw.getWrappedClass().isRecord()) {
       if (mbd.hasPropertyValues()) {
          throw new BeanCreationException(
                mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to a record&quot;);
       }
       else {
          // Skip property population phase for records since they are immutable.
          return;
       }
    }
 ​
    // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the
    // state of the bean before properties are set. This can be used, for example,
    // to support styles of field injection.
    // 在设置属性之前，让任何InstantiationAwareBeanPostProcessors都有机会修改bean的状态。例如，这可以用于支持现场注入的样式。
    if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {
       for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) {
          if (!bp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {
             return;
          }
       }
    }
 ​
    // 属性填充值
    PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null);
 ​
    // 自动装配类型 byName byType
    int resolvedAutowireMode = mbd.getResolvedAutowireMode();
    if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) {
       // 根据pvs 封装属性值
       MutablePropertyValues newPvs = new MutablePropertyValues(pvs);
       // Add property values based on autowire by name if applicable.
       if (resolvedAutowireMode == AUTOWIRE_BY_NAME) {
          // 添加属性值，根据byName
          autowireByName(beanName, mbd, bw, newPvs);
       }
       // Add property values based on autowire by type if applicable.
       if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) {
          // 添加属性值，根据byType
          autowireByType(beanName, mbd, bw, newPvs);
       }
       pvs = newPvs;
    }
    // 此工厂是否持有InstantiationAwareBeanPostProcessor后置处理器
    if (hasInstantiationAwareBeanPostProcessors()) {
       if (pvs == null) {
          pvs = mbd.getPropertyValues();
       }
       // 遍历后置处理器，如果返回非空的PropertyValues，将pvs更新为返回的PropertyValues
       for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) {
          PropertyValues pvsToUse = bp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);
          if (pvsToUse == null) {
             return;
          }
          pvs = pvsToUse;
       }
    }
 ​
    boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE);
    if (needsDepCheck) {
       PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);
       checkDependencies(beanName, mbd, filteredPds, pvs);
    }
 ​
    if (pvs != null) {
       // 将属性应用到 bean 中
       applyPropertyValues(beanName, mbd, bw, pvs);
    }
 }
</code></pre>
<h4 id="initializebean">initializeBean</h4>
<p>如果bean实现了InitializingBean接口，那么initializeBean会调用bean的afterPropertiesSet方法。这个方法在bean的属性初始化后会被执行。</p>
<p>如果在配置文件中通过init-method或注解指定了初始化方法，那么initializeBean会调用这个方法。</p>
<pre><code class="language-java"> protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) {
    //用于执行BeanNameAware、BeanClassLoaderAware和BeanFactoryAware等Aware回调方法
    invokeAwareMethods(beanName, bean);
 ​
    Object wrappedBean = bean;
    // 如果mbd不为空并且不是合成bean，则执行BeanPostProcessor的beforeInitialization方法
    // 这里明明是mbd == null，为什么要解释成不为空呢，下面会有解释
    if (mbd == null || !mbd.isSynthetic()) {
       wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);
    }
 ​
    try {
       // 执行bean的初始化方法
       invokeInitMethods(beanName, wrappedBean, mbd);
    }
    catch (Throwable ex) {
       throw new BeanCreationException(
             (mbd != null ? mbd.getResourceDescription() : null), beanName, ex.getMessage(), ex);
    }
    // 如果bean定义不存在或者bean不是合成的，则调用applyBeanPostProcessorsAfterInitialization方法，对bean进行初始化后的后处理器。
    if (mbd == null || !mbd.isSynthetic()) {
       wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);
    }
 ​
    return wrappedBean;
 }

</code></pre>
<h2 id="什么是循环依赖">什么是循环依赖</h2>
<p>循环依赖就是循环引用，就是两个或多个 bean 相互之间的持有对方，比如 TestA 引用 TestB，TestB 引用 TestC，TestC引用 TestA，则他们最终会形成一个闭环。</p>
<h3 id="spring-是如何解决循环依赖的">Spring 是如何解决循环依赖的</h3>
<h4 id="构造器循环依赖">构造器循环依赖</h4>
<ol>
<li>表示通过构造器注入构成的循环依赖，此依赖是无法解决的，只能拋出 BeanCurcenlylCreationException 异常表示循环依赖</li>
<li>如在创建 TestA类时，构造器需要 TestB 类，那将去创建 TestB，在创建 TestB 类时又发现需要 TestC 类，则又去创建TestC，最终在创建 TestC 时发现又需要 TestA，从而形成一个环，没办法创建。</li>
<li>Spring 容器将每一个正在创建的 bean 标识符放在一个当前创建 bean 池中，bean标识符在创建过程中将一直保持在这个池中，因此如果在创建 bean 过程中发现自己已经在当的创建bean 池里时，将抛出 BeanCurrentlyInCreationException 异常表示循环依赖；而对于创建完毕的bean 将从当前创建bean池中清除掉。</li>
</ol>
<h4 id="setter-循环依赖">setter 循环依赖</h4>
<p>表示通过 setter 注入方式构成的循环依赖。对于 setter 注人造成的依赖是通过 Spring 容器提前暴露刚完成构造器注入但未完成其他步骤（如 setter 注入）的bean来完成的，而且只能解决单例作用域的bean 循环依赖。通过提前暴露一个单例工厂方法，从而使其他 bean 能引用到该bean。</p>
<ol>
<li>Spring 容器创建单例 testA bean，首先根据无参构造器创建 bean，并暴露一个ObjectFactory用于返回一个提前暴露一个创建中的bean，并将testA 标识符放到当前创建bean 池，然后进行 setter 注入testB。</li>
<li>Spring 容器创建单例 testB bean，首先根据无参构造器创建 bean，并暴露一个ObjectFactory用于返回一个提前暴露一个创建中的 bean，并将testB 标识符放到当前创建 bean池，然后进行 setter 注入testC。</li>
<li>Spring 容器创建单例 testC bean，首先根据无参构造器创建 bean，并暴露一个ObjectFactory用于返回一个提前暴露一个创建中的 bean，并将testC 标识符放到当前创建 bean池，然后进行 setter 注入testA。进行注入testA 时由于提前暴露了ObjectFactory工厂，从而使用它返回提前暴露一个创建中的bean。</li>
<li>最后在依赖注入testB 和 testA，完成 setter 注入。</li>
<li>对于单例 bean 来说，可以通过 setAllowCircularRefernces(false)来禁用循环引用</li>
</ol>
<h3 id="三级缓存">三级缓存</h3>
<p>第⼀级缓存：singletonObjects，⽤于保存实例化、注⼊、初始化完成的 bean 实例；<br>
第⼆级缓存：earlySingletonObjects，⽤于保存实例化完成的 bean 实例；<br>
第三级缓存：singletonFactories，⽤于保存 bean 创建⼯⼚，以便后⾯有机会创建代理对象。</p>
<pre><code class="language-java">/** Cache of singleton objects: bean name --&gt; bean instance */
/** 一级缓存：用于存放完全初始化好的 bean **/
private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);
 
/** Cache of early singleton objects: bean name --&gt; bean instance */
/** 二级缓存：存放原始的 bean 对象（尚未填充属性），用于解决循环依赖 */
private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);

/** Cache of singleton factories: bean name --&gt; ObjectFactory */
/** 三级级缓存：存放 bean 工厂对象，用于解决循环依赖 */
private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);

</code></pre>
<h3 id="getsingleton方法中三级缓存的使用">getSingleton方法中三级缓存的使用</h3>
<pre><code class="language-java">protected Object getSingleton(String beanName, boolean allowEarlyReference) {
  // Spring首先从singletonObjects（一级缓存）中尝试获取
  Object singletonObject = this.singletonObjects.get(beanName);
  // 若是获取不到而且对象在建立中，则尝试从earlySingletonObjects(二级缓存)中获取
  if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {
    synchronized (this.singletonObjects) {
        singletonObject = this.earlySingletonObjects.get(beanName);
        if (singletonObject == null &amp;&amp; allowEarlyReference) {
          ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);
          if (singletonFactory != null) {
            //若是仍是获取不到而且允许从singletonFactories经过getObject获取，则经过singletonFactory.getObject()(三级缓存)获取
              singletonObject = singletonFactory.getObject();
              //若是获取到了则将singletonObject放入到earlySingletonObjects,也就是将三级缓存提高到二级缓存中
              this.earlySingletonObjects.put(beanName, singletonObject);
              this.singletonFactories.remove(beanName);
          }
        }
    }
  }
  return (singletonObject != NULL_OBJECT ? singletonObject : null);
}
</code></pre>
<p>三级缓存的使用过程如下</p>
<ol>
<li>Spring 会先从一级缓存 singletonObjects 中尝试获取 Bean。</li>
<li>若是获取不到，而且对象正在建立中，就会尝试从二级缓存 earlySingletonObjects 中获取 Bean。</li>
<li>若还是获取不到，且允许从三级缓存 singletonFactories 中经过 singletonFactory 的 getObject() 方法获取 Bean 对象，就会尝试从三级缓存 singletonFactories 中获取 Bean。</li>
<li>若是在三级缓存中获取到了 Bean，会将该 Bean 存放到二级缓存中。</li>
</ol>
<h3 id="为什么要三级缓存">为什么要三级缓存?</h3>
<p>二级缓存也是可以解决循环依赖的。为什么 Spring 不选择二级缓存，而要额外多添加一层缓存，使用三级缓存呢？</p>
<p>如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。</p>
<p>使用三级缓存而非二级缓存并不是因为只有三级缓存才能解决循环引用问题，其实二级缓存同样也能很好解决循环引用问题。使用三级而非二级缓存并非出于 IOC 的考虑，而是出于 AOP 的考虑，即若使用二级缓存，在 AOP 情形注入到其他 Bean的，不是最终的代理对象，而是原始对象。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql物化和半连接]]></title>
        <id>https://q456qq520.github.io/post/mysql-wu-hua-he-ban-lian-jie/</id>
        <link href="https://q456qq520.github.io/post/mysql-wu-hua-he-ban-lian-jie/">
        </link>
        <updated>2025-04-23T02:28:17.000Z</updated>
        <content type="html"><![CDATA[<h2 id="物化materialization">物化（Materialization）</h2>
<p>物化应该是指将子查询的结果存储到一个临时表中，这样后续的查询可以直接使用这个临时表，而不需要每次都重新执行子查询。这样可以减少重复计算，尤其是在子查询结果集较大的情况下，可能提高性能。</p>
<h3 id="适用场景">适用场景：</h3>
<ol>
<li>非相关子查询：子查询不依赖外层查询的值，可以独立执行并缓存结果。</li>
<li>子查询结果集较大：如果子查询返回的结果集较大，物化可以避免重复计算，提高效率。</li>
<li>需要多次访问子查询结果：例如子查询被用于JOIN或WHERE条件多次时，物化临时表可以复用。</li>
<li>子查询复杂度高：若子查询包含聚合、排序或复杂过滤（如GROUP BY, DISTINCT），物化可减少计算开销。</li>
</ol>
<h3 id="示例">示例</h3>
<pre><code>SELECT * FROM customers 
WHERE id IN (SELECT customer_id FROM orders WHERE amount &gt; 100);
</code></pre>
<p>若子查询SELECT customer_id FROM orders的结果集大且无索引，优化器可能物化结果到临时表，再与customers表JOIN。</p>
<p>优化提示：</p>
<p>使用SUBQUERY提示强制物化：</p>
<pre><code>SELECT /*+ SUBQUERY(MATERIALIZATION) */ * FROM customers ...;
</code></pre>
<h2 id="半连接">半连接</h2>
<p>半连接通常用于存在性检查，比如使用IN或者EXISTS子句时。半连接和普通连接的不同之处在于，半连接只需要返回外层表中存在匹配的记录，而不会返回多条匹配记录导致重复。</p>
<h3 id="适用场景-2">适用场景：</h3>
<ol>
<li>存在性检查：使用IN或EXISTS时，只需判断外层记录是否存在匹配，无需返回所有匹配项。</li>
<li>相关子查询：子查询依赖外层查询的值，需逐行判断。</li>
<li>索引可用性高：若子查询字段有索引（如customer_id上的索引），半连接可通过索引快速定位匹配项。</li>
<li>结果集较小：子查询结果集较小时，半连接避免物化开销，直接通过索引高效匹配。</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM departments d 
WHERE EXISTS (SELECT 1 FROM employees e WHERE e.dept_id = d.id);
</code></pre>
<p>若employees.dept_id有索引，优化器可能选择半连接策略，仅检查是否存在匹配记录。</p>
<p>优化提示：</p>
<p>使用SEMIJOIN提示强制半连接策略：</p>
<pre><code>SELECT /*+ SEMIJOIN(DUPSWEEDOUT) */ * FROM departments ...;
</code></pre>
<h2 id="关键选择因素">关键选择因素</h2>
<table>
<thead>
<tr>
<th>因素</th>
<th>物化</th>
<th>半连接</th>
</tr>
</thead>
<tbody>
<tr>
<td>子查询相关性</td>
<td>非相关子查询</td>
<td>相关或非相关子查询</td>
</tr>
<tr>
<td>结果集大小</td>
<td>大结果集</td>
<td>小结果集</td>
</tr>
<tr>
<td>索引情况</td>
<td>无高效索引时更优</td>
<td>子查询字段有索引时更优</td>
</tr>
<tr>
<td>执行频率</td>
<td>结果需多次访问时更优</td>
<td>单次存在性检查更优</td>
</tr>
<tr>
<td>资源消耗</td>
<td>占用临时表空间</td>
<td>通常内存友好</td>
</tr>
</tbody>
</table>
<h3 id="调试与优化建议">调试与优化建议</h3>
<ol>
<li>使用EXPLAIN分析：通过执行计划查看优化器选择的策略（如MATERIALIZED或SEMIJOIN）。</li>
<li>强制策略：通过优化器提示（如/*+ SEMIJOIN(...) */）干预选择。</li>
<li>索引优化：为子查询字段添加索引，提升半连接效率。</li>
<li>权衡资源：物化可能占用更多内存/磁盘，需根据系统资源调整。</li>
</ol>
<p>总结：非相关大结果集优先物化，相关或索引友好场景选半连接，结合EXPLAIN和实际性能测试进行调优。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HTTPS]]></title>
        <id>https://q456qq520.github.io/post/https-qing-qiu-jie-duan-fen-xi/</id>
        <link href="https://q456qq520.github.io/post/https-qing-qiu-jie-duan-fen-xi/">
        </link>
        <updated>2024-04-10T06:15:39.000Z</updated>
        <content type="html"><![CDATA[<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=2022147586&auto=1&height=66"></iframe>
<h2 id="1-请求阶段分析">1. 请求阶段分析</h2>
<p>一个完整、无任何缓存、未复用连接的 HTTPS 请求需要经过以下几个阶段：DNS 域名解析、TCP 握手、SSL 握手、服务器处理、内容传输。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1712729855422.png" alt="" loading="lazy"></figure>
<h2 id="2-请求阶段耗时分析">2. 请求阶段耗时分析</h2>
<p>HTTPS 请求的各个阶段可以使用 curl 命令进行详细的耗时分析[2]。如表 2-2 所示， curl 提供了详细的耗时分析选项，这样我们就可以更准确地掌握每一个环节的消耗时间，进一步提升网络优化的效率和精度。</p>
<p>表-网络请求阶段分析</p>
<table>
<thead>
<tr>
<th>请求阶段</th>
<th>释义</th>
</tr>
</thead>
<tbody>
<tr>
<td>time_namelookup</td>
<td>从请求开始到域名解析完成的耗时</td>
</tr>
<tr>
<td>time_connect</td>
<td>从请求开始到 TCP 三次握手完成耗时</td>
</tr>
<tr>
<td>time_appconnect</td>
<td>从请求开始到 TLS 握手完成的耗时</td>
</tr>
<tr>
<td>time_pretransfer</td>
<td>从请求开始到向服务器发送第一个 GET/POST 请求开始之前的耗时</td>
</tr>
<tr>
<td>time_redirect</td>
<td>重定向时间，包括到内容传输前的重定向的 DNS 解析、TCP 连接、内容传输等时间</td>
</tr>
<tr>
<td>time_starttransfer</td>
<td>从请求开始到内容传输前的时间</td>
</tr>
<tr>
<td>time_total</td>
<td>从请求开始到完成的总耗时</td>
</tr>
</tbody>
</table>
<p>对一个接口使用 curl 测试：</p>
<pre><code class="language-java">$ curl -w '\n time_namelookup=%{time_namelookup}\n time_connect=%{time_connect}\n time_appconnect=%{time_appconnect}\n time_redirect=%{time_redirect}\n time_pretransfer=%{time_pretransfer}\n time_starttransfer=%{time_starttransfer}\n time_total=%{time_total}\n' -o /dev/null -s 'https://www.thebyte.com.cn/'
// 输出的结果
time_namelookup=0.025021
time_connect=0.033326
time_appconnect=0.071539
time_redirect=0.000000
time_pretransfer=0.071622
time_starttransfer=0.088528
time_total=0.088744
</code></pre>
<blockquote>
<p>curl 操作参见 https://catonmat.net/cookbooks/curl ↩︎</p>
</blockquote>
<h2 id="3-域名解析环节实践">3. 域名解析环节实践</h2>
<h3 id="31-域名解析的工作原理">3.1 域名解析的工作原理</h3>
<p>域名解析靠的是 DNS，我们在浏览器输入一个域名时，DNS 负责将该域名解析为相应的 IP 地址，以便后续与目标服务器建立 TCP/IP 连接。探寻 DNS 工作原理之前，我们先了解域名的结构。如图 2-3 所示，域名是一种树状结构，最顶层的域名是根域名（注意是一个点“.”，它是 .root 的含义），然后是顶级域名（top-level domain，简写 TLD），再是一级域名、二级域名、三级域名。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1712731210190.webp" alt="" loading="lazy"></figure>
<p><strong>DNS 解析流程</strong></p>
<ol>
<li>用户向 DNS 解析器（也称为递归解析器，例如电信运营商的 114.114.114.114）发出解析 example.com 域名请求。</li>
<li>DNS解析器 判断是否存在解析缓存，如存在返回缓存结果。如无则就近向 Root nameserver (根域名服务器)请求所属 TLD 域名服务器。</li>
<li>获取 com.域的 TLD 域名服务器后， 向该地址请求 example.com. 的 权威解析服务器（Authoritative nameserver）。</li>
<li>得到权威解析服务器地址后，向该服务获取域名对应的 IP 地址，域名解析过程结束。</li>
</ol>
<h3 id="32-dns-故障排查">3.2 DNS 故障排查</h3>
<ol>
<li>使用 nslookup 命令<br>
第一个介绍的是 nslookup 命令，该命令用于查询 DNS 的记录、域名解析是否正常等。</li>
</ol>
<p>nslookup 命令示例：</p>
<pre><code class="language-java">$ nslookup thebyte.com.cn        
Server:		8.8.8.8
Address:	8.8.8.8#53

Non-authoritative answer:
Name:	thebyte.com.cn
Address: 110.40.229.45
</code></pre>
<p>第一行的 Server 为当前使用的 DNS解析器。<br>
Non-authoritative answer 因为 DNS 解析器只是转发权威解析服务器的记录，所以为非权威应答。<br>
Address 为解析结果，上面的解析可以看到是一个A记录 110.40.229.45。</p>
<ol start="2">
<li>使用 dig 命令<br>
nslookup 返回的结果比较简单，如果想获取更多的信息，可以尝试使用 dig 命令。</li>
</ol>
<p>dig命令示例：</p>
<pre><code class="language-java">$ dig thebyte.com.cn

; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; thebyte.com.cn
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63697
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;thebyte.com.cn.			IN	A

;; ANSWER SECTION:
thebyte.com.cn.		599	IN	A	110.40.229.45

;; Query time: 14 msec
;; SERVER: 8.8.8.8#53(8.8.8.8)
;; WHEN: Fri May 12 15:22:33 CST 2023
;; MSG SIZE  rcvd: 59
</code></pre>
<p>第一段 opcode 为 QUERY，表示执行查询操作，status 为 NOERROR，表示解析成功。<br>
第二段 QUESTION SECTION 部分显示了发起的 DNS 请求参数，A 表示我们默认查询 A 类型记录。<br>
第三段 ANSWER SECTION 部分为 DNS 查询结果，可以看到 thebyte.com.cn. 的解析结果为 110.40.229.45。<br>
最后一段为查询所用的DNS解析器、耗时等信息。</p>
<h2 id="4-http-请求优化">4. HTTP 请求优化</h2>
<ul>
<li>包体积优化：传输数据的包体大小与传输耗时成正相关，压缩算法是减小包体的最有效手段(没有之一)。</li>
<li>SSL 层优化：升级 TLS 算法以及 HTTPS 证书，降低 SSL 层的性能消耗。</li>
<li>传输层优化：升级拥塞控制算法（例如由默认的 Cubic 升级为 BBR 算法）提升数据传输效率。</li>
<li>网络层优化：使用一些商业网络加速服务，在网络层对数据包进行路由优化，实现动态服务加速。</li>
<li>使用更现代的 HTTP 协议：升级至 HTTP/2，进一步可以使用 QUIC。</li>
</ul>
<h3 id="41-对传输内容进行压缩">4.1 对传输内容进行压缩</h3>
<p>所有的现代浏览器、客户端及 HTTP 服务器软件都支持压缩技术，唯一需要协商的是客户端与服务端所采用的压缩算法。</p>
<p>为了选择采用的压缩算法，HTTP 客户端和服务器之间会使用主动协商机制：HTTP 客户端发送 Accept-Encoding 首部（其中包含它所支持的压缩算法，以及各自的优先级），服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知 HTTP 客户端它选择了哪一种算法。</p>
<h2 id="5-https-原理及-ssl-层优化实践">5. HTTPS 原理及 SSL 层优化实践</h2>
<p>HTTPS 是什么？简单理解就是 HTTP+SSL/TLS。</p>
<h3 id="51-理解-https-流程">5.1 理解 HTTPS 流程</h3>
<p>HTTP 添加 SSL 层的本质是为了实现信息传递“绝对”的安全性。</p>
<p>如图，如果是一个 1 v 1 的通信模型，想实现信息传递安全性，使用对称加密就可以。只要保证密钥不被第三者知道，信息传递的安全问题就能解决！</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1712731764166.png" alt="" loading="lazy"></figure>
<p>但是，对称加密方式在 HTTP 场景下就出现问题了。如图所示，对称加密的关键操作是如何保证秘钥的安全性，而 HTTP 通信模型是 1 v N，使用对称加密这种方式等同没有加密。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1712731768876.png" alt="" loading="lazy"></figure>
<p>为了解决秘钥暴露的问题，我们使每个客户端使用不同的算法/密钥，并再增加一个协商的过程，用于确定双方采用哪一种加密算法/密钥（这个协商的过程就是 TLS 协议做的事情）<br>
<img src="https://q456qq520.github.io/post-images/1712731829129.png" alt="" loading="lazy"></p>
<p>不过问题还是存在，协商过程解决了对称加密算法或秘钥独立性问题，但协商过程依旧是明文的，密钥依然存在被截获的可能性。</p>
<p>解决这个问题就必须换一种思路，只使用对称加密就会陷入“无限套娃”的死胡同。我们引入一个新的概念：非对称加密算法。</p>
<blockquote>
<p>非对称加密有两个密钥：公钥、私钥，私钥加密的密文只能公钥解，公钥加密的密文只能私钥解。</p>
</blockquote>
<p>由于对称加解密效率远比非对称加解密效率高得多，所以我们这样：</p>
<ol>
<li>对 HTTP 内容使用对称加密</li>
<li>协商流程中，通过一个随机数确定对称加密算法/密钥，然后使用非对称加密算法的私钥对其加密。</li>
<li>客户端先公钥解密获得对称加密的密钥，再用该密钥解密 HTTP 内容，从而获得明文。</li>
</ol>
<h5 id="证书认证机构">证书认证机构</h5>
<p>如果服务端直接发送公钥证书给客户端，仍然无法避免中间被截获的可能性。</p>
<p>此时，我们引入一个双方都信任的第三方机构，使用第三方机构的私钥将服务器公钥加密后传输给客户端，客户端再使用第三方公钥（内置在本地）进行解密。虽然流程绕了些，但至少离我们的目标”绝对“安全又近了些。</p>
<p>这个双方都信任的机构就是 HTTPS 中的 CA（CA，Certificate Authority，证书认证机构）。</p>
<p>HTTPS 中把公钥规范成数字证书的形式由 CA 签发（数字证书通常包含服务端公钥、持有者信息、CA 的信息以及过期信息等）。服务端向 CA 申请数字证书，再把数字证书下发给客户端。至于第三方 CA 公钥的问题，解决方案就是提前预装在系统内，这就是系统内根证书的由来。</p>
<p>总结 HTTPS 的通信逻辑如下：<br>
<img src="https://q456qq520.github.io/post-images/1712732068028.svg" alt="" loading="lazy"></p>
<ol>
<li>服务端向 CA 机构申请证书，</li>
<li>客户端请求服务端时，服务端向客户端下发证书</li>
<li>客户端根据本地根证书校验服务端的证书</li>
<li>客户端拿到证书的内公钥，加密之后传递服务端，服务端用本地的私钥进行解密获取正文。</li>
</ol>
<h3 id="52-ssl-层优化实践">5.2 SSL 层优化实践</h3>
<p>HTTPS 建立连接的过程中，TLS 握手阶段最长可以花费 2-RTT，除去握手延迟外，SSL 层还有其他的一些隐形消耗，不做任何优化措施情况下，网络耗时和加解密耗时影响会让 HTTPS 连接效率比 HTTP 慢上几百毫秒，在高延迟网络环境下，HTTPS 延迟问题更加明显。</p>
<h5 id="协议升级">协议升级</h5>
<p>优化 SSL 层，效果最为明显的方式是升级最新 TLS1.3 协议[1]。TLS 1.3 协议放弃了安全性较低的加密功能的支持，并改进了 TLS 握手流程。TLS 1.3 协议中的 TLS 握手只需要一次 RTT 而不是两次，如果客户端复用之前连接，TLS 握手的往返次数可以为零，这使 HTTPS 连接更快，能显著减少延迟并改善用户体验。如图所示，如果使用 TLS 1.2 需要两次往返（ 2-RTT ）才能完成握手，然后才能发送请求。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1712732331870.png" alt="" loading="lazy"></figure>
<p>相比 TLS1.2 协议，TLS 1.3 协议的握手时间减半，如图所示。这意味着访问一个网站，使用 TLS 1.3 协议，会降低将近 100ms 的延时。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1712732336578.png" alt="" loading="lazy"></figure>
<h5 id="证书优化">证书优化</h5>
<p>SSL 层中的证书验证也是一个比较耗时的环节：服务器需要把自己的证书链全发给客户端，客户端接收后再逐一验证。证书环节我们关注两个方面优化：<strong>证书传输优化</strong> 、** 证书中非对称算法升级 **。</p>
<p>客户端在验证证书过程中，需要判断当前证书状态，是否被撤销/过期等，需要再去访问 CA 下载 CRL 或者 OCSP 数据，这又会产生 DNS 查询、建立连接、收发数据等一系列网络通信，增加多个 RTT。</p>
<blockquote>
<p>TIP<br>
CRL（Certificate Revocation List）证书撤销列表，是由 CA 机构维护的一个列表，列表中包含已经被吊销的证书序列号和吊销时间。<br>
OCSP（Online Certificate Status Protocol）在线证书状态协议，是一种改进的证书状态确认方法，用于减轻证书吊销检查的负载和提高数据传输的私密性，相比于 CRL ，OCSP提供了实时验证证书状态的能力。<br>
OCSP Stapling 是 OCSP 的改进方案，将原本需要客户端实时发起的 OCSP 请求转嫁给服务端，服务端通过预先访问 CA 获取 OCSP 响应，然后在握手时随着证书一起发给客户端，免去了客户端连接 CA 服务器查询的环节，解决了 OCSP 的隐私和性能问题。</p>
</blockquote>
<ol>
<li>在 Nginx 中配置 OCSP Stapling 服务。</li>
</ol>
<pre><code class="language-Nginx">server {
    listen 443 ssl;
    server_name  thebyte.com.cn;
    index index.html;

    ssl_certificate         server.pem;#证书的.cer文件路径
    ssl_certificate_key     server-key.pem;#证书的.key文件

    # 开启 OCSP Stapling 当客户端访问时 NginX 将去指定的证书中查找 OCSP 服务的地址，获得响应内容后通过证书链下发给客户端。
    ssl_stapling on;
    ssl_stapling_verify on;# 启用OCSP响应验证，OCSP信息响应适用的证书
    ssl_trusted_certificate /path/to/xxx.pem;# 若 ssl_certificate 指令指定了完整的证书链，则 ssl_trusted_certificate 可省略。
    resolver 8.8.8.8 valid=60s;# 添加resolver解析OSCP响应服务器的主机名，valid表示缓存。
    resolver_timeout 2s;# resolver_timeout表示网络超时时间
}
</code></pre>
<ol start="2">
<li>检查服务端是否已开启 OCSP Stapling。</li>
</ol>
<pre><code class="language-yml">openssl s_client -connect thebyte.com.cn:443 -servername thebyte.com.cn -status -tlsextdebug &lt; /dev/null 2&gt;&amp;1 | grep &quot;OCSP&quot; 
</code></pre>
<p>若结果中存在”successful“，则表示已开启 OCSP Stapling 服务。</p>
<pre><code class="language-yml">OCSP response:
OCSP Response Data:
    OCSP Response Status: successful (0x0)
    Response Type: Basic OCSP Response
</code></pre>
<h5 id="证书算法优化">证书算法优化</h5>
<p>目前 SSL 密钥交换 + 签名有三种主流的方式：</p>
<ul>
<li>RSA 密钥交换（无需签名）。</li>
<li>ECDHE 密钥交换、RSA 签名。</li>
<li>ECDHE 密钥交换、ECDSA 签名。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transactional与锁]]></title>
        <id>https://q456qq520.github.io/post/transactional-yu-suo/</id>
        <link href="https://q456qq520.github.io/post/transactional-yu-suo/">
        </link>
        <updated>2024-01-31T08:42:43.000Z</updated>
        <content type="html"><![CDATA[<p>https://www.cnblogs.com/thisiswhy/p/15175380.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[计算机网络（一）]]></title>
        <id>https://q456qq520.github.io/post/ji-suan-ji-wang-luo-yi/</id>
        <link href="https://q456qq520.github.io/post/ji-suan-ji-wang-luo-yi/">
        </link>
        <updated>2023-10-12T09:03:03.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="计算机网络和因特网">计算机网络和因特网</h2>
<h3 id="11-什么是因特网">1.1 什么是因特网</h3>
<h4 id="111-相关组成">1.1.1 相关组成</h4>
<p>所有连接到因特网的设备都称为主机(host)或端系统，端系统通过<code>通信链路</code>和<code>分组交换机</code>连接到一起。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="计算机网络和因特网">计算机网络和因特网</h2>
<h3 id="11-什么是因特网">1.1 什么是因特网</h3>
<h4 id="111-相关组成">1.1.1 相关组成</h4>
<p>所有连接到因特网的设备都称为主机(host)或端系统，端系统通过<code>通信链路</code>和<code>分组交换机</code>连接到一起。</p>
<!-- more -->
<p>通信链路：物理媒体包括同轴电缆、铜线、光纤和无线电频谱。不同的链路能够以不同的速率传输数据，链路的传输速率以比特/秒(bit/s,或bps)度量。当一台端系 统要向另一台端系统发送数据时，发送端系统将数据分段，并为每段加上首部字节。由此 形成的信息包用计算机网络的术语来说称为分组(packet)。这些分组通过网络发送到目的端系统，在那里被装配成初始数据。</p>
<p>分组交换机：两种最著名的类型是路由器和链路层交换机。</p>
<h4 id="112-服务描述">1.1.2 服务描述</h4>
<p>运行在一个端系统上的应用程序怎样才 能指令因特网向运行在另一个端系统上的软件发送数据呢?</p>
<p>与因特网相连的端系统提供了一个<code>套接字接口</code>,该接口规定了运行 在一个端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交 付数据的方式。因特网套接字接口是一套发送程序必须遵循的规则集合，因此因特网能够 将数据交付给目的地。</p>
<h4 id="113什么是协议">1.1.3什么是协议</h4>
<p>在因特网中，涉及两个或多个远程通信实体的所有活动都受协议的制约。</p>
<p><mark>协议</mark> 定义了在两个或多个通信实体之间交换的报文的格式和顺 序，以及报文发送和/或接收一条报文或其他事件所采取的动作。</p>
<h3 id="12-网络边缘">1.2 网络边缘</h3>
<p>与因特网相连的计算机和其他设备因为它们位于因特网的边缘，故而被称为端系统。端系统也称为主机(host),因为它们容纳(即运行)应用程序。主机有时又被进一步划分为两类:客户(client)和服务器(server)。</p>
<h4 id="121-接入网">1.2.1 接入网</h4>
<p>将端系统物理连接到其边缘路由器的网络称为接入网。</p>
<h3 id="13-网络核心">1.3 网络核心</h3>
<h4 id="131-分组交换">1.3.1 分组交换</h4>
<p>在各种网络应用中，端系统彼此交换报文。<br>
为了从源端系统向目的端系统发送一个报文，源将长报文划分为较小的数据块，称之为<code>分组</code>。在源和目的地之间，每个分组都通过通信链路和分组交换机传送。(交换机主要有两类:路由器和链路层交换机)分组以等于该链路最大传输速率的速度传输通过通信链路。</p>
<ol>
<li>
<p>存储转发传输<br>
多数分组交换机在链路的输入端使用存储转发传输机制。</p>
</li>
<li>
<p>排队时延和分组丢失<br>
如果到达的分组需要传输到某条链路，但发现该链路正忙于传输其他分组，该到达分组必须在输出缓存中等待。因此，除了存储转发时延以外，分组还要承受输岀缓存的<mark>排队时延</mark>。因为缓存空间的大小是有限的。在此情况下，将出现分组<mark>丢失(丢包)</mark>,到达的分组或已经排队的分组之一将被丢弃。</p>
</li>
<li>
<p>转发表和路由选择协议<br>
当源主机要向目的端系统发 送一个分组时，源在该分组的首部包含了目的地的IP地址。每台路由器具有一个转发表,用于将目的地址(或目的地址的一部分)映射成为输岀链路。<br>
因特网具有一些特殊的路由选择协议,用于自动地设置这些转发表。</p>
</li>
</ol>
<h4 id="132-电路交换">1.3.2 电路交换</h4>
<p>通过网络链路和交换机移动数据有两种基本方法:电路交换和分组交换</p>
<p>在电路交换网络中，在端系统间通信会话期间，预留了端系统间沿路径通信所需要的 资源(缓存，链路传输速率)。</p>
<ol>
<li>
<p>电路交换网络中的复用<br>
链路中的电路是通过频分复用 ( Frequency- Division Multiplexing, FDM ) 或时分复用 (Time-Division Multiplexing, TDM)来实现的。对于FDM,链路的频谱由跨越链路创建的所有连接共享。特别是，在连接期间链路为每条连接专用一个频段，该频段的宽度称为带宽。</p>
</li>
<li>
<p>分组交换与电路交换的对比<br>
分组交换相比电路交换：提供了比电路交换更好的带宽共享;比电路交换更简单、更有效，实现<br>
成本更低。</p>
</li>
</ol>
<h3 id="14-分组交换网中的时延-丢包和吞吐量">1.4 分组交换网中的时延、丢包和吞吐量</h3>
<h4 id="141分组交换网中的时延概述">1.4.1分组交换网中的时延概述</h4>
<p>当分组从一个节点(主机或路由器)沿着这条路径到后继节 点(主机或路由器)，该分组在沿途的每个节点经受了几种不同类型的时延。这些时延最 为重要的是<code>节点处理时延</code>、<code>排队时延</code>、<code>传输时延</code>和<code>传播时延</code>,这些时延总体累加起来是<mark>节点总时延</mark>。</p>
<p><strong>时延的类型</strong></p>
<ol>
<li>处理时延<br>
检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。</li>
<li>排队时延<br>
在队列中，当分组在链路上等待传输时，它经受排队时延。</li>
<li>传输时延<br>
当所有已经 到达的分组被传输后，才能传输刚到达的分组。用L比特表示该分组的长度，用R bps(即b/s)表示从路由器A到路由器B的链路传输速率。传输时延是L/R</li>
<li>传播时延<br>
一旦一个比特被推向链路，该比特需要向路由器B传播。从该链路的起点到路由器B传播所需要的时间是传播时延。</li>
<li>传输时延和传播时延的比较<br>
传输时延是路由器推出分组所需要的时间，它是分组长度和链路传输速率的函 数，而与两台路由器之间的距离无关。另一方面，传播时延是一个比特从一台路由器传播 到另一台路由器所需要的时间，它是两台路由器之间距离的函数，而与分组长度或链路传输速率无关。</li>
</ol>
<h4 id="142排队时延和丢包">1.4.2排队时延和丢包</h4>
<p>R是传输速率，即从队列中推出比特的速率(以bps即b/s为单 位)。为了简单起见，也假定所有分组都是由L比特组成的。则比特到达队列的平均速率 是La bps。最后，假定该队列非常大，因此它基本能容纳无限数量的比特。比率La/R被称为<mark>流量强度</mark>,它在估计排队时延的范围方面经常起着重要的作用。如果La/R&gt;l,则比特到达队列的平均速率超过从该队列传输岀去的速率。在这种不幸的情 况下，该队列趋向于无限增加，并且排队时延将趋向无穷大!因此，流量工程中的一条金科玉律是:<strong>设计系统时流量强度不能大于1</strong>。</p>
<h5 id="丢包">丢包</h5>
<p>因为排队容量是有限的，随着流量强度接近1,排队时延并不真正趋向无穷大。相反，到达的分组将发现<br>
一个满的队列。由于没有地方存储这个分组，路由器将<mark>丢弃</mark>该分组，即该分组将出会<mark>丢失</mark>。</p>
<p>分组丢失的比例随着流量强度增加而增加。</p>
<h4 id="143端到端时延">1.4.3端到端时延</h4>
<p>总时延 = N台路由器（单台处理时延 + 传输时延 + 传播时延）</p>
<h4 id="144计算机网络中的吞吐量">1.4.4计算机网络中的吞吐量</h4>
<p>假设从主机A到主机B跨越计算机网络传送一个大文件，在任何时间瞬间的<mark>瞬时吞吐量</mark>是主机B接收到该文件的速率(以bps计)。如果该文件由F 比特组成，主机B接收到所有F 比特用去卩秒, 则文件传送的<mark>平均吞吐量</mark>是F/T bps。</p>
<p>吞吐量取决于数据流过的链路的传输速率。当没有其他干扰流量时，其吞吐量能够近似为沿着源和目的地之间路径的最小传输速率。<br>
吞吐量不仅取决于沿着路径的传输速率，而且取决于干扰流量。特别是，如果许多其他的数据流也通过这条链路流动，一条具有高传输速率的链 路仍然可能成为文件传输的瓶颈链路。</p>
<h3 id="15协议层次及其服务模型">1.5协议层次及其服务模型</h3>
<h4 id="151分层的体系结构">1.5.1分层的体系结构</h4>
<h5 id="协议分层">协议分层</h5>
<p>为了给网络协议的设计 提供一个结构，网络设计者以分层的方式组织协议以及实现这些协议的网络硬件和软件，每个协议属于这些层次之一。一个协议层能够用软件、硬件或两者的结合来实现。</p>
<p>各层的所有协议被称为协议栈因特网的协议栈由 5个层次组成:<code>物理层、链路层、网络层、运输层和应用层</code>。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1708935366126.png" alt="" loading="lazy"></figure>
<ol>
<li>应用层<br>
这是网络应用程序及它们的应用层协议存留的地方。因特网的应用层包括许多协议，例如HTTP(它提供了Web文档的请求和 传送)、SMTP (它提供了电子邮件报文的传输)和FTP (它提供两个端系统之间的文件传送)。</li>
</ol>
<p>应用层协议分布在多个端系统上，而一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息分组，这种位于应用层的信息分组称为<mark>报文</mark>。</p>
<ol start="2">
<li>
<p>运输层<br>
因特网的运输层在应用程序端点之间传送应用层报文。<br>
运输层有两种运输协议，即<mark>TCP</mark>和<mark>UDP</mark>,利用其中的任一个都能运输应用层报文。TCP向它的应用程序提供了面向连接的服务。这种服务包括了应用层报文向目的地的确保传递和流量控制(即发送方/接收方速率匹配)。TCP也将长报文划分为短报文，并提供拥塞控制机制，因此当网络拥塞时，源抑制其传输速率。UDP协议向它的应用程序提供无连接服务。这是一种不提供 不必要服务的服务，没有可靠性，没有流量控制，也没有拥塞控制。我们把运输层的分组称为<mark>报文段</mark>。</p>
</li>
<li>
<p>网络层<br>
网络层负责将称为<mark>数据报</mark>的网络层分组从一台主机移动到另一台主机。<br>
网络层包括著名的网际协议IP,该协议定义了在数据报中的各个字段以及端 系统和路由器如何作用于这些字段。IP仅有一个，所有具有网络层的因特网组件必须运行 IP。因特网的网络层也包括决定路由的路由选择协议等。</p>
</li>
<li>
<p>链路层<br>
因特网的网络层通过源和目的地之间的一系列路由器路由数据报。为了将分组从一个 节 点 (主机或路由器)移动到路径上的下一个节点，网络层必须依靠该链路层的服务。特 别是在每个节点，网络层将数据报下传给链路层，链路层沿着路径将数据报传递给下一个节点。在该下一个节点，链路层将数据报上传给网络层。<br>
由链路层提供的服务取决于应用于该链路的特定链路层协议。我们把链路层分组称为<mark>帧</mark>。</p>
</li>
<li>
<p>物理层<br>
物理层的任务是将链路层帧中的一个个比特从一个节点移动到下一个节点。</p>
</li>
</ol>
<h5 id="osi模型">OSI模型</h5>
<p>7层是:应用层、表示层、会话层、运输层、网络层、数据链路层和物理层。</p>
<p>表示层的作用是使通信的应用程序能够解释交换数据的含义。这些服务包括数据压缩和数据加密(它们是自解释的)以及数据描述(这使得应用程序不必担心在各台计算机中表示/ 存储的内部格式不同的问题)。会话层提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。</p>
<h4 id="152-封装">1.5.2 封装</h4>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1708936416720.png" alt="" loading="lazy"></figure>
<p>在发送主机端，一个应用层(M)被传送给运输层。在最简单的情况下,运输层收取到报文并附上附加信息(所谓运输层首部信息，H1),该首部将被接收端的运输层使用。应用层报文和运输层首部信息一道构成了运输层报文段。运输层报文段因此<mark>封装</mark>了应用层报文。</p>
<p>运输层则向网络层传递该报文段，网络层增加了如源和目的端系统地址等网络层首部信息(Hn),生成了网络层数据报。该数据报接下来被传递给链路层，链路层增加它自己的链路层首部信息并生成链路层帧。在每一层，一个分组具有两种类型的字段:首部字段和有效载荷字段。有效载荷通常是来自上一层的分组。</p>
<h2 id="应用层">应用层</h2>
<h3 id="2-1-应用层协议原理">2. 1 应用层协议原理</h3>
<h4 id="2-1-1-网络应用程序体系结构">2. 1. 1 网络应用程序体系结构</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[最佳实践-springboot参数校验效率提升]]></title>
        <id>https://q456qq520.github.io/post/zui-jia-shi-jian-springboot-can-shu-xiao-yan-xiao-lu-ti-sheng/</id>
        <link href="https://q456qq520.github.io/post/zui-jia-shi-jian-springboot-can-shu-xiao-yan-xiao-lu-ti-sheng/">
        </link>
        <updated>2023-07-20T03:03:56.000Z</updated>
        <content type="html"><![CDATA[<h2 id="背景">背景</h2>
<p>随着语法糖或者工具包集成越来越多，现在参数校验已经不需要像往常那样写一大串的ifelse判断逻辑了。</p>
<p>常用的就有springboot中validation的引入大大的减少了工作量。</p>
<p>一般就是在实体类中添加 @NotNull等注解，再在入口处添加@Validated 的方式实现参数校验。这其中其实还可以偷懒，就是利用aop，全局进行参数校验，再统一增强返回，就不需要一个一个的加@Validated 了。</p>
<h2 id="全局参数校验">全局参数校验</h2>
<pre><code class="language-java"> public static &lt;T&gt; void postMethodException(T t) {
        if (t == null) {
            return;
        }
        ValidatorFactory factory = Validation.buildDefaultValidatorFactory();
        Validator validator = factory.getValidator();
        Set&lt;ConstraintViolation&lt;T&gt;&gt; violations = validator.validate(t);
        String errorMsg = violations.stream().map(ConstraintViolation::getMessage).collect(Collectors.joining(&quot;&amp;&quot;));
        if (StringUtils.isNotBlank(errorMsg)) {
            throw new PrescriptionException(ResultEnum.INPUT_PARAM_ERROR.getCode(), errorMsg);
        }
    }

    /**
     * 全局异常捕获
     */
    @ExceptionHandler(value = Exception.class)
    @ResponseBody
    public ResponseResult&lt;?&gt; otherException(Exception e) {
        log.error(&quot;catch other exception, e:&quot;, e);
        return ResponseResultUtil.failure(&quot;系统异常&quot;, ResultEnum.FAILURE.getCode(), e.getMessage());
    }

}

</code></pre>
<p>这是aop中部分代码贴图，不知道大家有没有发现问题，其中<br>
ValidatorFactory factory = Validation.buildDefaultValidatorFactory();<br>
Validator validator = factory.getValidator();</p>
<p>会导致校验效率十分低下，因为会频繁的new 工厂对象，导致gc频繁，造成性能瓶颈。</p>
<h2 id="解决办法">解决办法</h2>
<p>办法很简单。</p>
<pre><code class="language-java">public class ValidationUtils {

    private static Validator validator = Validation
            .byProvider(HibernateValidator.class)
            .configure()
            .failFast(true)
            .buildValidatorFactory()
            .getValidator();


    public static &lt;T&gt; void validate(T obj) {
        validator.validate(obj);
    }

}
</code></pre>
<p>既然知道了原因，那就不要让它一直创建就好了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[最佳实践-数据库的模糊搜索]]></title>
        <id>https://q456qq520.github.io/post/zui-jia-shi-jian-shu-ju-ku-de-mo-hu-sou-suo/</id>
        <link href="https://q456qq520.github.io/post/zui-jia-shi-jian-shu-ju-ku-de-mo-hu-sou-suo/">
        </link>
        <updated>2023-07-20T01:11:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-常见场景">一 常见场景</h2>
<h3 id="11-数据库表创建">1.1 数据库表创建</h3>
<p>首先创建一个学生表并添加姓名的普通索引。</p>
<pre><code class="language-mysql">CREATE TABLE `school`.`student`  (
  `id` bigint(10) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `name` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `age` int(3) NULL DEFAULT NULL,
  `class_number` bigint(10) NULL DEFAULT NULL,
  `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `name`(`name`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;
</code></pre>
<p>并为其中填充几条数据：</p>
<pre><code class="language-mysql">INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (1, '张三', 10, 3, '2023-07-20 09:31:29', '2023-07-20 09:31:34');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (2, '李四', 11, 3, '2023-07-20 09:31:44', '2023-07-20 09:31:44');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (3, '王五', 10, 3, '2023-07-20 09:32:19', '2023-07-20 09:32:19');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (4, '盖伦', 9, 3, '2023-07-20 09:32:39', '2023-07-20 09:32:39');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (5, '普朗克', 10, 3, '2023-07-20 09:32:56', '2023-07-20 09:32:56');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (6, '卡特', 12, 3, '2023-07-20 09:34:31', '2023-07-20 09:34:31');
</code></pre>
<h3 id="12-查询案例">1.2 查询案例</h3>
<p>假设现在有需要对<code>name</code>进行模糊查询，sql如下：</p>
<pre><code class="language-mysql">select * from student where name like '%王%';
</code></pre>
<h3 id="13-案例分析">1.3 案例分析</h3>
<p>用<code>EXPLAIN</code>看看执行计划：<br>
<img src="https://q456qq520.github.io/post-images/1689817827264.png" alt="" loading="lazy"></p>
<p>从图中发现是没有走索引的。那怎么办？索引岂不是白建了？</p>
<h3 id="14-解决方法">1.4 解决方法</h3>
<p>别慌，先给你支一招，如下图：<br>
<img src="https://q456qq520.github.io/post-images/1689817985469.png" alt="" loading="lazy"></p>
<p>走最左侧原则，去掉左边的通配符，就可以发现能走索引了。</p>
<p>产品：我要的就是要全模糊，不要一边模糊搜索。</p>
<p>那该怎么办呢？</p>
<h3 id="15-全文索引">1.5 全文索引</h3>
<p>这时候可以采用终极杀招，使用mysql 自带的全文索引。不懂全文索引的可以先去了解一下。简而言之能实现我们全模糊的要求还走索引，是一种空间换时间的典型。</p>
<pre><code class="language-mysql">create fulltext index name_fulltext on student(name) WITH PARSER ngram;;
</code></pre>
<p>首先建立一个name的全文索引。</p>
<p>接着采用全文索引提供的布尔查询(也可以在查询参数上加通配符*)：</p>
<pre><code class="language-mysql">select * from student where match(name) against('朗' IN BOOLEAN MODE);
select * from student where MATCH ( name ) against ( '王' IN NATURAL LANGUAGE MODE );
</code></pre>
<p>发现，结果啥也没有。什么情况？</p>
<p>这个问题有很多原因，其中最常见的就是<mark>最小搜索长度</mark>导致的。</p>
<p>MySQL 中的全文索引，有两个变量，最小搜索长度和最大搜索长度，对于长度小于最小搜索长度和大于最大搜索长度的词语，都不会被索引。通俗点就是说，想对一个词语使用全文索引搜索，那么这个词语的长度必须在以上两个变量的区间内。</p>
<p>这两个的默认值可以使用以下命令查看</p>
<pre><code class="language-mysql">show variables like '%ft%';
</code></pre>
<p>可以看到这两个变量在 MyISAM 和 InnoDB 两种存储引擎下的变量名和默认值</p>
<pre><code class="language-mysql">// MyISAM
ft_min_word_len = 4;
ft_max_word_len = 84;

// InnoDB
innodb_ft_min_token_size = 3;
innodb_ft_max_token_size = 84;
</code></pre>
<p>可以看到最小搜索长度 MyISAM 引擎下默认是 4，InnoDB 引擎下是 3，也即，MySQL 的全文索引只会对长度大于等于 4 或者 3 的词语建立索引，而刚刚搜索的长度大于等于 4。</p>
<h4 id="配置最小搜索长度">配置最小搜索长度</h4>
<p>全文索引的相关参数都无法进行动态修改，必须通过修改 MySQL 的配置文件来完成。修改最小搜索长度的值为 1，首先打开 MySQL 的配置文件 /etc/my.cnf，在 [mysqld] 的下面追加以下内容</p>
<pre><code class="language-mysql">[mysqld]
innodb_ft_min_token_size = 1
ft_min_word_len = 1
</code></pre>
<blockquote>
<p>可以使用以下命令查询配置文件路径<br>
mysql --help|grep 'my.cnf'</p>
</blockquote>
<p>然后重启 MySQL 服务器，并修复全文索引。<br>
⚠️注意，修改完参数以后，一定要修复下索引，不然参数不会生效。</p>
<p>两种方式，一种是重建索引，一种是执行命令。</p>
<pre><code class="language-mysql">repair table student quick;
</code></pre>
<p>MySQL 的全文索引最开始仅支持英语，因为英语的词与词之间有空格，使用空格作为分词的分隔符是很方便的。亚洲文字，比如汉语、日语、汉语等，是没有空格的，这就造成了一定的限制。不过 MySQL 5.7.6 开始，引入了一个 ngram 全文分析器来解决这个问题，并且对 MyISAM 和 InnoDB 引擎都有效。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1689820849998.png" alt="" loading="lazy"></figure>
<p>再次执行执行计划，可以看到现在是走索引了。</p>
<h3 id="16-elasticsearch">1.6 ElasticSearch</h3>
<p>还有一个执行效率更高更快的办法，那就是引入ES。这里不过多介绍，大概方案就是，用text类型对需要模糊查询对词进行分词，其次是利用match查询进行模糊查询。要达到模糊的效果，首先是要对中英文采取不同对分词器，然后利用match的<mark>Operator.AND</mark>熟悉进行查询。</p>
<blockquote>
<p>Operator.AND和Operator.OR是用于设置match查询的操作符的枚举类型。它们的区别在于如何处理多个查询词的匹配逻辑：<br>
Operator.AND：使用AND操作符，表示所有的查询词都必须出现在匹配的文档中。只有当文档中同时包含所有的查询词时，才会被匹配到。<br>
Operator.OR：使用OR操作符，表示只要文档中包含任何一个查询词，就会被匹配到。只要文档中包含至少一个查询词，就会被视为匹配。</p>
</blockquote>
<p>具体案例为：</p>
<pre><code class="language-json">{
  &quot;from&quot;: 0,
  &quot;size&quot;: 20,
  &quot;timeout&quot;: &quot;60s&quot;,
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        {
          &quot;exists&quot;: {
            &quot;field&quot;: &quot;yb_code&quot;,
            &quot;boost&quot;: 1
          }
        },
        {
          &quot;match&quot;: {
            &quot;name&quot;: {
              &quot;query&quot;: &quot;高血压&quot;,
              &quot;operator&quot;: &quot;AND&quot;,
              &quot;prefix_length&quot;: 0,
              &quot;max_expansions&quot;: 50,
              &quot;fuzzy_transpositions&quot;: true,
              &quot;lenient&quot;: false,
              &quot;zero_terms_query&quot;: &quot;NONE&quot;,
              &quot;auto_generate_synonyms_phrase_query&quot;: true,
              &quot;boost&quot;: 1
            }
          }
        }
      ],
      &quot;filter&quot;: [
        {
          &quot;bool&quot;: {
            &quot;must&quot;: [
              {
                &quot;term&quot;: {
                  &quot;category&quot;: {
                    &quot;value&quot;: 1,
                    &quot;boost&quot;: 1
                  }
                }
              }
            ],
            &quot;adjust_pure_negative&quot;: true,
            &quot;boost&quot;: 1
          }
        }
      ],
      &quot;adjust_pure_negative&quot;: true,
      &quot;boost&quot;: 1
    }
  },
  &quot;sort&quot;: [
    {
      &quot;name_length&quot;: {
        &quot;order&quot;: &quot;asc&quot;
      }
    },
    {
      &quot;id&quot;: {
        &quot;order&quot;: &quot;asc&quot;
      }
    }
  ]
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1689821426314.png" alt="" loading="lazy"></figure>
<p>其中match可以用matchPhrase,但是效果没有match好，或者使用wildcardQuery这种通配符查询的方式也可以。</p>
<p>PS：<br>
如果想看某个字段分词情况，可以用下面的请求：<br>
GET  https://{ip}:{port}/index/_doc/{id}/_termvectors?fields={field}</p>
]]></content>
    </entry>
</feed>