<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://q456qq520.github.io</id>
    <title>LIKECAT</title>
    <updated>2025-04-29T03:01:19.851Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://q456qq520.github.io"/>
    <link rel="self" href="https://q456qq520.github.io/atom.xml"/>
    <subtitle>一条小咸鱼</subtitle>
    <logo>https://q456qq520.github.io/images/avatar.png</logo>
    <icon>https://q456qq520.github.io/favicon.ico</icon>
    <rights>All rights reserved 2025, LIKECAT</rights>
    <entry>
        <title type="html"><![CDATA[Spring bean的生命周期]]></title>
        <id>https://q456qq520.github.io/post/spring-bean-de-sheng-ming-zhou-qi/</id>
        <link href="https://q456qq520.github.io/post/spring-bean-de-sheng-ming-zhou-qi/">
        </link>
        <updated>2025-04-28T03:45:03.000Z</updated>
        <content type="html"><![CDATA[<h2 id="什么是-bean">什么是 Bean</h2>
<blockquote>
<p>In Spring, the objects that form the backbone of your application and that are managed by the Spring IoC container are called beans. A bean is an object that is instantiated, assembled, and otherwise managed by a Spring IoC container. Otherwise, a bean is simply one of many objects in your application. Beans, and the dependencies among them, are reflected in the configuration metadata used by a container.</p>
</blockquote>
<p>简而言之，bean 是由 Spring IoC 容器实例化、组装和管理的对象。</p>
<h2 id="什么是-spring-bean-的生命周期">什么是 Spring Bean 的生命周期</h2>
<p>对于普通的 Java 对象，当 new 的时候创建对象，然后该对象就能够使用了。一旦该对象不再被使用，则由 Java 自动进行垃圾回收。</p>
<p>而 Spring 中的对象是 bean，bean 和普通的 Java 对象没啥大的区别，只不过 Spring 不再自己去 new 对象了，而是由 IoC 容器去帮助我们实例化对象并且管理它，我们需要哪个对象，去问 IoC 容器要即可。IoC 其实就是解决对象之间的耦合问题，Spring Bean 的生命周期完全由容器控制。</p>
<h2 id="bean生命周期">Bean生命周期</h2>
<p>⚠️这里我们说的 Spring Bean 的生命周期主要指的是 singleton bean，对于 prototype 的 bean ，Spring 在创建好交给使用者之后则不会再管理后续的生命周期。</p>
<h3 id="bean-的作用域">bean 的作用域</h3>
<ul>
<li>singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。</li>
<li>prototype : 每次请求都会创建一个新的 bean 实例。</li>
<li>request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。</li>
<li>session : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。</li>
<li>global-session： 全局 session 作用域，仅仅在基于 Portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码（例如：HTML）片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话</li>
</ul>
<h3 id="spring-singleton-bean-的生命周期">Spring Singleton Bean 的生命周期</h3>
<ol>
<li>实例化 Instantiation</li>
<li>属性赋值 Populate</li>
<li>初始化 Initialization</li>
<li>销毁 Destruction</li>
</ol>
<p>实例化 -&gt; 属性赋值 -&gt; 初始化 -&gt; 销毁</p>
<blockquote>
<p>Bean实例化的时机也分为两种，BeanFactory管理的Bean是在使用到Bean的时候才会实例化Bean，ApplicantContext管理的Bean在容器初始化的时候就会完成Bean实例化。</p>
</blockquote>
<blockquote>
<p>“实例化”和“初始化”是两个完全不同的过程，千万不要搞混，实例化只是给 Bean 分配了内存空间，而初始化则是将程序的执行权，从系统级别转换到用户级别，并开始执行用户添加的业务代码。</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1745812173127.png" alt="" loading="lazy"></figure>
<p>Bean实例化前后，可以进行一些处理，但是如果从Bean实例化前算开始，那么就要追溯到容器的初始化、beanDefiinition的加载开始。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1745812261215.png" alt="" loading="lazy"></figure>
<ol>
<li>实例化：第 1 步，实例化一个 Bean 对象</li>
<li>属性赋值：第 2 步，为 Bean 设置相关属性和依赖</li>
<li>初始化：初始化的阶段的步骤比较多，5、6步是真正的初始化，第 3、4 步为在初始化前执行，第 7 步在初始化后执行，初始化完成之后，Bean就可以被使用了</li>
<li>销毁：第 8~10步，第8步其实也可以算到销毁阶段，但不是真正意义上的销毁，而是先在使用前注册了销毁的相关调用接口，为了后面第9、10步真正销毁 Bean 时再执行相应的方法</li>
</ol>
<h3 id="spring-singleton-bean-的生命周期详解">Spring Singleton Bean 的生命周期详解</h3>
<h4 id="docreatebean">doCreateBean</h4>
<pre><code class="language-java">protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException {
    BeanWrapper instanceWrapper = null;
    if (mbd.isSingleton()) {
        instanceWrapper = (BeanWrapper)this.factoryBeanInstanceCache.remove(beanName);
    }

    if (instanceWrapper == null) {
        // 实例化阶段
        instanceWrapper = this.createBeanInstance(beanName, mbd, args);
    }

    ...

    Object exposedObject = bean;

    try {
        // 属性赋值阶段
        this.populateBean(beanName, mbd, instanceWrapper);
        // 初始化阶段
        exposedObject = this.initializeBean(beanName, exposedObject, mbd);
    } catch (Throwable var18) {
        ...
    }

    ...
}
</code></pre>
<p>至于销毁，是在容器关闭时调用的，详见<code>ConfigurableApplicationContext#close()</code></p>
<h4 id="createbeaninstance">createBeanInstance</h4>
<pre><code class="language-java">protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) {
		//首先确保bean 已经被解析过
		Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);
        // 如果beanClass 不是public 类型，那么就 抛出异常，提示   non-public access not allowed
		if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) {
			throw new BeanCreationException(mbd.getResourceDescription(), beanName,
					&quot;Bean class isn't public, and non-public access not allowed: &quot; + beanClass.getName());
		}
        // 如果存在，就返回一个  callback回调函数，在 obtainFromSupplier 方法里面
        //调用对应的具体方法 ，并转换成 BeanWrapper 类型
		Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier();
		if (instanceSupplier != null) {
		   // 这里转换成 BeanWrapper  类型
			return obtainFromSupplier(instanceSupplier, beanName);
		}
        // 如果存在对应的工厂方法，那么就使用工厂方法进行初始化
		if (mbd.getFactoryMethodName() != null) {
			return instantiateUsingFactoryMethod(beanName, mbd, args);
		}

		// Shortcut when re-creating the same bean...
		boolean resolved = false;
		boolean autowireNecessary = false;
		if (args == null) {
			synchronized (mbd.constructorArgumentLock) {
			//一个类有多个构造函数，每个构造商数都有不同的参数,所以调用前前需要先根据参数锁定构 
            //边的数或对应的工厂方法 
				if (mbd.resolvedConstructorOrFactoryMethod != null) {
				    // 设置 已经解析
					resolved = true;
					autowireNecessary = mbd.constructorArgumentsResolved;
				}
			}
		}
		//如果已经解析过则使用解析好的构造函数方法，不用再次锁定 
		if (resolved) {
		    // 构造函数参数都已经解析完
			if (autowireNecessary) {
			    // 使用构造函数自动注入
				return autowireConstructor(beanName, mbd, null, null);
			}
			else {
      			//使用其默认构造函数实例化给定的bean
				return instantiateBean(beanName, mbd);
			}
		}

		// Candidate constructors for autowiring?
		// 如果上面没有解析好对应的构造函数， 这里看看有没有指定构造函数
		/**
		  具体里面其实 是 SmartInstantiationAwareBeanPostProcessor , 这个类 继承了
		  InstantiationAwareBeanPostProcessor， 调用里面的determineCandidateConstructors 方法 
		  来确认有没有指定的构造函数
		*/
		Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);
		if (ctors != null || mbd.getResolvedAutowireMode() == AUTOWIRE_CONSTRUCTOR ||
				mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) {
			// 构造函数自动注入
			return autowireConstructor(beanName, mbd, ctors, args);
		}

		// 获取确定用于默认构造的首选构造函数（如果有）。 如有必要，构造函数参数将自动装配。
		ctors = mbd.getPreferredConstructors();
		if (ctors != null) {
			return autowireConstructor(beanName, mbd, ctors, null);
		}

		// 默认使用无参构造函数
		return instantiateBean(beanName, mbd);
	}
</code></pre>
<h4 id="populatebean">populateBean</h4>
<pre><code class="language-java"> protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) {
    if (bw == null) {
       // 如果beanWrapper为空，说明bean实例为null，需要跳过property值的设置
       // 但是如果beanWrapper为空而且mbd.hasPropertyValues()为true，说明bean实例为null，bean定义中存在property值，需要抛出异常
       if (mbd.hasPropertyValues()) {
          throw new BeanCreationException(
                mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;);
       }
       else {
          // Skip property population phase for null instance.
          return;
       }
    }
 ​
    // 如果Bean是记录类型，那么Spring将跳过属性填充阶段，因为记录类型的属性是不可变的，无法进行属性注入
    if (bw.getWrappedClass().isRecord()) {
       if (mbd.hasPropertyValues()) {
          throw new BeanCreationException(
                mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to a record&quot;);
       }
       else {
          // Skip property population phase for records since they are immutable.
          return;
       }
    }
 ​
    // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the
    // state of the bean before properties are set. This can be used, for example,
    // to support styles of field injection.
    // 在设置属性之前，让任何InstantiationAwareBeanPostProcessors都有机会修改bean的状态。例如，这可以用于支持现场注入的样式。
    if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) {
       for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) {
          if (!bp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) {
             return;
          }
       }
    }
 ​
    // 属性填充值
    PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null);
 ​
    // 自动装配类型 byName byType
    int resolvedAutowireMode = mbd.getResolvedAutowireMode();
    if (resolvedAutowireMode == AUTOWIRE_BY_NAME || resolvedAutowireMode == AUTOWIRE_BY_TYPE) {
       // 根据pvs 封装属性值
       MutablePropertyValues newPvs = new MutablePropertyValues(pvs);
       // Add property values based on autowire by name if applicable.
       if (resolvedAutowireMode == AUTOWIRE_BY_NAME) {
          // 添加属性值，根据byName
          autowireByName(beanName, mbd, bw, newPvs);
       }
       // Add property values based on autowire by type if applicable.
       if (resolvedAutowireMode == AUTOWIRE_BY_TYPE) {
          // 添加属性值，根据byType
          autowireByType(beanName, mbd, bw, newPvs);
       }
       pvs = newPvs;
    }
    // 此工厂是否持有InstantiationAwareBeanPostProcessor后置处理器
    if (hasInstantiationAwareBeanPostProcessors()) {
       if (pvs == null) {
          pvs = mbd.getPropertyValues();
       }
       // 遍历后置处理器，如果返回非空的PropertyValues，将pvs更新为返回的PropertyValues
       for (InstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().instantiationAware) {
          PropertyValues pvsToUse = bp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName);
          if (pvsToUse == null) {
             return;
          }
          pvs = pvsToUse;
       }
    }
 ​
    boolean needsDepCheck = (mbd.getDependencyCheck() != AbstractBeanDefinition.DEPENDENCY_CHECK_NONE);
    if (needsDepCheck) {
       PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching);
       checkDependencies(beanName, mbd, filteredPds, pvs);
    }
 ​
    if (pvs != null) {
       // 将属性应用到 bean 中
       applyPropertyValues(beanName, mbd, bw, pvs);
    }
 }
</code></pre>
<h4 id="initializebean">initializeBean</h4>
<p>如果bean实现了InitializingBean接口，那么initializeBean会调用bean的afterPropertiesSet方法。这个方法在bean的属性初始化后会被执行。</p>
<p>如果在配置文件中通过init-method或注解指定了初始化方法，那么initializeBean会调用这个方法。</p>
<pre><code class="language-java"> protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) {
    //用于执行BeanNameAware、BeanClassLoaderAware和BeanFactoryAware等Aware回调方法
    invokeAwareMethods(beanName, bean);
 ​
    Object wrappedBean = bean;
    // 如果mbd不为空并且不是合成bean，则执行BeanPostProcessor的beforeInitialization方法
    // 这里明明是mbd == null，为什么要解释成不为空呢，下面会有解释
    if (mbd == null || !mbd.isSynthetic()) {
       wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);
    }
 ​
    try {
       // 执行bean的初始化方法
       invokeInitMethods(beanName, wrappedBean, mbd);
    }
    catch (Throwable ex) {
       throw new BeanCreationException(
             (mbd != null ? mbd.getResourceDescription() : null), beanName, ex.getMessage(), ex);
    }
    // 如果bean定义不存在或者bean不是合成的，则调用applyBeanPostProcessorsAfterInitialization方法，对bean进行初始化后的后处理器。
    if (mbd == null || !mbd.isSynthetic()) {
       wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);
    }
 ​
    return wrappedBean;
 }

</code></pre>
<h2 id="什么是循环依赖">什么是循环依赖</h2>
<p>循环依赖就是循环引用，就是两个或多个 bean 相互之间的持有对方，比如 TestA 引用 TestB，TestB 引用 TestC，TestC引用 TestA，则他们最终会形成一个闭环。</p>
<h3 id="spring-是如何解决循环依赖的">Spring 是如何解决循环依赖的</h3>
<h4 id="构造器循环依赖">构造器循环依赖</h4>
<ol>
<li>表示通过构造器注入构成的循环依赖，此依赖是无法解决的，只能拋出 BeanCurcenlylCreationException 异常表示循环依赖</li>
<li>如在创建 TestA类时，构造器需要 TestB 类，那将去创建 TestB，在创建 TestB 类时又发现需要 TestC 类，则又去创建TestC，最终在创建 TestC 时发现又需要 TestA，从而形成一个环，没办法创建。</li>
<li>Spring 容器将每一个正在创建的 bean 标识符放在一个当前创建 bean 池中，bean标识符在创建过程中将一直保持在这个池中，因此如果在创建 bean 过程中发现自己已经在当的创建bean 池里时，将抛出 BeanCurrentlyInCreationException 异常表示循环依赖；而对于创建完毕的bean 将从当前创建bean池中清除掉。</li>
</ol>
<h4 id="setter-循环依赖">setter 循环依赖</h4>
<p>表示通过 setter 注入方式构成的循环依赖。对于 setter 注人造成的依赖是通过 Spring 容器提前暴露刚完成构造器注入但未完成其他步骤（如 setter 注入）的bean来完成的，而且只能解决单例作用域的bean 循环依赖。通过提前暴露一个单例工厂方法，从而使其他 bean 能引用到该bean。</p>
<ol>
<li>Spring 容器创建单例 testA bean，首先根据无参构造器创建 bean，并暴露一个ObjectFactory用于返回一个提前暴露一个创建中的bean，并将testA 标识符放到当前创建bean 池，然后进行 setter 注入testB。</li>
<li>Spring 容器创建单例 testB bean，首先根据无参构造器创建 bean，并暴露一个ObjectFactory用于返回一个提前暴露一个创建中的 bean，并将testB 标识符放到当前创建 bean池，然后进行 setter 注入testC。</li>
<li>Spring 容器创建单例 testC bean，首先根据无参构造器创建 bean，并暴露一个ObjectFactory用于返回一个提前暴露一个创建中的 bean，并将testC 标识符放到当前创建 bean池，然后进行 setter 注入testA。进行注入testA 时由于提前暴露了ObjectFactory工厂，从而使用它返回提前暴露一个创建中的bean。</li>
<li>最后在依赖注入testB 和 testA，完成 setter 注入。</li>
<li>对于单例 bean 来说，可以通过 setAllowCircularRefernces(false)来禁用循环引用</li>
</ol>
<h3 id="三级缓存">三级缓存</h3>
<p>第⼀级缓存：singletonObjects，⽤于保存实例化、注⼊、初始化完成的 bean 实例；<br>
第⼆级缓存：earlySingletonObjects，⽤于保存实例化完成的 bean 实例；<br>
第三级缓存：singletonFactories，⽤于保存 bean 创建⼯⼚，以便后⾯有机会创建代理对象。</p>
<pre><code class="language-java">/** Cache of singleton objects: bean name --&gt; bean instance */
/** 一级缓存：用于存放完全初始化好的 bean **/
private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;String, Object&gt;(256);
 
/** Cache of early singleton objects: bean name --&gt; bean instance */
/** 二级缓存：存放原始的 bean 对象（尚未填充属性），用于解决循环依赖 */
private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;String, Object&gt;(16);

/** Cache of singleton factories: bean name --&gt; ObjectFactory */
/** 三级级缓存：存放 bean 工厂对象，用于解决循环依赖 */
private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;String, ObjectFactory&lt;?&gt;&gt;(16);

</code></pre>
<h3 id="getsingleton方法中三级缓存的使用">getSingleton方法中三级缓存的使用</h3>
<pre><code class="language-java">protected Object getSingleton(String beanName, boolean allowEarlyReference) {
  // Spring首先从singletonObjects（一级缓存）中尝试获取
  Object singletonObject = this.singletonObjects.get(beanName);
  // 若是获取不到而且对象在建立中，则尝试从earlySingletonObjects(二级缓存)中获取
  if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {
    synchronized (this.singletonObjects) {
        singletonObject = this.earlySingletonObjects.get(beanName);
        if (singletonObject == null &amp;&amp; allowEarlyReference) {
          ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);
          if (singletonFactory != null) {
            //若是仍是获取不到而且允许从singletonFactories经过getObject获取，则经过singletonFactory.getObject()(三级缓存)获取
              singletonObject = singletonFactory.getObject();
              //若是获取到了则将singletonObject放入到earlySingletonObjects,也就是将三级缓存提高到二级缓存中
              this.earlySingletonObjects.put(beanName, singletonObject);
              this.singletonFactories.remove(beanName);
          }
        }
    }
  }
  return (singletonObject != NULL_OBJECT ? singletonObject : null);
}
</code></pre>
<p>三级缓存的使用过程如下</p>
<ol>
<li>Spring 会先从一级缓存 singletonObjects 中尝试获取 Bean。</li>
<li>若是获取不到，而且对象正在建立中，就会尝试从二级缓存 earlySingletonObjects 中获取 Bean。</li>
<li>若还是获取不到，且允许从三级缓存 singletonFactories 中经过 singletonFactory 的 getObject() 方法获取 Bean 对象，就会尝试从三级缓存 singletonFactories 中获取 Bean。</li>
<li>若是在三级缓存中获取到了 Bean，会将该 Bean 存放到二级缓存中。</li>
</ol>
<h3 id="为什么要三级缓存">为什么要三级缓存?</h3>
<p>二级缓存也是可以解决循环依赖的。为什么 Spring 不选择二级缓存，而要额外多添加一层缓存，使用三级缓存呢？</p>
<p>如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。</p>
<p>使用三级缓存而非二级缓存并不是因为只有三级缓存才能解决循环引用问题，其实二级缓存同样也能很好解决循环引用问题。使用三级而非二级缓存并非出于 IOC 的考虑，而是出于 AOP 的考虑，即若使用二级缓存，在 AOP 情形注入到其他 Bean的，不是最终的代理对象，而是原始对象。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql物化和半连接]]></title>
        <id>https://q456qq520.github.io/post/mysql-wu-hua-he-ban-lian-jie/</id>
        <link href="https://q456qq520.github.io/post/mysql-wu-hua-he-ban-lian-jie/">
        </link>
        <updated>2025-04-23T02:28:17.000Z</updated>
        <content type="html"><![CDATA[<h2 id="物化materialization">物化（Materialization）</h2>
<p>物化应该是指将子查询的结果存储到一个临时表中，这样后续的查询可以直接使用这个临时表，而不需要每次都重新执行子查询。这样可以减少重复计算，尤其是在子查询结果集较大的情况下，可能提高性能。</p>
<h3 id="适用场景">适用场景：</h3>
<ol>
<li>非相关子查询：子查询不依赖外层查询的值，可以独立执行并缓存结果。</li>
<li>子查询结果集较大：如果子查询返回的结果集较大，物化可以避免重复计算，提高效率。</li>
<li>需要多次访问子查询结果：例如子查询被用于JOIN或WHERE条件多次时，物化临时表可以复用。</li>
<li>子查询复杂度高：若子查询包含聚合、排序或复杂过滤（如GROUP BY, DISTINCT），物化可减少计算开销。</li>
</ol>
<h3 id="示例">示例</h3>
<pre><code>SELECT * FROM customers 
WHERE id IN (SELECT customer_id FROM orders WHERE amount &gt; 100);
</code></pre>
<p>若子查询SELECT customer_id FROM orders的结果集大且无索引，优化器可能物化结果到临时表，再与customers表JOIN。</p>
<p>优化提示：</p>
<p>使用SUBQUERY提示强制物化：</p>
<pre><code>SELECT /*+ SUBQUERY(MATERIALIZATION) */ * FROM customers ...;
</code></pre>
<h2 id="半连接">半连接</h2>
<p>半连接通常用于存在性检查，比如使用IN或者EXISTS子句时。半连接和普通连接的不同之处在于，半连接只需要返回外层表中存在匹配的记录，而不会返回多条匹配记录导致重复。</p>
<h3 id="适用场景-2">适用场景：</h3>
<ol>
<li>存在性检查：使用IN或EXISTS时，只需判断外层记录是否存在匹配，无需返回所有匹配项。</li>
<li>相关子查询：子查询依赖外层查询的值，需逐行判断。</li>
<li>索引可用性高：若子查询字段有索引（如customer_id上的索引），半连接可通过索引快速定位匹配项。</li>
<li>结果集较小：子查询结果集较小时，半连接避免物化开销，直接通过索引高效匹配。</li>
</ol>
<pre><code class="language-mysql">SELECT * FROM departments d 
WHERE EXISTS (SELECT 1 FROM employees e WHERE e.dept_id = d.id);
</code></pre>
<p>若employees.dept_id有索引，优化器可能选择半连接策略，仅检查是否存在匹配记录。</p>
<p>优化提示：</p>
<p>使用SEMIJOIN提示强制半连接策略：</p>
<pre><code>SELECT /*+ SEMIJOIN(DUPSWEEDOUT) */ * FROM departments ...;
</code></pre>
<h2 id="关键选择因素">关键选择因素</h2>
<table>
<thead>
<tr>
<th>因素</th>
<th>物化</th>
<th>半连接</th>
</tr>
</thead>
<tbody>
<tr>
<td>子查询相关性</td>
<td>非相关子查询</td>
<td>相关或非相关子查询</td>
</tr>
<tr>
<td>结果集大小</td>
<td>大结果集</td>
<td>小结果集</td>
</tr>
<tr>
<td>索引情况</td>
<td>无高效索引时更优</td>
<td>子查询字段有索引时更优</td>
</tr>
<tr>
<td>执行频率</td>
<td>结果需多次访问时更优</td>
<td>单次存在性检查更优</td>
</tr>
<tr>
<td>资源消耗</td>
<td>占用临时表空间</td>
<td>通常内存友好</td>
</tr>
</tbody>
</table>
<h3 id="调试与优化建议">调试与优化建议</h3>
<ol>
<li>使用EXPLAIN分析：通过执行计划查看优化器选择的策略（如MATERIALIZED或SEMIJOIN）。</li>
<li>强制策略：通过优化器提示（如/*+ SEMIJOIN(...) */）干预选择。</li>
<li>索引优化：为子查询字段添加索引，提升半连接效率。</li>
<li>权衡资源：物化可能占用更多内存/磁盘，需根据系统资源调整。</li>
</ol>
<p>总结：非相关大结果集优先物化，相关或索引友好场景选半连接，结合EXPLAIN和实际性能测试进行调优。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[HTTPS]]></title>
        <id>https://q456qq520.github.io/post/https-qing-qiu-jie-duan-fen-xi/</id>
        <link href="https://q456qq520.github.io/post/https-qing-qiu-jie-duan-fen-xi/">
        </link>
        <updated>2024-04-10T06:15:39.000Z</updated>
        <content type="html"><![CDATA[<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=2022147586&auto=1&height=66"></iframe>
<h2 id="1-请求阶段分析">1. 请求阶段分析</h2>
<p>一个完整、无任何缓存、未复用连接的 HTTPS 请求需要经过以下几个阶段：DNS 域名解析、TCP 握手、SSL 握手、服务器处理、内容传输。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1712729855422.png" alt="" loading="lazy"></figure>
<h2 id="2-请求阶段耗时分析">2. 请求阶段耗时分析</h2>
<p>HTTPS 请求的各个阶段可以使用 curl 命令进行详细的耗时分析[2]。如表 2-2 所示， curl 提供了详细的耗时分析选项，这样我们就可以更准确地掌握每一个环节的消耗时间，进一步提升网络优化的效率和精度。</p>
<p>表-网络请求阶段分析</p>
<table>
<thead>
<tr>
<th>请求阶段</th>
<th>释义</th>
</tr>
</thead>
<tbody>
<tr>
<td>time_namelookup</td>
<td>从请求开始到域名解析完成的耗时</td>
</tr>
<tr>
<td>time_connect</td>
<td>从请求开始到 TCP 三次握手完成耗时</td>
</tr>
<tr>
<td>time_appconnect</td>
<td>从请求开始到 TLS 握手完成的耗时</td>
</tr>
<tr>
<td>time_pretransfer</td>
<td>从请求开始到向服务器发送第一个 GET/POST 请求开始之前的耗时</td>
</tr>
<tr>
<td>time_redirect</td>
<td>重定向时间，包括到内容传输前的重定向的 DNS 解析、TCP 连接、内容传输等时间</td>
</tr>
<tr>
<td>time_starttransfer</td>
<td>从请求开始到内容传输前的时间</td>
</tr>
<tr>
<td>time_total</td>
<td>从请求开始到完成的总耗时</td>
</tr>
</tbody>
</table>
<p>对一个接口使用 curl 测试：</p>
<pre><code class="language-java">$ curl -w '\n time_namelookup=%{time_namelookup}\n time_connect=%{time_connect}\n time_appconnect=%{time_appconnect}\n time_redirect=%{time_redirect}\n time_pretransfer=%{time_pretransfer}\n time_starttransfer=%{time_starttransfer}\n time_total=%{time_total}\n' -o /dev/null -s 'https://www.thebyte.com.cn/'
// 输出的结果
time_namelookup=0.025021
time_connect=0.033326
time_appconnect=0.071539
time_redirect=0.000000
time_pretransfer=0.071622
time_starttransfer=0.088528
time_total=0.088744
</code></pre>
<blockquote>
<p>curl 操作参见 https://catonmat.net/cookbooks/curl ↩︎</p>
</blockquote>
<h2 id="3-域名解析环节实践">3. 域名解析环节实践</h2>
<h3 id="31-域名解析的工作原理">3.1 域名解析的工作原理</h3>
<p>域名解析靠的是 DNS，我们在浏览器输入一个域名时，DNS 负责将该域名解析为相应的 IP 地址，以便后续与目标服务器建立 TCP/IP 连接。探寻 DNS 工作原理之前，我们先了解域名的结构。如图 2-3 所示，域名是一种树状结构，最顶层的域名是根域名（注意是一个点“.”，它是 .root 的含义），然后是顶级域名（top-level domain，简写 TLD），再是一级域名、二级域名、三级域名。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1712731210190.webp" alt="" loading="lazy"></figure>
<p><strong>DNS 解析流程</strong></p>
<ol>
<li>用户向 DNS 解析器（也称为递归解析器，例如电信运营商的 114.114.114.114）发出解析 example.com 域名请求。</li>
<li>DNS解析器 判断是否存在解析缓存，如存在返回缓存结果。如无则就近向 Root nameserver (根域名服务器)请求所属 TLD 域名服务器。</li>
<li>获取 com.域的 TLD 域名服务器后， 向该地址请求 example.com. 的 权威解析服务器（Authoritative nameserver）。</li>
<li>得到权威解析服务器地址后，向该服务获取域名对应的 IP 地址，域名解析过程结束。</li>
</ol>
<h3 id="32-dns-故障排查">3.2 DNS 故障排查</h3>
<ol>
<li>使用 nslookup 命令<br>
第一个介绍的是 nslookup 命令，该命令用于查询 DNS 的记录、域名解析是否正常等。</li>
</ol>
<p>nslookup 命令示例：</p>
<pre><code class="language-java">$ nslookup thebyte.com.cn        
Server:		8.8.8.8
Address:	8.8.8.8#53

Non-authoritative answer:
Name:	thebyte.com.cn
Address: 110.40.229.45
</code></pre>
<p>第一行的 Server 为当前使用的 DNS解析器。<br>
Non-authoritative answer 因为 DNS 解析器只是转发权威解析服务器的记录，所以为非权威应答。<br>
Address 为解析结果，上面的解析可以看到是一个A记录 110.40.229.45。</p>
<ol start="2">
<li>使用 dig 命令<br>
nslookup 返回的结果比较简单，如果想获取更多的信息，可以尝试使用 dig 命令。</li>
</ol>
<p>dig命令示例：</p>
<pre><code class="language-java">$ dig thebyte.com.cn

; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; thebyte.com.cn
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 63697
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;thebyte.com.cn.			IN	A

;; ANSWER SECTION:
thebyte.com.cn.		599	IN	A	110.40.229.45

;; Query time: 14 msec
;; SERVER: 8.8.8.8#53(8.8.8.8)
;; WHEN: Fri May 12 15:22:33 CST 2023
;; MSG SIZE  rcvd: 59
</code></pre>
<p>第一段 opcode 为 QUERY，表示执行查询操作，status 为 NOERROR，表示解析成功。<br>
第二段 QUESTION SECTION 部分显示了发起的 DNS 请求参数，A 表示我们默认查询 A 类型记录。<br>
第三段 ANSWER SECTION 部分为 DNS 查询结果，可以看到 thebyte.com.cn. 的解析结果为 110.40.229.45。<br>
最后一段为查询所用的DNS解析器、耗时等信息。</p>
<h2 id="4-http-请求优化">4. HTTP 请求优化</h2>
<ul>
<li>包体积优化：传输数据的包体大小与传输耗时成正相关，压缩算法是减小包体的最有效手段(没有之一)。</li>
<li>SSL 层优化：升级 TLS 算法以及 HTTPS 证书，降低 SSL 层的性能消耗。</li>
<li>传输层优化：升级拥塞控制算法（例如由默认的 Cubic 升级为 BBR 算法）提升数据传输效率。</li>
<li>网络层优化：使用一些商业网络加速服务，在网络层对数据包进行路由优化，实现动态服务加速。</li>
<li>使用更现代的 HTTP 协议：升级至 HTTP/2，进一步可以使用 QUIC。</li>
</ul>
<h3 id="41-对传输内容进行压缩">4.1 对传输内容进行压缩</h3>
<p>所有的现代浏览器、客户端及 HTTP 服务器软件都支持压缩技术，唯一需要协商的是客户端与服务端所采用的压缩算法。</p>
<p>为了选择采用的压缩算法，HTTP 客户端和服务器之间会使用主动协商机制：HTTP 客户端发送 Accept-Encoding 首部（其中包含它所支持的压缩算法，以及各自的优先级），服务器则从中选择一种，使用该算法对响应的消息主体进行压缩，并且发送 Content-Encoding 首部来告知 HTTP 客户端它选择了哪一种算法。</p>
<h2 id="5-https-原理及-ssl-层优化实践">5. HTTPS 原理及 SSL 层优化实践</h2>
<p>HTTPS 是什么？简单理解就是 HTTP+SSL/TLS。</p>
<h3 id="51-理解-https-流程">5.1 理解 HTTPS 流程</h3>
<p>HTTP 添加 SSL 层的本质是为了实现信息传递“绝对”的安全性。</p>
<p>如图，如果是一个 1 v 1 的通信模型，想实现信息传递安全性，使用对称加密就可以。只要保证密钥不被第三者知道，信息传递的安全问题就能解决！</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1712731764166.png" alt="" loading="lazy"></figure>
<p>但是，对称加密方式在 HTTP 场景下就出现问题了。如图所示，对称加密的关键操作是如何保证秘钥的安全性，而 HTTP 通信模型是 1 v N，使用对称加密这种方式等同没有加密。</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1712731768876.png" alt="" loading="lazy"></figure>
<p>为了解决秘钥暴露的问题，我们使每个客户端使用不同的算法/密钥，并再增加一个协商的过程，用于确定双方采用哪一种加密算法/密钥（这个协商的过程就是 TLS 协议做的事情）<br>
<img src="https://q456qq520.github.io/post-images/1712731829129.png" alt="" loading="lazy"></p>
<p>不过问题还是存在，协商过程解决了对称加密算法或秘钥独立性问题，但协商过程依旧是明文的，密钥依然存在被截获的可能性。</p>
<p>解决这个问题就必须换一种思路，只使用对称加密就会陷入“无限套娃”的死胡同。我们引入一个新的概念：非对称加密算法。</p>
<blockquote>
<p>非对称加密有两个密钥：公钥、私钥，私钥加密的密文只能公钥解，公钥加密的密文只能私钥解。</p>
</blockquote>
<p>由于对称加解密效率远比非对称加解密效率高得多，所以我们这样：</p>
<ol>
<li>对 HTTP 内容使用对称加密</li>
<li>协商流程中，通过一个随机数确定对称加密算法/密钥，然后使用非对称加密算法的私钥对其加密。</li>
<li>客户端先公钥解密获得对称加密的密钥，再用该密钥解密 HTTP 内容，从而获得明文。</li>
</ol>
<h5 id="证书认证机构">证书认证机构</h5>
<p>如果服务端直接发送公钥证书给客户端，仍然无法避免中间被截获的可能性。</p>
<p>此时，我们引入一个双方都信任的第三方机构，使用第三方机构的私钥将服务器公钥加密后传输给客户端，客户端再使用第三方公钥（内置在本地）进行解密。虽然流程绕了些，但至少离我们的目标”绝对“安全又近了些。</p>
<p>这个双方都信任的机构就是 HTTPS 中的 CA（CA，Certificate Authority，证书认证机构）。</p>
<p>HTTPS 中把公钥规范成数字证书的形式由 CA 签发（数字证书通常包含服务端公钥、持有者信息、CA 的信息以及过期信息等）。服务端向 CA 申请数字证书，再把数字证书下发给客户端。至于第三方 CA 公钥的问题，解决方案就是提前预装在系统内，这就是系统内根证书的由来。</p>
<p>总结 HTTPS 的通信逻辑如下：<br>
<img src="https://q456qq520.github.io/post-images/1712732068028.svg" alt="" loading="lazy"></p>
<ol>
<li>服务端向 CA 机构申请证书，</li>
<li>客户端请求服务端时，服务端向客户端下发证书</li>
<li>客户端根据本地根证书校验服务端的证书</li>
<li>客户端拿到证书的内公钥，加密之后传递服务端，服务端用本地的私钥进行解密获取正文。</li>
</ol>
<h3 id="52-ssl-层优化实践">5.2 SSL 层优化实践</h3>
<p>HTTPS 建立连接的过程中，TLS 握手阶段最长可以花费 2-RTT，除去握手延迟外，SSL 层还有其他的一些隐形消耗，不做任何优化措施情况下，网络耗时和加解密耗时影响会让 HTTPS 连接效率比 HTTP 慢上几百毫秒，在高延迟网络环境下，HTTPS 延迟问题更加明显。</p>
<h5 id="协议升级">协议升级</h5>
<p>优化 SSL 层，效果最为明显的方式是升级最新 TLS1.3 协议[1]。TLS 1.3 协议放弃了安全性较低的加密功能的支持，并改进了 TLS 握手流程。TLS 1.3 协议中的 TLS 握手只需要一次 RTT 而不是两次，如果客户端复用之前连接，TLS 握手的往返次数可以为零，这使 HTTPS 连接更快，能显著减少延迟并改善用户体验。如图所示，如果使用 TLS 1.2 需要两次往返（ 2-RTT ）才能完成握手，然后才能发送请求。</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1712732331870.png" alt="" loading="lazy"></figure>
<p>相比 TLS1.2 协议，TLS 1.3 协议的握手时间减半，如图所示。这意味着访问一个网站，使用 TLS 1.3 协议，会降低将近 100ms 的延时。</p>
<figure data-type="image" tabindex="6"><img src="https://q456qq520.github.io/post-images/1712732336578.png" alt="" loading="lazy"></figure>
<h5 id="证书优化">证书优化</h5>
<p>SSL 层中的证书验证也是一个比较耗时的环节：服务器需要把自己的证书链全发给客户端，客户端接收后再逐一验证。证书环节我们关注两个方面优化：<strong>证书传输优化</strong> 、** 证书中非对称算法升级 **。</p>
<p>客户端在验证证书过程中，需要判断当前证书状态，是否被撤销/过期等，需要再去访问 CA 下载 CRL 或者 OCSP 数据，这又会产生 DNS 查询、建立连接、收发数据等一系列网络通信，增加多个 RTT。</p>
<blockquote>
<p>TIP<br>
CRL（Certificate Revocation List）证书撤销列表，是由 CA 机构维护的一个列表，列表中包含已经被吊销的证书序列号和吊销时间。<br>
OCSP（Online Certificate Status Protocol）在线证书状态协议，是一种改进的证书状态确认方法，用于减轻证书吊销检查的负载和提高数据传输的私密性，相比于 CRL ，OCSP提供了实时验证证书状态的能力。<br>
OCSP Stapling 是 OCSP 的改进方案，将原本需要客户端实时发起的 OCSP 请求转嫁给服务端，服务端通过预先访问 CA 获取 OCSP 响应，然后在握手时随着证书一起发给客户端，免去了客户端连接 CA 服务器查询的环节，解决了 OCSP 的隐私和性能问题。</p>
</blockquote>
<ol>
<li>在 Nginx 中配置 OCSP Stapling 服务。</li>
</ol>
<pre><code class="language-Nginx">server {
    listen 443 ssl;
    server_name  thebyte.com.cn;
    index index.html;

    ssl_certificate         server.pem;#证书的.cer文件路径
    ssl_certificate_key     server-key.pem;#证书的.key文件

    # 开启 OCSP Stapling 当客户端访问时 NginX 将去指定的证书中查找 OCSP 服务的地址，获得响应内容后通过证书链下发给客户端。
    ssl_stapling on;
    ssl_stapling_verify on;# 启用OCSP响应验证，OCSP信息响应适用的证书
    ssl_trusted_certificate /path/to/xxx.pem;# 若 ssl_certificate 指令指定了完整的证书链，则 ssl_trusted_certificate 可省略。
    resolver 8.8.8.8 valid=60s;# 添加resolver解析OSCP响应服务器的主机名，valid表示缓存。
    resolver_timeout 2s;# resolver_timeout表示网络超时时间
}
</code></pre>
<ol start="2">
<li>检查服务端是否已开启 OCSP Stapling。</li>
</ol>
<pre><code class="language-yml">openssl s_client -connect thebyte.com.cn:443 -servername thebyte.com.cn -status -tlsextdebug &lt; /dev/null 2&gt;&amp;1 | grep &quot;OCSP&quot; 
</code></pre>
<p>若结果中存在”successful“，则表示已开启 OCSP Stapling 服务。</p>
<pre><code class="language-yml">OCSP response:
OCSP Response Data:
    OCSP Response Status: successful (0x0)
    Response Type: Basic OCSP Response
</code></pre>
<h5 id="证书算法优化">证书算法优化</h5>
<p>目前 SSL 密钥交换 + 签名有三种主流的方式：</p>
<ul>
<li>RSA 密钥交换（无需签名）。</li>
<li>ECDHE 密钥交换、RSA 签名。</li>
<li>ECDHE 密钥交换、ECDSA 签名。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transactional与锁]]></title>
        <id>https://q456qq520.github.io/post/transactional-yu-suo/</id>
        <link href="https://q456qq520.github.io/post/transactional-yu-suo/">
        </link>
        <updated>2024-01-31T08:42:43.000Z</updated>
        <content type="html"><![CDATA[<p>https://www.cnblogs.com/thisiswhy/p/15175380.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[计算机网络（一）]]></title>
        <id>https://q456qq520.github.io/post/ji-suan-ji-wang-luo-yi/</id>
        <link href="https://q456qq520.github.io/post/ji-suan-ji-wang-luo-yi/">
        </link>
        <updated>2023-10-12T09:03:03.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="计算机网络和因特网">计算机网络和因特网</h2>
<h3 id="11-什么是因特网">1.1 什么是因特网</h3>
<h4 id="111-相关组成">1.1.1 相关组成</h4>
<p>所有连接到因特网的设备都称为主机(host)或端系统，端系统通过<code>通信链路</code>和<code>分组交换机</code>连接到一起。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="计算机网络和因特网">计算机网络和因特网</h2>
<h3 id="11-什么是因特网">1.1 什么是因特网</h3>
<h4 id="111-相关组成">1.1.1 相关组成</h4>
<p>所有连接到因特网的设备都称为主机(host)或端系统，端系统通过<code>通信链路</code>和<code>分组交换机</code>连接到一起。</p>
<!-- more -->
<p>通信链路：物理媒体包括同轴电缆、铜线、光纤和无线电频谱。不同的链路能够以不同的速率传输数据，链路的传输速率以比特/秒(bit/s,或bps)度量。当一台端系 统要向另一台端系统发送数据时，发送端系统将数据分段，并为每段加上首部字节。由此 形成的信息包用计算机网络的术语来说称为分组(packet)。这些分组通过网络发送到目的端系统，在那里被装配成初始数据。</p>
<p>分组交换机：两种最著名的类型是路由器和链路层交换机。</p>
<h4 id="112-服务描述">1.1.2 服务描述</h4>
<p>运行在一个端系统上的应用程序怎样才 能指令因特网向运行在另一个端系统上的软件发送数据呢?</p>
<p>与因特网相连的端系统提供了一个<code>套接字接口</code>,该接口规定了运行 在一个端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交 付数据的方式。因特网套接字接口是一套发送程序必须遵循的规则集合，因此因特网能够 将数据交付给目的地。</p>
<h4 id="113什么是协议">1.1.3什么是协议</h4>
<p>在因特网中，涉及两个或多个远程通信实体的所有活动都受协议的制约。</p>
<p><mark>协议</mark> 定义了在两个或多个通信实体之间交换的报文的格式和顺 序，以及报文发送和/或接收一条报文或其他事件所采取的动作。</p>
<h3 id="12-网络边缘">1.2 网络边缘</h3>
<p>与因特网相连的计算机和其他设备因为它们位于因特网的边缘，故而被称为端系统。端系统也称为主机(host),因为它们容纳(即运行)应用程序。主机有时又被进一步划分为两类:客户(client)和服务器(server)。</p>
<h4 id="121-接入网">1.2.1 接入网</h4>
<p>将端系统物理连接到其边缘路由器的网络称为接入网。</p>
<h3 id="13-网络核心">1.3 网络核心</h3>
<h4 id="131-分组交换">1.3.1 分组交换</h4>
<p>在各种网络应用中，端系统彼此交换报文。<br>
为了从源端系统向目的端系统发送一个报文，源将长报文划分为较小的数据块，称之为<code>分组</code>。在源和目的地之间，每个分组都通过通信链路和分组交换机传送。(交换机主要有两类:路由器和链路层交换机)分组以等于该链路最大传输速率的速度传输通过通信链路。</p>
<ol>
<li>
<p>存储转发传输<br>
多数分组交换机在链路的输入端使用存储转发传输机制。</p>
</li>
<li>
<p>排队时延和分组丢失<br>
如果到达的分组需要传输到某条链路，但发现该链路正忙于传输其他分组，该到达分组必须在输出缓存中等待。因此，除了存储转发时延以外，分组还要承受输岀缓存的<mark>排队时延</mark>。因为缓存空间的大小是有限的。在此情况下，将出现分组<mark>丢失(丢包)</mark>,到达的分组或已经排队的分组之一将被丢弃。</p>
</li>
<li>
<p>转发表和路由选择协议<br>
当源主机要向目的端系统发 送一个分组时，源在该分组的首部包含了目的地的IP地址。每台路由器具有一个转发表,用于将目的地址(或目的地址的一部分)映射成为输岀链路。<br>
因特网具有一些特殊的路由选择协议,用于自动地设置这些转发表。</p>
</li>
</ol>
<h4 id="132-电路交换">1.3.2 电路交换</h4>
<p>通过网络链路和交换机移动数据有两种基本方法:电路交换和分组交换</p>
<p>在电路交换网络中，在端系统间通信会话期间，预留了端系统间沿路径通信所需要的 资源(缓存，链路传输速率)。</p>
<ol>
<li>
<p>电路交换网络中的复用<br>
链路中的电路是通过频分复用 ( Frequency- Division Multiplexing, FDM ) 或时分复用 (Time-Division Multiplexing, TDM)来实现的。对于FDM,链路的频谱由跨越链路创建的所有连接共享。特别是，在连接期间链路为每条连接专用一个频段，该频段的宽度称为带宽。</p>
</li>
<li>
<p>分组交换与电路交换的对比<br>
分组交换相比电路交换：提供了比电路交换更好的带宽共享;比电路交换更简单、更有效，实现<br>
成本更低。</p>
</li>
</ol>
<h3 id="14-分组交换网中的时延-丢包和吞吐量">1.4 分组交换网中的时延、丢包和吞吐量</h3>
<h4 id="141分组交换网中的时延概述">1.4.1分组交换网中的时延概述</h4>
<p>当分组从一个节点(主机或路由器)沿着这条路径到后继节 点(主机或路由器)，该分组在沿途的每个节点经受了几种不同类型的时延。这些时延最 为重要的是<code>节点处理时延</code>、<code>排队时延</code>、<code>传输时延</code>和<code>传播时延</code>,这些时延总体累加起来是<mark>节点总时延</mark>。</p>
<p><strong>时延的类型</strong></p>
<ol>
<li>处理时延<br>
检查分组首部和决定将该分组导向何处所需要的时间是处理时延的一部分。</li>
<li>排队时延<br>
在队列中，当分组在链路上等待传输时，它经受排队时延。</li>
<li>传输时延<br>
当所有已经 到达的分组被传输后，才能传输刚到达的分组。用L比特表示该分组的长度，用R bps(即b/s)表示从路由器A到路由器B的链路传输速率。传输时延是L/R</li>
<li>传播时延<br>
一旦一个比特被推向链路，该比特需要向路由器B传播。从该链路的起点到路由器B传播所需要的时间是传播时延。</li>
<li>传输时延和传播时延的比较<br>
传输时延是路由器推出分组所需要的时间，它是分组长度和链路传输速率的函 数，而与两台路由器之间的距离无关。另一方面，传播时延是一个比特从一台路由器传播 到另一台路由器所需要的时间，它是两台路由器之间距离的函数，而与分组长度或链路传输速率无关。</li>
</ol>
<h4 id="142排队时延和丢包">1.4.2排队时延和丢包</h4>
<p>R是传输速率，即从队列中推出比特的速率(以bps即b/s为单 位)。为了简单起见，也假定所有分组都是由L比特组成的。则比特到达队列的平均速率 是La bps。最后，假定该队列非常大，因此它基本能容纳无限数量的比特。比率La/R被称为<mark>流量强度</mark>,它在估计排队时延的范围方面经常起着重要的作用。如果La/R&gt;l,则比特到达队列的平均速率超过从该队列传输岀去的速率。在这种不幸的情 况下，该队列趋向于无限增加，并且排队时延将趋向无穷大!因此，流量工程中的一条金科玉律是:<strong>设计系统时流量强度不能大于1</strong>。</p>
<h5 id="丢包">丢包</h5>
<p>因为排队容量是有限的，随着流量强度接近1,排队时延并不真正趋向无穷大。相反，到达的分组将发现<br>
一个满的队列。由于没有地方存储这个分组，路由器将<mark>丢弃</mark>该分组，即该分组将出会<mark>丢失</mark>。</p>
<p>分组丢失的比例随着流量强度增加而增加。</p>
<h4 id="143端到端时延">1.4.3端到端时延</h4>
<p>总时延 = N台路由器（单台处理时延 + 传输时延 + 传播时延）</p>
<h4 id="144计算机网络中的吞吐量">1.4.4计算机网络中的吞吐量</h4>
<p>假设从主机A到主机B跨越计算机网络传送一个大文件，在任何时间瞬间的<mark>瞬时吞吐量</mark>是主机B接收到该文件的速率(以bps计)。如果该文件由F 比特组成，主机B接收到所有F 比特用去卩秒, 则文件传送的<mark>平均吞吐量</mark>是F/T bps。</p>
<p>吞吐量取决于数据流过的链路的传输速率。当没有其他干扰流量时，其吞吐量能够近似为沿着源和目的地之间路径的最小传输速率。<br>
吞吐量不仅取决于沿着路径的传输速率，而且取决于干扰流量。特别是，如果许多其他的数据流也通过这条链路流动，一条具有高传输速率的链 路仍然可能成为文件传输的瓶颈链路。</p>
<h3 id="15协议层次及其服务模型">1.5协议层次及其服务模型</h3>
<h4 id="151分层的体系结构">1.5.1分层的体系结构</h4>
<h5 id="协议分层">协议分层</h5>
<p>为了给网络协议的设计 提供一个结构，网络设计者以分层的方式组织协议以及实现这些协议的网络硬件和软件，每个协议属于这些层次之一。一个协议层能够用软件、硬件或两者的结合来实现。</p>
<p>各层的所有协议被称为协议栈因特网的协议栈由 5个层次组成:<code>物理层、链路层、网络层、运输层和应用层</code>。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1708935366126.png" alt="" loading="lazy"></figure>
<ol>
<li>应用层<br>
这是网络应用程序及它们的应用层协议存留的地方。因特网的应用层包括许多协议，例如HTTP(它提供了Web文档的请求和 传送)、SMTP (它提供了电子邮件报文的传输)和FTP (它提供两个端系统之间的文件传送)。</li>
</ol>
<p>应用层协议分布在多个端系统上，而一个端系统中的应用程序使用协议与另一个端系统中的应用程序交换信息分组，这种位于应用层的信息分组称为<mark>报文</mark>。</p>
<ol start="2">
<li>
<p>运输层<br>
因特网的运输层在应用程序端点之间传送应用层报文。<br>
运输层有两种运输协议，即<mark>TCP</mark>和<mark>UDP</mark>,利用其中的任一个都能运输应用层报文。TCP向它的应用程序提供了面向连接的服务。这种服务包括了应用层报文向目的地的确保传递和流量控制(即发送方/接收方速率匹配)。TCP也将长报文划分为短报文，并提供拥塞控制机制，因此当网络拥塞时，源抑制其传输速率。UDP协议向它的应用程序提供无连接服务。这是一种不提供 不必要服务的服务，没有可靠性，没有流量控制，也没有拥塞控制。我们把运输层的分组称为<mark>报文段</mark>。</p>
</li>
<li>
<p>网络层<br>
网络层负责将称为<mark>数据报</mark>的网络层分组从一台主机移动到另一台主机。<br>
网络层包括著名的网际协议IP,该协议定义了在数据报中的各个字段以及端 系统和路由器如何作用于这些字段。IP仅有一个，所有具有网络层的因特网组件必须运行 IP。因特网的网络层也包括决定路由的路由选择协议等。</p>
</li>
<li>
<p>链路层<br>
因特网的网络层通过源和目的地之间的一系列路由器路由数据报。为了将分组从一个 节 点 (主机或路由器)移动到路径上的下一个节点，网络层必须依靠该链路层的服务。特 别是在每个节点，网络层将数据报下传给链路层，链路层沿着路径将数据报传递给下一个节点。在该下一个节点，链路层将数据报上传给网络层。<br>
由链路层提供的服务取决于应用于该链路的特定链路层协议。我们把链路层分组称为<mark>帧</mark>。</p>
</li>
<li>
<p>物理层<br>
物理层的任务是将链路层帧中的一个个比特从一个节点移动到下一个节点。</p>
</li>
</ol>
<h5 id="osi模型">OSI模型</h5>
<p>7层是:应用层、表示层、会话层、运输层、网络层、数据链路层和物理层。</p>
<p>表示层的作用是使通信的应用程序能够解释交换数据的含义。这些服务包括数据压缩和数据加密(它们是自解释的)以及数据描述(这使得应用程序不必担心在各台计算机中表示/ 存储的内部格式不同的问题)。会话层提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。</p>
<h4 id="152-封装">1.5.2 封装</h4>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1708936416720.png" alt="" loading="lazy"></figure>
<p>在发送主机端，一个应用层(M)被传送给运输层。在最简单的情况下,运输层收取到报文并附上附加信息(所谓运输层首部信息，H1),该首部将被接收端的运输层使用。应用层报文和运输层首部信息一道构成了运输层报文段。运输层报文段因此<mark>封装</mark>了应用层报文。</p>
<p>运输层则向网络层传递该报文段，网络层增加了如源和目的端系统地址等网络层首部信息(Hn),生成了网络层数据报。该数据报接下来被传递给链路层，链路层增加它自己的链路层首部信息并生成链路层帧。在每一层，一个分组具有两种类型的字段:首部字段和有效载荷字段。有效载荷通常是来自上一层的分组。</p>
<h2 id="应用层">应用层</h2>
<h3 id="2-1-应用层协议原理">2. 1 应用层协议原理</h3>
<h4 id="2-1-1-网络应用程序体系结构">2. 1. 1 网络应用程序体系结构</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[最佳实践-springboot参数校验效率提升]]></title>
        <id>https://q456qq520.github.io/post/zui-jia-shi-jian-springboot-can-shu-xiao-yan-xiao-lu-ti-sheng/</id>
        <link href="https://q456qq520.github.io/post/zui-jia-shi-jian-springboot-can-shu-xiao-yan-xiao-lu-ti-sheng/">
        </link>
        <updated>2023-07-20T03:03:56.000Z</updated>
        <content type="html"><![CDATA[<h2 id="背景">背景</h2>
<p>随着语法糖或者工具包集成越来越多，现在参数校验已经不需要像往常那样写一大串的ifelse判断逻辑了。</p>
<p>常用的就有springboot中validation的引入大大的减少了工作量。</p>
<p>一般就是在实体类中添加 @NotNull等注解，再在入口处添加@Validated 的方式实现参数校验。这其中其实还可以偷懒，就是利用aop，全局进行参数校验，再统一增强返回，就不需要一个一个的加@Validated 了。</p>
<h2 id="全局参数校验">全局参数校验</h2>
<pre><code class="language-java"> public static &lt;T&gt; void postMethodException(T t) {
        if (t == null) {
            return;
        }
        ValidatorFactory factory = Validation.buildDefaultValidatorFactory();
        Validator validator = factory.getValidator();
        Set&lt;ConstraintViolation&lt;T&gt;&gt; violations = validator.validate(t);
        String errorMsg = violations.stream().map(ConstraintViolation::getMessage).collect(Collectors.joining(&quot;&amp;&quot;));
        if (StringUtils.isNotBlank(errorMsg)) {
            throw new PrescriptionException(ResultEnum.INPUT_PARAM_ERROR.getCode(), errorMsg);
        }
    }

    /**
     * 全局异常捕获
     */
    @ExceptionHandler(value = Exception.class)
    @ResponseBody
    public ResponseResult&lt;?&gt; otherException(Exception e) {
        log.error(&quot;catch other exception, e:&quot;, e);
        return ResponseResultUtil.failure(&quot;系统异常&quot;, ResultEnum.FAILURE.getCode(), e.getMessage());
    }

}

</code></pre>
<p>这是aop中部分代码贴图，不知道大家有没有发现问题，其中<br>
ValidatorFactory factory = Validation.buildDefaultValidatorFactory();<br>
Validator validator = factory.getValidator();</p>
<p>会导致校验效率十分低下，因为会频繁的new 工厂对象，导致gc频繁，造成性能瓶颈。</p>
<h2 id="解决办法">解决办法</h2>
<p>办法很简单。</p>
<pre><code class="language-java">public class ValidationUtils {

    private static Validator validator = Validation
            .byProvider(HibernateValidator.class)
            .configure()
            .failFast(true)
            .buildValidatorFactory()
            .getValidator();


    public static &lt;T&gt; void validate(T obj) {
        validator.validate(obj);
    }

}
</code></pre>
<p>既然知道了原因，那就不要让它一直创建就好了。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[最佳实践-数据库的模糊搜索]]></title>
        <id>https://q456qq520.github.io/post/zui-jia-shi-jian-shu-ju-ku-de-mo-hu-sou-suo/</id>
        <link href="https://q456qq520.github.io/post/zui-jia-shi-jian-shu-ju-ku-de-mo-hu-sou-suo/">
        </link>
        <updated>2023-07-20T01:11:04.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-常见场景">一 常见场景</h2>
<h3 id="11-数据库表创建">1.1 数据库表创建</h3>
<p>首先创建一个学生表并添加姓名的普通索引。</p>
<pre><code class="language-mysql">CREATE TABLE `school`.`student`  (
  `id` bigint(10) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `name` varchar(30) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL,
  `age` int(3) NULL DEFAULT NULL,
  `class_number` bigint(10) NULL DEFAULT NULL,
  `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
  `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `name`(`name`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;
</code></pre>
<p>并为其中填充几条数据：</p>
<pre><code class="language-mysql">INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (1, '张三', 10, 3, '2023-07-20 09:31:29', '2023-07-20 09:31:34');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (2, '李四', 11, 3, '2023-07-20 09:31:44', '2023-07-20 09:31:44');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (3, '王五', 10, 3, '2023-07-20 09:32:19', '2023-07-20 09:32:19');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (4, '盖伦', 9, 3, '2023-07-20 09:32:39', '2023-07-20 09:32:39');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (5, '普朗克', 10, 3, '2023-07-20 09:32:56', '2023-07-20 09:32:56');
INSERT INTO `school`.`student` (`id`, `name`, `age`, `class_number`, `create_time`, `update_time`) VALUES (6, '卡特', 12, 3, '2023-07-20 09:34:31', '2023-07-20 09:34:31');
</code></pre>
<h3 id="12-查询案例">1.2 查询案例</h3>
<p>假设现在有需要对<code>name</code>进行模糊查询，sql如下：</p>
<pre><code class="language-mysql">select * from student where name like '%王%';
</code></pre>
<h3 id="13-案例分析">1.3 案例分析</h3>
<p>用<code>EXPLAIN</code>看看执行计划：<br>
<img src="https://q456qq520.github.io/post-images/1689817827264.png" alt="" loading="lazy"></p>
<p>从图中发现是没有走索引的。那怎么办？索引岂不是白建了？</p>
<h3 id="14-解决方法">1.4 解决方法</h3>
<p>别慌，先给你支一招，如下图：<br>
<img src="https://q456qq520.github.io/post-images/1689817985469.png" alt="" loading="lazy"></p>
<p>走最左侧原则，去掉左边的通配符，就可以发现能走索引了。</p>
<p>产品：我要的就是要全模糊，不要一边模糊搜索。</p>
<p>那该怎么办呢？</p>
<h3 id="15-全文索引">1.5 全文索引</h3>
<p>这时候可以采用终极杀招，使用mysql 自带的全文索引。不懂全文索引的可以先去了解一下。简而言之能实现我们全模糊的要求还走索引，是一种空间换时间的典型。</p>
<pre><code class="language-mysql">create fulltext index name_fulltext on student(name) WITH PARSER ngram;;
</code></pre>
<p>首先建立一个name的全文索引。</p>
<p>接着采用全文索引提供的布尔查询(也可以在查询参数上加通配符*)：</p>
<pre><code class="language-mysql">select * from student where match(name) against('朗' IN BOOLEAN MODE);
select * from student where MATCH ( name ) against ( '王' IN NATURAL LANGUAGE MODE );
</code></pre>
<p>发现，结果啥也没有。什么情况？</p>
<p>这个问题有很多原因，其中最常见的就是<mark>最小搜索长度</mark>导致的。</p>
<p>MySQL 中的全文索引，有两个变量，最小搜索长度和最大搜索长度，对于长度小于最小搜索长度和大于最大搜索长度的词语，都不会被索引。通俗点就是说，想对一个词语使用全文索引搜索，那么这个词语的长度必须在以上两个变量的区间内。</p>
<p>这两个的默认值可以使用以下命令查看</p>
<pre><code class="language-mysql">show variables like '%ft%';
</code></pre>
<p>可以看到这两个变量在 MyISAM 和 InnoDB 两种存储引擎下的变量名和默认值</p>
<pre><code class="language-mysql">// MyISAM
ft_min_word_len = 4;
ft_max_word_len = 84;

// InnoDB
innodb_ft_min_token_size = 3;
innodb_ft_max_token_size = 84;
</code></pre>
<p>可以看到最小搜索长度 MyISAM 引擎下默认是 4，InnoDB 引擎下是 3，也即，MySQL 的全文索引只会对长度大于等于 4 或者 3 的词语建立索引，而刚刚搜索的长度大于等于 4。</p>
<h4 id="配置最小搜索长度">配置最小搜索长度</h4>
<p>全文索引的相关参数都无法进行动态修改，必须通过修改 MySQL 的配置文件来完成。修改最小搜索长度的值为 1，首先打开 MySQL 的配置文件 /etc/my.cnf，在 [mysqld] 的下面追加以下内容</p>
<pre><code class="language-mysql">[mysqld]
innodb_ft_min_token_size = 1
ft_min_word_len = 1
</code></pre>
<blockquote>
<p>可以使用以下命令查询配置文件路径<br>
mysql --help|grep 'my.cnf'</p>
</blockquote>
<p>然后重启 MySQL 服务器，并修复全文索引。<br>
⚠️注意，修改完参数以后，一定要修复下索引，不然参数不会生效。</p>
<p>两种方式，一种是重建索引，一种是执行命令。</p>
<pre><code class="language-mysql">repair table student quick;
</code></pre>
<p>MySQL 的全文索引最开始仅支持英语，因为英语的词与词之间有空格，使用空格作为分词的分隔符是很方便的。亚洲文字，比如汉语、日语、汉语等，是没有空格的，这就造成了一定的限制。不过 MySQL 5.7.6 开始，引入了一个 ngram 全文分析器来解决这个问题，并且对 MyISAM 和 InnoDB 引擎都有效。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1689820849998.png" alt="" loading="lazy"></figure>
<p>再次执行执行计划，可以看到现在是走索引了。</p>
<h3 id="16-elasticsearch">1.6 ElasticSearch</h3>
<p>还有一个执行效率更高更快的办法，那就是引入ES。这里不过多介绍，大概方案就是，用text类型对需要模糊查询对词进行分词，其次是利用match查询进行模糊查询。要达到模糊的效果，首先是要对中英文采取不同对分词器，然后利用match的<mark>Operator.AND</mark>熟悉进行查询。</p>
<blockquote>
<p>Operator.AND和Operator.OR是用于设置match查询的操作符的枚举类型。它们的区别在于如何处理多个查询词的匹配逻辑：<br>
Operator.AND：使用AND操作符，表示所有的查询词都必须出现在匹配的文档中。只有当文档中同时包含所有的查询词时，才会被匹配到。<br>
Operator.OR：使用OR操作符，表示只要文档中包含任何一个查询词，就会被匹配到。只要文档中包含至少一个查询词，就会被视为匹配。</p>
</blockquote>
<p>具体案例为：</p>
<pre><code class="language-json">{
  &quot;from&quot;: 0,
  &quot;size&quot;: 20,
  &quot;timeout&quot;: &quot;60s&quot;,
  &quot;query&quot;: {
    &quot;bool&quot;: {
      &quot;must&quot;: [
        {
          &quot;exists&quot;: {
            &quot;field&quot;: &quot;yb_code&quot;,
            &quot;boost&quot;: 1
          }
        },
        {
          &quot;match&quot;: {
            &quot;name&quot;: {
              &quot;query&quot;: &quot;高血压&quot;,
              &quot;operator&quot;: &quot;AND&quot;,
              &quot;prefix_length&quot;: 0,
              &quot;max_expansions&quot;: 50,
              &quot;fuzzy_transpositions&quot;: true,
              &quot;lenient&quot;: false,
              &quot;zero_terms_query&quot;: &quot;NONE&quot;,
              &quot;auto_generate_synonyms_phrase_query&quot;: true,
              &quot;boost&quot;: 1
            }
          }
        }
      ],
      &quot;filter&quot;: [
        {
          &quot;bool&quot;: {
            &quot;must&quot;: [
              {
                &quot;term&quot;: {
                  &quot;category&quot;: {
                    &quot;value&quot;: 1,
                    &quot;boost&quot;: 1
                  }
                }
              }
            ],
            &quot;adjust_pure_negative&quot;: true,
            &quot;boost&quot;: 1
          }
        }
      ],
      &quot;adjust_pure_negative&quot;: true,
      &quot;boost&quot;: 1
    }
  },
  &quot;sort&quot;: [
    {
      &quot;name_length&quot;: {
        &quot;order&quot;: &quot;asc&quot;
      }
    },
    {
      &quot;id&quot;: {
        &quot;order&quot;: &quot;asc&quot;
      }
    }
  ]
}
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1689821426314.png" alt="" loading="lazy"></figure>
<p>其中match可以用matchPhrase,但是效果没有match好，或者使用wildcardQuery这种通配符查询的方式也可以。</p>
<p>PS：<br>
如果想看某个字段分词情况，可以用下面的请求：<br>
GET  https://{ip}:{port}/index/_doc/{id}/_termvectors?fields={field}</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[秒杀系统常见问题]]></title>
        <id>https://q456qq520.github.io/post/miao-sha-xi-tong-chang-jian-wen-ti/</id>
        <link href="https://q456qq520.github.io/post/miao-sha-xi-tong-chang-jian-wen-ti/">
        </link>
        <updated>2023-05-19T02:02:57.000Z</updated>
        <content type="html"><![CDATA[<h2 id="超卖问题">超卖问题</h2>
<p>秒杀系统主要应用在商品抢购的场景，比如：</p>
<ul>
<li>电商抢购限量商品</li>
<li>卖演唱会的门票</li>
<li>火车票抢座<br>
…</li>
</ul>
<p>秒杀系统抽象来说就是以下几个步骤：</p>
<ul>
<li>用户选定商品下单</li>
<li>校验库存</li>
<li>扣库存</li>
<li>创建用户订单</li>
</ul>
<p>对于秒杀系统来说，严格防止超卖是一件十分重要的事情。下面我们看一下超卖问题出现的原因与解决办法。</p>
<h3 id="建立简易的数据库表结构">建立“简易”的数据库表结构</h3>
<p>一张库存表stock，一张订单表stock_order</p>
<pre><code class="language-java">-- ----------------------------
-- Table structure for stock
-- ----------------------------
DROP TABLE IF EXISTS `stock`;
CREATE TABLE `stock` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称',
  `count` int(11) NOT NULL COMMENT '库存',
  `sale` int(11) NOT NULL COMMENT '已售',
  `version` int(11) NOT NULL COMMENT '乐观锁，版本号',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Table structure for stock_order
-- ----------------------------
DROP TABLE IF EXISTS `stock_order`;
CREATE TABLE `stock_order` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `sid` int(11) NOT NULL COMMENT '库存ID',
  `name` varchar(30) NOT NULL DEFAULT '' COMMENT '商品名称',
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
</code></pre>
<h3 id="相应代码">相应代码</h3>
<h5 id="controller层代码">Controller层代码</h5>
<p>提供一个HTTP接口: 参数为商品的Id</p>
<pre><code class="language-java">@RequestMapping(&quot;/createWrongOrder/{sid}&quot;)
@ResponseBody
public String createWrongOrder(@PathVariable int sid) {
    LOGGER.info(&quot;购买物品编号sid=[{}]&quot;, sid);
    int id = 0;
    try {
        id = orderService.createWrongOrder(sid);
        LOGGER.info(&quot;创建订单id: [{}]&quot;, id);
    } catch (Exception e) {
        LOGGER.error(&quot;Exception&quot;, e);
    }
    return String.valueOf(id);
}
</code></pre>
<h5 id="service层代码">Service层代码</h5>
<pre><code class="language-java">@Override
public int createWrongOrder(int sid) throws Exception {
    //校验库存
    Stock stock = checkStock(sid);
    //扣库存
    saleStock(stock);
    //创建订单
    int id = createOrder(stock);
    return id;
}

private Stock checkStock(int sid) {
    Stock stock = stockService.getStockById(sid);
    if (stock.getSale().equals(stock.getCount())) {
        throw new RuntimeException(&quot;库存不足&quot;);
    }
    return stock;
}

private int saleStock(Stock stock) {
    stock.setSale(stock.getSale() + 1);
    return stockService.updateStockById(stock);
}

private int createOrder(Stock stock) {
    StockOrder order = new StockOrder();
    order.setSid(stock.getId());
    order.setName(stock.getName());
    int id = orderMapper.insertSelective(order);
    return id;
}
</code></pre>
<h4 id="发起并发购买请求">发起并发购买请求</h4>
<blockquote>
<p>https://www.cnblogs.com/stulzq/p/8971531.html<br>
在JMeter里启动1000个线程，无延迟同时访问接口。模拟1000个人，抢购100个产品的场景。点击启动。</p>
</blockquote>
<p>结果卖出了14个，库存减少了14个，但是每个请求Spring都处理了，创建了1000个订单。</p>
<h4 id="避免超卖问题更新商品库存的版本号">避免超卖问题：更新商品库存的版本号</h4>
<p>为了解决上面的超卖问题，我们当然可以在Service层给更新表添加一个事务，这样每个线程更新请求的时候都会先去锁表的这一行（悲观锁），更新完库存后再释放锁。可这样就太慢了，1000个线程可等不及。</p>
<p>我们需要乐观锁。</p>
<p>一个最简单的办法就是，给每个商品库存一个版本号version字段</p>
<p>我们修改代码：</p>
<h5 id="controller层">Controller层</h5>
<pre><code class="language-java">/**
 * 乐观锁更新库存
 * @param sid
 * @return
 */
@RequestMapping(&quot;/createOptimisticOrder/{sid}&quot;)
@ResponseBody
public String createOptimisticOrder(@PathVariable int sid) {
    int id;
    try {
        id = orderService.createOptimisticOrder(sid);
        LOGGER.info(&quot;购买成功，剩余库存为: [{}]&quot;, id);
    } catch (Exception e) {
        LOGGER.error(&quot;购买失败：[{}]&quot;, e.getMessage());
        return &quot;购买失败，库存不足&quot;;
    }
    return String.format(&quot;购买成功，剩余库存为：%d&quot;, id);
</code></pre>
<h5 id="service层">Service层</h5>
<pre><code class="language-java">@Override
public int createOptimisticOrder(int sid) throws Exception {
    //校验库存
    Stock stock = checkStock(sid);
    //乐观锁更新库存
    saleStockOptimistic(stock);
    //创建订单
    int id = createOrder(stock);
    return stock.getCount() - (stock.getSale()+1);
}

private void saleStockOptimistic(Stock stock) {
    LOGGER.info(&quot;查询数据库，尝试更新库存&quot;);
    int count = stockService.updateStockByOptimistic(stock);
    if (count == 0){
        throw new RuntimeException(&quot;并发更新库存失败，version不匹配&quot;) ;
    }
}
</code></pre>
<h5 id="mapper">Mapper</h5>
<pre><code class="language-xml">&lt;update id=&quot;updateByOptimistic&quot; parameterType=&quot;cn.monitor4all.miaoshadao.dao.Stock&quot;&gt;
    update stock
    &lt;set&gt;
      sale = sale + 1,
      version = version + 1,
    &lt;/set&gt;
    WHERE id = #{id,jdbcType=INTEGER}
    AND version = #{version,jdbcType=INTEGER}
  &lt;/update&gt;
</code></pre>
<p>我们在实际减库存的SQL操作中，首先判断version是否是我们查询库存时候的version，如果是，扣减库存，成功抢购。如果发现version变了，则不更新数据库，返回抢购失败。</p>
<p>再次打开JMeter，把库存恢复为100，清空订单表，发起1000次请求。</p>
<p>这次的结果是：</p>
<p>卖出去了39个，version更新为了39,同时创建了39个订单。我们没有超卖，可喜可贺。</p>
<p>由于并发访问的原因，很多线程更新库存失败了，所以在我们这种设计下，1000个人真要是同时发起购买，只有39个幸运儿能够买到东西，但是我们防止了超卖。</p>
<h2 id="令牌桶限流-再谈超卖">令牌桶限流 + 再谈超卖</h2>
<h3 id="接口限流">接口限流</h3>
<p>在面临高并发的请购请求时，我们如果不对接口进行限流，可能会对后台系统造成极大的压力。尤其是对于下单的接口，过多的请求打到数据库会对系统的稳定性造成影响。</p>
<p>所以秒杀系统会尽量选择独立于公司其他后端系统之外进行单独部署，以免秒杀业务崩溃影响到其他系统。</p>
<p>除了独立部署秒杀业务之外，我们能够做的就是尽量让后台系统稳定优雅的处理大量请求。</p>
<h5 id="令牌桶算法与漏桶算法">令牌桶算法与漏桶算法</h5>
<blockquote>
<p>漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会直接溢出，可以看出漏桶算法能强行限制数据的传输速率。</p>
</blockquote>
<p>令牌桶算法不能与另外一种常见算法漏桶算法相混淆。这两种算法的主要区别在于：</p>
<p>漏桶算法能够强行限制数据的传输速率，而令牌桶算法在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在令牌桶算法中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，因此它适合于具有突发特性的流量。</p>
<h5 id="使用guava的ratelimiter实现令牌桶限流接口">使用Guava的RateLimiter实现令牌桶限流接口</h5>
<p>Guava是只提供了令牌桶的一种实现，实际项目中肯定还要根据需求来使用或者自己实现，大家可以看看这篇文章：<br>
https://segmentfault.com/a/1190000012875897</p>
<blockquote>
<p>OrderController</p>
</blockquote>
<pre><code class="language-java">@Controller
public class OrderController {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrderController.class);

    @Autowired
    private StockService stockService;

    @Autowired
    private OrderService orderService;

    //每秒放行10个请求
    RateLimiter rateLimiter = RateLimiter.create(10);

    @RequestMapping(&quot;/createWrongOrder/{sid}&quot;)
    @ResponseBody
    public String createWrongOrder(@PathVariable int sid) {
        int id = 0;
        try {
            id = orderService.createWrongOrder(sid);
            LOGGER.info(&quot;创建订单id: [{}]&quot;, id);
        } catch (Exception e) {
            LOGGER.error(&quot;Exception&quot;, e);
        }
        return String.valueOf(id);
    }

    /**
     * 乐观锁更新库存 + 令牌桶限流
     * @param sid
     * @return
     */
    @RequestMapping(&quot;/createOptimisticOrder/{sid}&quot;)
    @ResponseBody
    public String createOptimisticOrder(@PathVariable int sid) {
        // 阻塞式获取令牌
        //LOGGER.info(&quot;等待时间&quot; + rateLimiter.acquire());
        // 非阻塞式获取令牌
        if (!rateLimiter.tryAcquire(1000, TimeUnit.MILLISECONDS)) {
            LOGGER.warn(&quot;你被限流了，真不幸，直接返回失败&quot;);
            return &quot;购买失败，库存不足&quot;;
        }
        int id;
        try {
            id = orderService.createOptimisticOrder(sid);
            LOGGER.info(&quot;购买成功，剩余库存为: [{}]&quot;, id);
        } catch (Exception e) {
            LOGGER.error(&quot;购买失败：[{}]&quot;, e.getMessage());
            return &quot;购买失败，库存不足&quot;;
        }
        return String.format(&quot;购买成功，剩余库存为：%d&quot;, id);
    }
}
</code></pre>
<p>代码中，RateLimiter rateLimiter = RateLimiter.create(10);这里初始化了令牌桶类，每秒放行10个请求。</p>
<p>在接口中，可以看到有两种使用方法：</p>
<ol>
<li>阻塞式获取令牌：请求进来后，若令牌桶里没有足够的令牌，就在这里阻塞住，等待令牌的发放。</li>
<li>非阻塞式获取令牌：请求进来后，若令牌桶里没有足够的令牌，会尝试等待设置好的时间（这里写了1000ms），其会自动判断在1000ms后，这个请求能不能拿到令牌，如果不能拿到，直接返回抢购失败。如果timeout设置为0，则等于阻塞时获取令牌。</li>
</ol>
<h3 id="再谈防止超卖">再谈防止超卖</h3>
<p>讲完了令牌桶限流算法，我们再回头思考超卖的问题，在海量请求的场景下，如果像第一篇文章那样的使用乐观锁，会导致大量的请求返回抢购失败，用户体验极差。</p>
<p>然而使用悲观锁，比如数据库事务，则可以让数据库一个个处理库存数修改，修改成功后再迎接下一个请求，所以在不同情况下，应该根据实际情况使用悲观锁和乐观锁。</p>
<h4 id="实现不需要版本号字段的乐观锁">实现不需要版本号字段的乐观锁</h4>
<pre><code class="language-xml">&lt;update id=&quot;updateByOptimistic&quot; parameterType=&quot;cn.monitor4all.miaoshadao.dao.Stock&quot;&gt;
    update stock
    &lt;set&gt;
      sale = sale + 1,
    &lt;/set&gt;
    WHERE id = #{id,jdbcType=INTEGER}
    AND sale = #{sale,jdbcType=INTEGER}
&lt;/update&gt;
</code></pre>
<h4 id="实现悲观锁">实现悲观锁</h4>
<blockquote>
<p>Controller</p>
</blockquote>
<pre><code class="language-java">/**
 * 事务for update更新库存
 * @param sid
 * @return
 */
@RequestMapping(&quot;/createPessimisticOrder/{sid}&quot;)
@ResponseBody
public String createPessimisticOrder(@PathVariable int sid) {
    int id;
    try {
        id = orderService.createPessimisticOrder(sid);
        LOGGER.info(&quot;购买成功，剩余库存为: [{}]&quot;, id);
    } catch (Exception e) {
        LOGGER.error(&quot;购买失败：[{}]&quot;, e.getMessage());
        return &quot;购买失败，库存不足&quot;;
    }
    return String.format(&quot;购买成功，剩余库存为：%d&quot;, id);
}
</code></pre>
<p>在Service中,给该卖商品流程加上事务:</p>
<pre><code class="language-java">@Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRED)
@Override
public int createPessimisticOrder(int sid){
    //校验库存(悲观锁for update)
    Stock stock = checkStockForUpdate(sid);
    //更新库存
    saleStock(stock);
    //创建订单
    int id = createOrder(stock);
    return stock.getCount() - (stock.getSale());
}

/**
 * 检查库存 ForUpdate
 * @param sid
 * @return
 */
private Stock checkStockForUpdate(int sid) {
    Stock stock = stockService.getStockByIdForUpdate(sid);
    if (stock.getSale().equals(stock.getCount())) {
        throw new RuntimeException(&quot;库存不足&quot;);
    }
    return stock;
}

/**
 * 更新库存
 * @param stock
 */
private void saleStock(Stock stock) {
    stock.setSale(stock.getSale() + 1);
    stockService.updateStockById(stock);
}

/**
 * 创建订单
 * @param stock
 * @return
 */
private int createOrder(Stock stock) {
    StockOrder order = new StockOrder();
    order.setSid(stock.getId());
    order.setName(stock.getName());
    int id = orderMapper.insertSelective(order);
    return id;
}
</code></pre>
<p>这里使用Spring的事务，@Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRED)，如果遇到回滚，则返回Exception，并且事务传播使用PROPAGATION_REQUIRED–支持当前事务，如果当前没有事务，就新建一个事务。</p>
<p>所以，悲观锁在大量请求的请求下，有着更好的卖出成功率。但是需要注意的是，如果请求量巨大，悲观锁会导致后面的请求进行了长时间的阻塞等待，用户就必须在页面等待，很像是“假死”，可以通过配合令牌桶限流，或者是给用户显著的等待提示来优化。</p>
<h2 id="抢购接口隐藏-单用户限制频率">抢购接口隐藏 + 单用户限制频率</h2>
<h3 id="抢购接口隐藏">抢购接口隐藏</h3>
<p>抢购接口隐藏（接口加盐）的具体做法：</p>
<ul>
<li>每次点击秒杀按钮，先从服务器获取一个秒杀验证值（接口内判断是否到秒杀时间）。</li>
<li>Redis以缓存用户ID和商品ID为Key，秒杀地址为Value缓存验证值</li>
<li>用户请求秒杀商品的时候，要带上秒杀验证值进行校验。</li>
</ul>
<p>理论上来说在访问接口的时间上受到了限制，并且我们还能通过在验证值接口增加更复杂的逻辑，让获取验证值的接口并不快速返回验证值，进一步拉平普通用户和坏蛋们的下单时刻。所以接口加盐还是有用的！</p>
<blockquote>
<p>加盐代码逻辑实现<br>
代码还是使用之前的项目，我们在其上面增加两个接口：</p>
</blockquote>
<ul>
<li>获取验证值接口</li>
<li>携带验证值下单接口</li>
</ul>
<p>由于之前我们只有两个表，一个stock表放库存商品，一个stockOrder订单表，放订购成功的记录。但是这次涉及到了用户，所以我们新增用户表，并且添加一个用户张三。并且在订单表中，不仅要记录商品id，同时要写入用户id。</p>
<p>整个SQL结构如下，讲究一个简洁，暂时不加入别的多余字段：</p>
<pre><code class="language-sql">-- ----------------------------
-- Table structure for stock
-- ----------------------------
DROP TABLE IF EXISTS `stock`;
CREATE TABLE `stock` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称',
  `count` int(11) NOT NULL COMMENT '库存',
  `sale` int(11) NOT NULL COMMENT '已售',
  `version` int(11) NOT NULL COMMENT '乐观锁，版本号',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of stock
-- ----------------------------
INSERT INTO `stock` VALUES ('1', 'iphone', '50', '0', '0');
INSERT INTO `stock` VALUES ('2', 'mac', '10', '0', '0');

-- ----------------------------
-- Table structure for stock_order
-- ----------------------------
DROP TABLE IF EXISTS `stock_order`;
CREATE TABLE `stock_order` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `sid` int(11) NOT NULL COMMENT '库存ID',
  `name` varchar(30) NOT NULL DEFAULT '' COMMENT '商品名称',
  `user_id` int(11) NOT NULL DEFAULT '0',
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of stock_order
-- ----------------------------

-- ----------------------------
-- Table structure for user
-- ----------------------------
DROP TABLE IF EXISTS `user`;
CREATE TABLE `user` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `user_name` varchar(255) NOT NULL DEFAULT '',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of user
-- ----------------------------
INSERT INTO `user` VALUES ('1', '张三');
</code></pre>
<h5 id="获取验证值接口">获取验证值接口</h5>
<p>该接口要求传用户id和商品id，返回验证值，并且该验证值</p>
<p>Controller中添加方法：</p>
<pre><code class="language-java">/**
 * 获取验证值
 * @return
 */
@RequestMapping(value = &quot;/getVerifyHash&quot;, method = {RequestMethod.GET})
@ResponseBody
public String getVerifyHash(@RequestParam(value = &quot;sid&quot;) Integer sid,
                            @RequestParam(value = &quot;userId&quot;) Integer userId) {
    String hash;
    try {
        hash = userService.getVerifyHash(sid, userId);
    } catch (Exception e) {
        LOGGER.error(&quot;获取验证hash失败，原因：[{}]&quot;, e.getMessage());
        return &quot;获取验证hash失败&quot;;
    }
    return String.format(&quot;请求抢购验证hash值为：%s&quot;, hash);
}
</code></pre>
<p>UserService中添加方法：</p>
<pre><code class="language-java">@Override
public String getVerifyHash(Integer sid, Integer userId) throws Exception {

    // 验证是否在抢购时间内
    LOGGER.info(&quot;请自行验证是否在抢购时间内&quot;);


    // 检查用户合法性
    User user = userMapper.selectByPrimaryKey(userId.longValue());
    if (user == null) {
        throw new Exception(&quot;用户不存在&quot;);
    }
    LOGGER.info(&quot;用户信息：[{}]&quot;, user.toString());

    // 检查商品合法性
    Stock stock = stockService.getStockById(sid);
    if (stock == null) {
        throw new Exception(&quot;商品不存在&quot;);
    }
    LOGGER.info(&quot;商品信息：[{}]&quot;, stock.toString());

    // 生成hash
    String verify = SALT + sid + userId;
    String verifyHash = DigestUtils.md5DigestAsHex(verify.getBytes());

    // 将hash和用户商品信息存入redis
    String hashKey = CacheKey.HASH_KEY.getKey() + &quot;_&quot; + sid + &quot;_&quot; + userId;
    stringRedisTemplate.opsForValue().set(hashKey, verifyHash, 3600, TimeUnit.SECONDS);
    LOGGER.info(&quot;Redis写入：[{}] [{}]&quot;, hashKey, verifyHash);
    return verifyHash;
}
</code></pre>
<p>一个Cache常量枚举类CacheKey：</p>
<pre><code class="language-java">package cn.monitor4all.miaoshadao.utils;

public enum CacheKey {
    HASH_KEY(&quot;miaosha_hash&quot;),
    LIMIT_KEY(&quot;miaosha_limit&quot;);

    private String key;

    private CacheKey(String key) {
        this.key = key;
    }
    public String getKey() {
        return key;
    }
}
</code></pre>
<p>可以看到在Service中，我们拿到用户id和商品id后，会检查商品和用户信息是否在表中存在，并且会验证现在的时间（我这里为了简化，只是写了一行LOGGER，大家可以根据需求自行实现）。在这样的条件过滤下，才会给出hash值。并且将Hash值写入了Redis中，缓存3600秒（1小时），如果用户拿到这个hash值一小时内没下单，则需要重新获取hash值。</p>
<p>想一下，这个hash值，如果每次都按照商品+用户的信息来md5，是不是不太安全呢。毕竟用户id并不一定是用户不知道的（就比如我这种用自增id存储的，肯定不安全），而商品id，万一也泄露了出去，那么如果再知到我们是简单的md5，那直接就把hash算出来了！</p>
<p>在代码里，我给hash值加了个前缀，也就是一个salt（盐），相当于给这个固定的字符串撒了一把盐，这个盐是HASH_KEY(&quot;miaosha_hash&quot;)，写死在了代码里。这样黑产只要不猜到这个盐，就没办法算出来hash值。</p>
<p>这也只是一种例子，实际中，你可以把盐放在其他地方， 并且不断变化，或者结合时间戳，这样就算自己的程序员也没法知道hash值的原本字符串是什么了。</p>
<h5 id="携带验证值下单接口">携带验证值下单接口</h5>
<p>用户在前台拿到了验证值后，点击下单按钮，前端携带着特征值，即可进行下单操作。</p>
<p>Controller中添加方法：</p>
<pre><code class="language-java">/**
 * 要求验证的抢购接口
 * @param sid
 * @return
 */
@RequestMapping(value = &quot;/createOrderWithVerifiedUrl&quot;, method = {RequestMethod.GET})
@ResponseBody
public String createOrderWithVerifiedUrl(@RequestParam(value = &quot;sid&quot;) Integer sid,
                                         @RequestParam(value = &quot;userId&quot;) Integer userId,
                                         @RequestParam(value = &quot;verifyHash&quot;) String verifyHash) {
    int stockLeft;
    try {
        stockLeft = orderService.createVerifiedOrder(sid, userId, verifyHash);
        LOGGER.info(&quot;购买成功，剩余库存为: [{}]&quot;, stockLeft);
    } catch (Exception e) {
        LOGGER.error(&quot;购买失败：[{}]&quot;, e.getMessage());
        return e.getMessage();
    }
    return String.format(&quot;购买成功，剩余库存为：%d&quot;, stockLeft);
}
</code></pre>
<p>OrderService中添加方法：</p>
<pre><code class="language-java">@Override
public int createVerifiedOrder(Integer sid, Integer userId, String verifyHash) throws Exception {

    // 验证是否在抢购时间内
    LOGGER.info(&quot;请自行验证是否在抢购时间内,假设此处验证成功&quot;);

    // 验证hash值合法性
    String hashKey = CacheKey.HASH_KEY.getKey() + &quot;_&quot; + sid + &quot;_&quot; + userId;
    String verifyHashInRedis = stringRedisTemplate.opsForValue().get(hashKey);
    if (!verifyHash.equals(verifyHashInRedis)) {
        throw new Exception(&quot;hash值与Redis中不符合&quot;);
    }
    LOGGER.info(&quot;验证hash值合法性成功&quot;);

    // 检查用户合法性
    User user = userMapper.selectByPrimaryKey(userId.longValue());
    if (user == null) {
        throw new Exception(&quot;用户不存在&quot;);
    }
    LOGGER.info(&quot;用户信息验证成功：[{}]&quot;, user.toString());

    // 检查商品合法性
    Stock stock = stockService.getStockById(sid);
    if (stock == null) {
        throw new Exception(&quot;商品不存在&quot;);
    }
    LOGGER.info(&quot;商品信息验证成功：[{}]&quot;, stock.toString());

    //乐观锁更新库存
    saleStockOptimistic(stock);
    LOGGER.info(&quot;乐观锁更新库存成功&quot;);

    //创建订单
    createOrderWithUserInfo(stock, userId);
    LOGGER.info(&quot;创建订单成功&quot;);

    return stock.getCount() - (stock.getSale()+1);
}
</code></pre>
<h3 id="单用户限制频率">单用户限制频率</h3>
<p>假设我们做好了接口隐藏，但是像我上面说的，总有无聊的人会写一个复杂的脚本，先请求hash值，再立刻请求购买，如果你的app下单按钮做的很差，大家都要开抢后0.5秒才能请求成功，那可能会让脚本依然能够在大家前面抢购成功。</p>
<p>我们需要在做一个额外的措施，来限制单个用户的抢购频率。</p>
<p>其实很简单的就能想到用redis给每个用户做访问统计，甚至是带上商品id，对单个商品做访问统计，这都是可行的。</p>
<p>我们先实现一个对用户的访问频率限制，我们在用户申请下单时，检查用户的访问次数，超过访问次数，则不让他下单！</p>
<h5 id="使用redismemcached">使用Redis/Memcached</h5>
<p>我们使用外部缓存来解决问题，这样即便是分布式的秒杀系统，请求被随意分流的情况下，也能做到精准的控制每个用户的访问次数。</p>
<p>Controller中添加方法：</p>
<pre><code class="language-java">/**
 * 要求验证的抢购接口 + 单用户限制访问频率
 * @param sid
 * @return
 */
@RequestMapping(value = &quot;/createOrderWithVerifiedUrlAndLimit&quot;, method = {RequestMethod.GET})
@ResponseBody
public String createOrderWithVerifiedUrlAndLimit(@RequestParam(value = &quot;sid&quot;) Integer sid,
                                                 @RequestParam(value = &quot;userId&quot;) Integer userId,
                                                 @RequestParam(value = &quot;verifyHash&quot;) String verifyHash) {
    int stockLeft;
    try {
        int count = userService.addUserCount(userId);
        LOGGER.info(&quot;用户截至该次的访问次数为: [{}]&quot;, count);
        boolean isBanned = userService.getUserIsBanned(userId);
        if (isBanned) {
            return &quot;购买失败，超过频率限制&quot;;
        }
        stockLeft = orderService.createVerifiedOrder(sid, userId, verifyHash);
        LOGGER.info(&quot;购买成功，剩余库存为: [{}]&quot;, stockLeft);
    } catch (Exception e) {
        LOGGER.error(&quot;购买失败：[{}]&quot;, e.getMessage());
        return e.getMessage();
    }
    return String.format(&quot;购买成功，剩余库存为：%d&quot;, stockLeft);
}
</code></pre>
<p>UserService中增加两个方法：</p>
<ul>
<li>addUserCount：每当访问订单接口，则增加一次访问次数，写入Redis</li>
<li>getUserIsBanned：从Redis读出该用户的访问次数，超过10次则不让购买了！不能让张三做法外狂徒。</li>
</ul>
<pre><code class="language-java">@Override
    public int addUserCount(Integer userId) throws Exception {
        String limitKey = CacheKey.LIMIT_KEY.getKey() + &quot;_&quot; + userId;
        String limitNum = stringRedisTemplate.opsForValue().get(limitKey);
        int limit = -1;
        if (limitNum == null) {
            stringRedisTemplate.opsForValue().set(limitKey, &quot;0&quot;, 3600, TimeUnit.SECONDS);
        } else {
            limit = Integer.parseInt(limitNum) + 1;
            stringRedisTemplate.opsForValue().set(limitKey, String.valueOf(limit), 3600, TimeUnit.SECONDS);
        }
        return limit;
    }

    @Override
    public boolean getUserIsBanned(Integer userId) {
        String limitKey = CacheKey.LIMIT_KEY.getKey() + &quot;_&quot; + userId;
        String limitNum = stringRedisTemplate.opsForValue().get(limitKey);
        if (limitNum == null) {
            LOGGER.error(&quot;该用户没有访问申请验证值记录，疑似异常&quot;);
            return true;
        }
        return Integer.parseInt(limitNum) &gt; ALLOW_COUNT;
    }
</code></pre>
<h5 id="能否不用redismemcached实现用户访问频率统计">能否不用Redis/Memcached实现用户访问频率统计</h5>
<p>如果你说你不愿意用redis，有什么办法能够实现访问频率统计吗，有呀，如果你放弃分布式的部署服务，那么你可以在内存中存储访问次数，比如：</p>
<ul>
<li>Google Guava的内存缓存</li>
<li>状态模式</li>
</ul>
<h2 id="缓存与数据库双写问题的争议">缓存与数据库双写问题的争议</h2>
<h3 id="缓存热点数据">缓存热点数据</h3>
<p>在秒杀实际的业务中，一定有很多需要做缓存的场景，比如售卖的商品，包括名称，详情等。访问量很大的数据，可以算是“热点”数据了，尤其是一些读取量远大于写入量的数据，更应该被缓存，而不应该让请求打到数据库上。</p>
<p>缓存量大但又不常变化的数据，比如详情，评论等。对于那些经常变化的数据，其实并不适合缓存，一方面会增加系统的复杂性（缓存的更新，缓存脏数据），另一方面也给系统带来一定的不稳定性（缓存系统的维护）。</p>
<p>「但一些极端情况下，你需要将一些会变动的数据进行缓存，比如想要页面显示准实时的库存数，或者其他一些特殊业务场景。这时候你需要保证缓存不能（一直）有脏数据。</p>
<p>上缓存的优点：</p>
<ul>
<li>能够缩短服务的响应时间，给用户带来更好的体验。</li>
<li>能够增大系统的吞吐量，依然能够提升用户体验。</li>
<li>减轻数据库的压力，防止高峰期数据库被压垮，导致整个线上服务BOOM！</li>
</ul>
<p>上了缓存，也会引入很多额外的问题：</p>
<ul>
<li>缓存有多种选型，是内存缓存，memcached还是redis，你是否都熟悉，如果不熟悉，无疑增加了维护的难度（本来是个纯洁的数据库系统）。</li>
<li>缓存系统也要考虑分布式，比如redis的分布式缓存还会有很多坑，无疑增加了系统的复杂性。</li>
<li>在特殊场景下，如果对缓存的准确性有非常高的要求，就必须考虑「缓存和数据库的一致性问题」。</li>
</ul>
<h3 id="缓存和数据库双写一致性">缓存和数据库双写一致性</h3>
<h5 id="不使用更新缓存而是删除缓存">不使用更新缓存而是删除缓存</h5>
<p>原因一：线程安全角度<br>
同时有请求A和请求B进行更新操作，那么会出现</p>
<p>（1）线程A更新了数据库<br>
（2）线程B更新了数据库<br>
（3）线程B更新了缓存<br>
（4）线程A更新了缓存</p>
<p>这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。</p>
<p>原因二：业务场景角度<br>
有如下两点：</p>
<p>（1）如果你是一个写数据库场景比较多，而读数据场景比较少的业务需求，采用这种方案就会导致，数据压根还没读到，缓存就被频繁的更新，浪费性能。<br>
（2）如果你写入数据库的值，并不是直接写入缓存的，而是要经过一系列复杂的计算再写入缓存。那么，每次写入数据库后，都再次计算写入缓存的值，无疑是浪费性能的。显然，删除缓存更为适合。</p>
<blockquote>
<p>其实如果业务非常简单，只是去数据库拿一个值，写入缓存，那么更新缓存也是可以的。但是，淘汰缓存操作简单，并且带来的副作用只是增加了一次cache miss，建议作为通用的处理方式。</p>
</blockquote>
<h5 id="先删除缓存还是先操作数据库">先删除缓存，还是先操作数据库?</h5>
<p>对于一个不能保证事务性的操作，一定涉及“哪个任务先做，哪个任务后做”的问题，解决这个问题的方向是：如果出现不一致，谁先做对业务的影响较小，就谁先执行。</p>
<p>假设先淘汰缓存，再写数据库：第一步淘汰缓存成功，第二步写数据库失败，则只会引发一次Cache miss。</p>
<p>假设先写数据库，再淘汰缓存：第一步写数据库操作成功，第二步淘汰缓存失败，则会出现DB中是新数据，Cache中是旧数据，数据不一致。</p>
<p>假如先删缓存，再更新数据库，该方案会导致请求数据不一致，比如同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:</p>
<p>（1）请求A进行写操作，删除缓存<br>
（2）请求B查询发现缓存不存在<br>
（3）请求B去数据库查询得到旧值<br>
（4）请求B将旧值写入缓存<br>
（5）请求A将新值写入数据库</p>
<p>上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。</p>
<p><mark>所以先删缓存，再更新数据库并不是一劳永逸的解决方案，再看看先更新数据库，再删缓存</mark></p>
<p>先更新数据库，再删缓存这种情况不存在并发问题么？不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生</p>
<p>（1）缓存刚好失效<br>
（2）请求A查询数据库，得一个旧值<br>
（3）请求B将新值写入数据库<br>
（4）请求B删除缓存<br>
（5）请求A将查到的旧值写入缓存</p>
<p>如果发生上述情况，确实是会发生脏数据。然而，发生这种情况的概率又有多少呢？发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。</p>
<p>所以，如果你想实现基础的缓存数据库双写一致的逻辑，那么在大多数情况下，在不想做过多设计，增加太大工作量的情况下，请<mark>先更新数据库，再删缓存</mark>!</p>
<h3 id="我一定要数据库和缓存数据一致怎么办">我一定要数据库和缓存数据一致怎么办</h3>
<p><mark>没有办法做到绝对的一致性，这是由CAP理论决定的，缓存系统适用的场景就是非强一致性的场景，所以它属于CAP中的AP</mark></p>
<p>所以，我们得委曲求全，可以去做到BASE理论中说的<code>「最终一致性」</code>。</p>
<blockquote>
<p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性</p>
</blockquote>
<h5 id="延时双删">延时双删</h5>
<p>上文我们提到，在先删除缓存，再更新数据库的情况下，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。那么延时双删怎么解决这个问题呢？</p>
<p>（1）先淘汰缓存<br>
（2）再写数据库（这两步和原来一样）<br>
（3）休眠1秒，再次淘汰缓存</p>
<p>这么做，可以将1秒内所造成的缓存脏数据，再次删除。</p>
<blockquote>
<p>针对上面的情形，读者应该自行评估自己的项目的读数据业务逻辑的耗时。然后写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。</p>
</blockquote>
<p>如果你用了mysql的读写分离架构怎么办？在这种情况下，造成数据不一致的原因如下，还是两个请求，一个请求A进行更新操作，另一个请求B进行查询操作。</p>
<p>（1）请求A进行写操作，删除缓存<br>
（2）请求A将数据写入数据库了，<br>
（3）请求B查询缓存发现，缓存没有值<br>
（4）请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值<br>
（5）请求B将旧值写入缓存<br>
（6）数据库完成主从同步，从库变为新值</p>
<p>上述情形，就是数据不一致的原因。还是使用双删延时策略。只是，睡眠时间修改为在主从同步的延时时间基础上，加几百ms。</p>
<p>采用这种同步淘汰策略，吞吐量降低怎么办？那就将第二次删除作为<code>异步</code>的。自己起一个线程，异步删除。这样，写的请求就不用沉睡一段时间后了，再返回。这么做，加大吞吐量。</p>
<p>所以在先删除缓存，再更新数据库的情况下，可以使用延时双删的策略，来保证脏数据只会存活一段时间，就会被准确的数据覆盖。</p>
<p>在先更新数据库，再删缓存的情况下，缓存出现脏数据的情况虽然可能性极小，但也会出现。我们依然可以用延时双删策略，在请求A对缓存写入了脏的旧值之后，再次删除缓存。来保证去掉脏缓存。</p>
<h5 id="删缓存失败了怎么办重试机制">删缓存失败了怎么办：重试机制</h5>
<p>看似问题都已经解决了，但其实，还有一个问题没有考虑到，那就是删除缓存的操作，失败了怎么办？比如延时双删的时候，第二次缓存删除失败了，那不还是没有清除脏数据吗？</p>
<p>方案一：<br>
（1）更新数据库数据；<br>
（2）缓存因为种种问题删除失败<br>
（3）将需要删除的key发送至消息队列<br>
（4）自己消费消息，获得需要删除的key<br>
（5）继续重试删除操作，直到成功</p>
<p>然而，该方案有一个缺点，对业务线代码造成大量的侵入。</p>
<p>方案二：<br>
（1）更新数据库数据<br>
（2）数据库会将操作信息写入binlog日志当中（而读取binlog的中间件，可以采用阿里开源的canal）<br>
（3）订阅程序提取出所需要的数据以及key<br>
（4）另起一段非业务代码，获得该信息<br>
（5）尝试删除缓存操作，发现删除失败<br>
（6）将这些信息发送至消息队列<br>
（7）重新从消息队列中获得该数据，重试操作。</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU1NTA0NTEwMg==&amp;mid=2247484200&amp;idx=1&amp;sn=6b6c7251ee83fe8ef9201373aafcffdd&amp;chksm=fbdb1aa9ccac93bfe26655f89056b0d25b3a536f6b11148878fe96ffdf1d8349d44659cad784&amp;token=841068032&amp;lang=zh_CN#rd">🔗参考文档</a></p>
<h2 id="如何优雅的实现订单异步处理">如何优雅的实现订单异步处理</h2>
<h3 id="简单的订单异步处理实现">简单的订单异步处理实现</h3>
<p>在秒杀系统用户进行抢购的过程中，由于在同一时间会有大量请求涌入服务器，如果每个请求都立即访问数据库进行扣减库存+写入订单的操作，对数据库的压力是巨大的。</p>
<p>如何减轻数据库的压力呢，我们将每一条秒杀的请求存入消息队列（例如RabbitMQ）中，放入消息队列后，给用户返回类似“抢购请求发送成功”的结果。而在消息队列中，我们将收到的下订单请求一个个的写入数据库中，比起多线程同步修改数据库的操作，大大缓解了数据库的连接压力，最主要的好处就表现在数据库连接的减少：</p>
<ul>
<li>同步方式：大量请求快速占满数据库框架开启的数据库连接池，同时修改数据库，导致数据库读写性能骤减。</li>
<li>异步方式：一条条消息以顺序的方式写入数据库，连接数几乎不变（当然，也取决于消息队列消费者的数量</li>
</ul>
<p>这种实现可以理解为是一中流量削峰：让数据库按照他的处理能力，从消息队列中拿取消息进行处理。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1684477287392.png" alt="" loading="lazy"></figure>
<p>我们在源码仓库里，新增一个controller对外接口：</p>
<pre><code class="language-java">/**
 * 下单接口：异步处理订单
 * @param sid
 * @return
 */
@RequestMapping(value = &quot;/createUserOrderWithMq&quot;, method = {RequestMethod.GET})
@ResponseBody
public String createUserOrderWithMq(@RequestParam(value = &quot;sid&quot;) Integer sid,
                              @RequestParam(value = &quot;userId&quot;) Integer userId) {
    try {
        // 检查缓存中该用户是否已经下单过
        Boolean hasOrder = orderService.checkUserOrderInfoInCache(sid, userId);
        if (hasOrder != null &amp;&amp; hasOrder) {
            LOGGER.info(&quot;该用户已经抢购过&quot;);
            return &quot;你已经抢购过了，不要太贪心.....&quot;;
        }
        // 没有下单过，检查缓存中商品是否还有库存
        LOGGER.info(&quot;没有抢购过，检查缓存中商品是否还有库存&quot;);
        Integer count = stockService.getStockCount(sid);
        if (count == 0) {
            return &quot;秒杀请求失败，库存不足.....&quot;;
        }

        // 有库存，则将用户id和商品id封装为消息体传给消息队列处理
        // 注意这里的有库存和已经下单都是缓存中的结论，存在不可靠性，在消息队列中会查表再次验证
        LOGGER.info(&quot;有库存：[{}]&quot;, count);
        JSONObject jsonObject = new JSONObject();
        jsonObject.put(&quot;sid&quot;, sid);
        jsonObject.put(&quot;userId&quot;, userId);
        sendToOrderQueue(jsonObject.toJSONString());
        return &quot;秒杀请求提交成功&quot;;
    } catch (Exception e) {
        LOGGER.error(&quot;下单接口：异步处理订单异常：&quot;, e);
        return &quot;秒杀请求失败，服务器正忙.....&quot;;
    }
}
</code></pre>
<p>createUserOrderWithMq接口整体流程如下：</p>
<ul>
<li>检查缓存中该用户是否已经下单过：在消息队列下单成功后写入redis一条用户id和商品id绑定的数据</li>
<li>没有下单过，检查缓存中商品是否还有库存</li>
<li>缓存中如果有库存，则将用户id和商品id封装为消息体「传给消息队列处理」</li>
</ul>
<p>注意：这里的「有库存和已经下单」都是缓存中的结论，存在不可靠性，在消息队列中会查表再次验证，「作为兜底逻辑」</p>
<p>消息队列是如何接收消息的呢？我们新建一个消息队列，采用第四篇文中使用过的RabbitMQ，我再稍微贴一下整个创建RabbitMQ的流程把</p>
<pre><code class="language-java">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<pre><code class="language-java">@Configuration
public class RabbitMqConfig {

    @Bean
    public Queue orderQueue() {
        return new Queue(&quot;orderQueue&quot;);
    }

}
</code></pre>
<p>添加一个消费者：</p>
<pre><code class="language-java">@Component
@RabbitListener(queues = &quot;orderQueue&quot;)
public class OrderMqReceiver {

    private static final Logger LOGGER = LoggerFactory.getLogger(OrderMqReceiver.class);

    @Autowired
    private StockService stockService;

    @Autowired
    private OrderService orderService;

    @RabbitHandler
    public void process(String message) {
        LOGGER.info(&quot;OrderMqReceiver收到消息开始用户下单流程: &quot; + message);
        JSONObject jsonObject = JSONObject.parseObject(message);
        try {
            orderService.createOrderByMq(jsonObject.getInteger(&quot;sid&quot;),jsonObject.getInteger(&quot;userId&quot;));
        } catch (Exception e) {
            LOGGER.error(&quot;消息处理异常：&quot;, e);
        }
    }
}
</code></pre>
<p>真正的下单的操作，在service中完成，我们在orderService中新建createOrderByMq方法：</p>
<pre><code class="language-java">@Override
public void createOrderByMq(Integer sid, Integer userId) throws Exception {

    Stock stock;
    //校验库存（不要学我在trycatch中做逻辑处理，这样是不优雅的。这里这样处理是为了兼容之前的秒杀系统文章）
    try {
        stock = checkStock(sid);
    } catch (Exception e) {
        LOGGER.info(&quot;库存不足！&quot;);
        return;
    }
    //乐观锁更新库存
    boolean updateStock = saleStockOptimistic(stock);
    if (!updateStock) {
        LOGGER.warn(&quot;扣减库存失败，库存已经为0&quot;);
        return;
    }

    LOGGER.info(&quot;扣减库存成功，剩余库存：[{}]&quot;, stock.getCount() - stock.getSale() - 1);
    stockService.delStockCountCache(sid);
    LOGGER.info(&quot;删除库存缓存&quot;);

    //创建订单
    LOGGER.info(&quot;写入订单至数据库&quot;);
    createOrderWithUserInfoInDB(stock, userId);
    LOGGER.info(&quot;写入订单至缓存供查询&quot;);
    createOrderWithUserInfoInCache(stock, userId);
    LOGGER.info(&quot;下单完成&quot;);

}
</code></pre>
<p>真正的下单的操作流程为：</p>
<ul>
<li>校验数据库库存</li>
<li>乐观锁更新库存（其他之前讲到的锁也可以啦）</li>
<li>写入订单至数据库</li>
<li>「写入订单和用户信息至缓存供查询」：写入后，在外层接口便可以通过判断redis中是否存在用户和商品的抢购信息，来直接给用户返回“你已经抢购过”的消息。</li>
</ul>
<p>我是如何在redis中记录商品和用户的关系的呢，我使用了set集合，key是商品id，而value则是用户id的集合，当然这样有一些不合理之处：</p>
<ul>
<li>这种结构默认了一个用户只能抢购一次这个商品</li>
<li>使用set集合，在用户过多后，每次检查需要遍历set，用户过多有性能问题</li>
</ul>
<pre><code class="language-java">@Override
    public Boolean checkUserOrderInfoInCache(Integer sid, Integer userId) throws Exception {
        String key = CacheKey.USER_HAS_ORDER.getKey() + &quot;_&quot; + sid;
        LOGGER.info(&quot;检查用户Id：[{}] 是否抢购过商品Id：[{}] 检查Key：[{}]&quot;, userId, sid, key);
        return stringRedisTemplate.opsForSet().isMember(key, userId.toString());
    }
</code></pre>
<h3 id="更加优雅的实现">更加优雅的实现</h3>
<p>我们实现了上面的异步处理后，用户那边得到的结果是怎么样的呢？</p>
<p>用户点击了提交订单，收到了消息：您的订单已经提交成功。然后用户啥也没看见，也没有订单号，用户开始慌了，点到了自己的个人中心——已付款。发现居然没有订单！（因为可能还在队列中处理）</p>
<p>这样的话，用户可能马上就要开始投诉了！太不人性化了，我们不能只为了开发方便，舍弃了用户体验！</p>
<p>所以我们要改进一下，如何改进呢？其实很简单：</p>
<ul>
<li>让前端在提交订单后，显示一个“排队中”</li>
<li>同时，前端不断请求 检查用户和商品是否已经有订单 的接口，如果得到订单已经处理完成的消息，页面跳转抢购成功。</li>
</ul>
<pre><code class="language-java">/**
 * 检查缓存中用户是否已经生成订单
 * @param sid
 * @return
 */
@RequestMapping(value = &quot;/checkOrderByUserIdInCache&quot;, method = {RequestMethod.GET})
@ResponseBody
public String checkOrderByUserIdInCache(@RequestParam(value = &quot;sid&quot;) Integer sid,
                              @RequestParam(value = &quot;userId&quot;) Integer userId) {
    // 检查缓存中该用户是否已经下单过
    try {
        Boolean hasOrder = orderService.checkUserOrderInfoInCache(sid, userId);
        if (hasOrder != null &amp;&amp; hasOrder) {
            return &quot;恭喜您，已经抢购成功！&quot;;
        }
    } catch (Exception e) {
        LOGGER.error(&quot;检查订单异常：&quot;, e);
    }
    return &quot;很抱歉，你的订单尚未生成，继续排队吧您嘞。&quot;;
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《Neo4j权威指南》一]]></title>
        <id>https://q456qq520.github.io/post/lesslessneo4j-quan-wei-zhi-nan-greatergreater-yi/</id>
        <link href="https://q456qq520.github.io/post/lesslessneo4j-quan-wei-zhi-nan-greatergreater-yi/">
        </link>
        <updated>2023-05-11T01:35:33.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="一-图数据库基础">一 图数据库基础</h2>
<h3 id="11-图数据模型">1.1 图数据模型</h3>
]]></summary>
        <content type="html"><![CDATA[<h2 id="一-图数据库基础">一 图数据库基础</h2>
<h3 id="11-图数据模型">1.1 图数据模型</h3>
<!-- more -->
<p>图数据要具体存储到图数据库中，最终落实为具体的数据文件，自然就涉及特定的图数据模型，即如何存，采用什么实现方式来存。常用的有三种：==属性图、超图和三元图。</p>
<p>其中Neo4j就采用属性图模型，因为属性图直观更易于理解，能描述大部分图使用场景。符合下列特征的图数据模型就称为属性图。</p>
<ul>
<li>它包含节点和关系</li>
<li>节点可以有属性（键值对）</li>
<li>节点可以有一个或多个标签</li>
<li>关系有名字和方向，并总是有一个开始节点和一个结束节点。</li>
<li>关系也可以有属性</li>
</ul>
<p>超图是一种更为广义对图模型，在超图中，一个关系（称作超边）可以关联任意数量的节点，无论是开始节点端还是结束节点端，而属性图中一个关系只允许一个开始节点和一个结束节点。因此，超图更适用表示多对多关系。</p>
<h3 id="12-图计算引擎">1.2 图计算引擎</h3>
<p>图数据库的核心也是构建在一个一起闹智商的，那就是图计算引擎，是能够组织存储大型图数据集并且实现了全局图计算算法的一种数据库核心构建。</p>
<p>它包含一个具有联机事务处理过程的数据库记录系统，图计算引擎用于响应用户终端允许时发来的查询请求，周期性从记录系统中进行数据抽取、转换和家在，然后将数据从记录数据系统读入到图计算引擎并进行离线查询和分析，最好将查询、分析的结果返回给用户终端。</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1683787705759.png" alt="" loading="lazy"></figure>
<p>目前较为流程的图计算引擎有两种：单机图计算引擎和分布式图计算引擎。</p>
<h3 id="13-neo4j概述">1.3 Neo4j概述</h3>
<p>Neo4j是由Java实现的开源的NoSQL图数据库。</p>
<h3 id="14-neo4j底层存储结构">1.4 Neo4j底层存储结构</h3>
<p>免索引邻接是图数据库实现高效遍历的关键，那么免索引邻接的实现机制就是Neo4j底层存储结构设计的关键。能够支持高效的，本地化的图存储以及任意图算法的快速遍历，是使用图数据库的重要原因。</p>
<p>从宏观角度来说，Neo4j中仅仅只有两种数据类型：</p>
<ol>
<li>节点（Node）：节点类似E-R图中的实体，每一个实体可以有0个或多个属性，这些属性以key-value对的形式存在，属性没有特殊的类别要求，同时每个节点还具有相应的标签（Label），用来区分不同类型的节点。</li>
<li>关系（Relationship）：关系也类似与E-R图中的关系。一个挂你想有起始节点和终止节点。关系也有自己的属性和标签。</li>
</ol>
<p><img src="https://q456qq520.github.io/post-images/1683792894779.png" alt="" loading="lazy"><br>
节点和关系分别采用固定长度存储，节点存储文件用来存储节点的记录，文件名叫<code>neostore.nodestore.db</code>。节点记录的长度为固定大小，每个节点记录的长度为9字节。格式为：<code>Node:inUse+nextRelId+nextPropId</code>。</p>
<ul>
<li>inUse：1表示该节点被正常使用，0表示该节点被删除。</li>
<li>nextRelId：该节点的下一个关系ID</li>
<li>nextPropId：该节点的下一个属性ID</li>
</ul>
<p>如果有一个ID为100的节点，就能直接计算出该记录在存储文件中的第900个字节。成本仅为O(1)。</p>
<p>关系存储文件用来存储关系的记录，文件名为<code>neostore.relationshipstore.db</code>。像节点的存储一样，关系存储区的记录大小也是固定的，格式为<code>Relationshipstore:inUse+firstNode+secondNode+relType+firstPrevRelId+firstNextRelId+secondPrevRelId+secondNextRelId+nextPropId</code>。</p>
<ul>
<li>inUse，nextPropId：作用同上</li>
<li>firstNode：当前关系的起始节点</li>
<li>secondNode：当前关系的终止节点</li>
<li>relType：关系的类型</li>
<li>firstPrevRelId &amp; firstNextRelId：起始节点的前一个和后一个关系的ID</li>
<li>secondPrevRelId &amp; secondNextRelId+nextPropId：终止节点的前一个和后一个关系的ID</li>
</ul>
<p>Neo4j中有一个<code>.id</code>文件用来保持对未使用记录对跟踪，用来回收未使用的空间。节点和关系的存储文件只关系图的基本存储结构而不是属性数据。这两种记录都使用固定大小的记录，以便存储文件内的任何记录都可以根据ID快速的计算出来。</p>
<p>下图是Neo4j中其他常见的基本存储类型，属性记录的物理存储放置在<code>neostore.propertystore.db</code>文件中。与节点和关系的存储记录一样，属性的存储记录也是固定长度。每个属性记录包含4个属性块和属性链中下一个属性的ID。属性链是单向链表，而关系链是双向链表。一个属性记录中可以包含任何JVM支持的基本数据类型、字符串、基于类型的数组以及属性索引文件（<code>neostore.propertystore.db.index</code>）。属性索引文件主要用于存储属性的名称，属性索引的值部分存储的是指向动态内存的记录或者内联值，短字符串和短数组会直接内联在属性存储记录中。当长度超过属性记录中的propBlock长度限制之后，会单独存储在其他的动态存储文件中。</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1683795844065.png" alt="" loading="lazy"></figure>
<p>Neo4j中两种动态存储：动态字符串存储（<code>neostore.propertystore.db.strings</code>）和动态数组存储（<code>neostore.propertystore.db.arrays</code>）。动态存储记录是可以扩展的，如果一个属性长到一条动态存储记录仍然无法完全容纳时，可以申请多个动态存储记录逻辑上进行连接。</p>
<h3 id="15-neo4j的遍历方式">1.5 Neo4j的遍历方式</h3>
<p>每个节点记录都包含一个指向该节点的第一个属性的指针和联系链中第一个联系的指针。要读取一个节点的属性，从指向第一个属性的指针开始，遍历整个单向链表的结构。要找到一个节点的关系，从指向的第一个关系开始，遍历整个双向链表，知道找到。一单找到我们就可以与使用和超找节点属性一样的方法查找关系的属性。我们也可以很方便的获取起始节点和结束节点的ID，利用节点ID就可以立即得到每个节点在节点存储文件中的具体位置，时间复杂度为O(1)。</p>
<p>下面通过一个例子来讲解遍历关系和节点的详细过程，假如在Neo4j中纯粹来ABCDE5个节点和R1、R2、R3、R4、R5、R6、R7 7个关系，它们之间的关系如下图所示。<br>
<img src="https://q456qq520.github.io/post-images/1683859055787.png" alt="" loading="lazy"><br>
假如要遍历图中节点B的所有关系，只需要向<code>NODEB-NEXT</code>方向遍历，直到指向NULL为止。如下图所示，可以看出即节点B的所有关系为R1、R3、R4、R5。<br>
<img src="https://q456qq520.github.io/post-images/1683859485562.png" alt="" loading="lazy"></p>
<p>通过固定大小的存储记录和指针ID，只要跟随指针就可以简单的实现遍历并且告诉指向。要遍历一个节点到另一个节点的特定关系，在Neo4j中只需要遍历几个指针。</p>
<ul>
<li>从一个给定节点定位关系链中第一个关系的位置，可以通过计算它在关系存储的偏移量来获得。跟获得节点存储位置的方法一样，使用关系ID乘以关系记录的固定大小即可找到关系在存储文件中的正确位置。</li>
<li>在关系记录中，搜索第二个字段可以找到第二个节点的ID，用节点记录大小乘以节点ID可以得到节点在存储中的正确位置。</li>
</ul>
<h3 id="16-neo4j的存储优化">1.6 Neo4j的存储优化</h3>
<p>Neo4j支持存储优化（压缩和内联存储属性值），对于某些段字符的属性可以直接存储在属性文件中，而不是单独的放到另一个动态存储区，这样可以减少I/O操作并增加吞吐量。</p>
<p>Neo4j还可以对属性名称的空间严格维护。属性名称都通过属性索引文件从属性存储中间接引用。属性索引允许所有具有想用名称的属性共享单个记录，因而可以节省相当大的空间和I/O开销。</p>
<p>Neo4j采用缓存策略，保证那些经常访问的数据可以快速地被多次重复访问。Neo4j高速缓存的页面置换算法是基于最不经常使用的页置换（LFU）缓存策略，即使有些页面近期没有使用过，但是因为以前的使用频率很高，那么在短期之内它页不会被淘汰。</p>
<h2 id="二-neo4j-基础入门">二 Neo4j 基础入门</h2>
<h3 id="21-安装部署">2.1 安装部署</h3>
<p>步骤一：安装对应版本JDK<br>
步骤二：<a href="https://neo4j.com/" title="🔗官网下载">🔗官网下载</a></p>
<p>初始用户名、密码均为neo4j，安装好后，具体文件目录如下：<br>
<img src="https://q456qq520.github.io/post-images/1683871781471.png" alt="" loading="lazy"></p>
<p>其中bin目录为运行目录，下面为启动关闭命令：</p>
<pre><code class="language-shell">./neo4j  start

./neo4j stop
</code></pre>
<p>启动完毕后，本地访问地址默认为：http://localhost:7474/browser/</p>
<h3 id="22-neo4j-中基本元素与概念">2.2 Neo4j 中基本元素与概念</h3>
<h4 id="221-节点">2.2.1 节点</h4>
<p>节点（Node）是图数据库中的一个基本元素，用以表示一个实体记录，就像关系数据库中的一条记录一样。在Neo4j中节点可以包含多个属性和多个标签。</p>
<h4 id="222-关系">2.2.2 关系</h4>
<p>关系（Relationship）是图数据库中的一个基本元素。当数据库汇中已经存在节点后，需要将节点连接起来构成图。关系就是用来连接两个节点，也称为图论的边（Edge），其始端和末端都必须是节点，关系不能指向空也不能从空发起。关系和节点一样可以包含多个属性，但是关系只能有一个类型（Type）。</p>
<p>关系必须有开始节点和结束节点。两头都不能为空。节点可以被关系串联或并联起来，由于关系是有方向的，所以可以在由节点、关系组成的图中进行遍历操作。</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1683873968406.png" alt="" loading="lazy"></figure>
<p>在图的遍历操作中我们可以指定关系遍历的方向或者指定为无方向，因此在创建关系时不必为两个节点创建相互指向的关系，而是在遍历时不指定遍历方向即可。特别注意一个节点可以存在指向自己的关系。</p>
<h4 id="223-属性">2.2.3 属性</h4>
<p>属性是由键值对组成的，就像hash表一样，属性名类似变量名，属性值类似变量值。属性值可以是基本的数据类型，或者由基本数据类型组成的数组。</p>
<p><mark>属性值没有null的概念</mark>，如果一个属性不需要了可以直接将整个键值对都移除，在查询时，可以用<code>IS NULL</code>关键字判断属性是否存在。</p>
<table>
<thead>
<tr>
<th>类型</th>
<th style="text-align:center">说明</th>
<th style="text-align:right">取值范围</th>
</tr>
</thead>
<tbody>
<tr>
<td>boolean</td>
<td style="text-align:center">布尔值</td>
<td style="text-align:right">true/false</td>
</tr>
<tr>
<td>btye</td>
<td style="text-align:center">8位的整数</td>
<td style="text-align:right">-128～127，inclusive</td>
</tr>
<tr>
<td>short</td>
<td style="text-align:center">16位的整数</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>int</td>
<td style="text-align:center">32位的整数</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>long</td>
<td style="text-align:center">64位的整数</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>float</td>
<td style="text-align:center">32位的浮点数</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>double</td>
<td style="text-align:center">64位的浮点数</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>char</td>
<td style="text-align:center">16位的无符号整数代表的字符</td>
<td style="text-align:right"></td>
</tr>
<tr>
<td>string</td>
<td style="text-align:center">Unicode字符序列</td>
<td style="text-align:right"></td>
</tr>
</tbody>
</table>
<h4 id="224-路径">2.2.4 路径</h4>
<p>当使用节点和关系创建了一个图后，在此图中任意两个节点间都说可能存在路径的。路径也有长度的概念，也就是路径中关系的条数，单独一个节点也可以组成长度为0的路径。</p>
<h4 id="225-遍历traversal">2.2.5 遍历（Traversal）</h4>
<p>遍历的规则可以是广度优先。也可以是深度优先。</p>
<h3 id="23-官方实例入门">2.3 官方实例入门</h3>
<h4 id="231-创建图数据">2.3.1 创建图数据</h4>
<p>首先创建一个电影节点，节点上有三个属性，分别代表电影标题、发布时间、宣传词。</p>
<pre><code class="language-sql">CREATE (TheMatrix:Movie {title:'The Matrix', released:1999, tagline:'Welcome to the Real World'})
</code></pre>
<p>再创建人物节点，节点有两个属性，名字和出生日期。</p>
<pre><code class="language-sql">CREATE (Keanu:Person {name:'Keanu Reeves', born:1964})
CREATE (Carrie:Person {name:'Carrie-Anne Moss', born:1967})
CREATE (Laurence:Person {name:'Laurence Fishburne', born:1961})
CREATE (Hugo:Person {name:'Hugo Weaving', born:1960})
CREATE (LillyW:Person {name:'Lilly Wachowski', born:1967})
CREATE (LanaW:Person {name:'Lana Wachowski', born:1965})
CREATE (JoelS:Person {name:'Joel Silver', born:1952})
</code></pre>
<p>然后创建演员、导演关系。</p>
<pre><code class="language-sql">  CREATE
      (Keanu)-[:ACTED_IN {roles:['Neo']}]-&gt;(TheMatrix),
      (Carrie)-[:ACTED_IN {roles:['Trinity']}]-&gt;(TheMatrix),
      (Laurence)-[:ACTED_IN {roles:['Morpheus']}]-&gt;(TheMatrix),
      (Hugo)-[:ACTED_IN {roles:['Agent Smith']}]-&gt;(TheMatrix),
      (LillyW)-[:DIRECTED]-&gt;(TheMatrix),
      (LanaW)-[:DIRECTED]-&gt;(TheMatrix),
      (JoelS)-[:PRODUCED]-&gt;(TheMatrix)
</code></pre>
<p>其中使用到了箭头运算符，如：(Keanu)-[:ACTED_IN {roles:['Neo']}]-&gt;(TheMatrix)，代表创建一个演员参演电影的关系，演员Keanu以角色roles:['Neo']参演ACTED_IN到电影中。  (LillyW)-[:DIRECTED]-&gt;(TheMatrix)表示导演与电影的关系。执行完毕后可以看到如下所示：<br>
<img src="https://q456qq520.github.io/post-images/1683883351323.png" alt="" loading="lazy"></p>
<h4 id="231-检索节点">2.3.1 检索节点</h4>
<h5 id="查找人员">查找人员</h5>
<ol>
<li>
<p>查找名为Tom Hanks的人物<br>
MATCH (tom {name:&quot;Tom Hanks&quot;}) RETURN tom</p>
</li>
<li>
<p>查找名为Cloud Atlas的电影<br>
MATCH (cloudAtlas {name:&quot;Cloud Atlas&quot;}) RETURN tom</p>
</li>
<li>
<p>随机查找10个人物的人名<br>
MATCH (people:Person) RETURN people.name LIMIT 10</p>
</li>
<li>
<p>查找多个电影，1990-2000发行的电影的名称<br>
MATCH (nineties:Movie) WHERE nineties.released &gt; 1990 AND nineties.released &lt; 2000 RETURN nineties.title</p>
</li>
</ol>
<h4 id="232-查询关系">2.3.2 查询关系</h4>
<ol>
<li>
<p>查找Tom Hanks参演过的电影的名称<br>
MATCH (tom:Person {name:&quot;Tom Hanks&quot;}) - [:ACTED_IN] -&gt; (tomHanksMovies) RETURN tom,tomHanksMovies</p>
</li>
<li>
<p>查询谁导演了电影“Cloud Atlas”<br>
MATCH (cloudAtlas {title:&quot;Cloud Atlas&quot;}) &lt;- [:DIRECTED] - (directors) RETURN directors.name<br>
首先匹配属性{title:&quot;Cloud Atlas&quot;}的节点，然后匹配此节点具有关系 [:DIRECTED] 并且是被某节点指向的节点，再返回name属性。</p>
</li>
<li>
<p>查找与Tom Hanks同出演过电影的人<br>
MATCH (tom:Person {name:&quot;Tom Hanks&quot;}) - [:ACTED_IN] -&gt; (tomHanksMovies) &lt;- [:ACTED_IN] - (coActors) RETURN coActors.name<br>
首先匹配节点类型为Person，属性为tom hanks的节点，然后匹配此节点通过 [:ACTED_IN] 关系指向的节点，并且同时匹配该节点的 [:ACTED_IN] 关系节点。</p>
</li>
<li>
<p>查询与电影“Cloud Atlas”相关的所有人<br>
MATCH (people:Person) - [relatedTo] - (:Movie {title: &quot;Cloud Atlas&quot;}) RETURN people.name, Type(relatedTo),relatedTo<br>
首先匹配节点类型为Person的节点，然后匹配节点类型为Movie、节点属性为{title: &quot;Cloud Atlas&quot;}的节点，最好匹配他们两者之间存在某种关系，最后返回。</p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[基于代价的慢查询优化建议]]></title>
        <id>https://q456qq520.github.io/post/ji-yu-dai-jie-de-man-cha-xun-you-hua-jian-yi/</id>
        <link href="https://q456qq520.github.io/post/ji-yu-dai-jie-de-man-cha-xun-you-hua-jian-yi/">
        </link>
        <updated>2023-04-21T07:13:41.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-背景">1 背景</h2>
<p>慢查询是指数据库中查询时间超过指定阈值的SQL，它是数据库的性能杀手，也是业务优化数据库访问的重要抓手。随着美团业务的高速增长，日均慢查询量已经过亿条，此前因慢查询导致的故障约占数据库故障总数的10%以上，而且高级别的故障呈日益增长趋势。因此，对慢查询的优化已经变得刻不容缓。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-背景">1 背景</h2>
<p>慢查询是指数据库中查询时间超过指定阈值的SQL，它是数据库的性能杀手，也是业务优化数据库访问的重要抓手。随着美团业务的高速增长，日均慢查询量已经过亿条，此前因慢查询导致的故障约占数据库故障总数的10%以上，而且高级别的故障呈日益增长趋势。因此，对慢查询的优化已经变得刻不容缓。</p>
<!-- more -->
<p>那么如何优化慢查询呢？最直接有效的方法就是选用一个查询效率高的索引。关于高效率的索引推荐，主要在日常工作中，基于经验规则的推荐随处可见，对于简单的SQL，如<mark>select * from sync_test1 where name like 'Bobby%'</mark>，直接添加索引IX(name) 就可以取得不错的效果；但对于稍微复杂点的SQL，如<mark>select * from sync_test1 where name like 'Bobby%' and dt &gt; '2021-07-06'</mark>，到底选择IX(name)、IX(dt)、IX(dt,name) 还是IX(name,dt)，该方法也无法给出准确的回答。更别说像多表Join、子查询这样复杂的场景了。所以采用基于代价的推荐来解决该问题会更加普适，因为基于代价的方法使用了和数据库优化器相同的方式，去量化评估所有的可能性，选出的是执行SQL耗费代价最小的索引。</p>
<h2 id="2-基于代价的优化器介绍">2 基于代价的优化器介绍</h2>
<h3 id="21-sql执行与优化器">2.1 SQL执行与优化器</h3>
<p>一条SQL在MySQL服务器中执行流程主要包含：SQL解析、基于语法树的准备工作、优化器的逻辑变化、优化器的代价准备工作、基于代价模型的优化、进行额外的优化和运行执行计划等部分。具体如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://q456qq520.github.io/post-images/1682064829235.jpeg" alt="" loading="lazy"></figure>
<h3 id="22-代价模型介绍">2.2 代价模型介绍</h3>
<p>而对于优化器来说，执行一条SQL有各种各样的方案可供选择，如表是否用索引、选择哪个索引、是否使用范围扫描、多表Join的连接顺序和子查询的执行方式等。如何从这些可选方案中选出耗时最短的方案呢？这就需要定义一个量化数值指标，这个指标就是代价(Cost)，我们分别计算出可选方案的操作耗时，从中选出最小值。</p>
<p>代价模型将操作分为Server层和Engine（存储引擎）层两类，<mark>Server层主要是CPU代价，Engine层主要是IO代价</mark>，比如MySQL从磁盘读取一个数据页的代价io_block_read_cost为1，计算符合条件的行代价为row_evaluate_cost为0.2。除此之外还有：</p>
<ol>
<li>memory_temptable_create_cost (default 2.0) 内存临时表的创建代价。</li>
<li>memory_temptable_row_cost (default 0.2) 内存临时表的行代价。</li>
<li>key_compare_cost (default 0.1) 键比较的代价，例如排序。</li>
<li>disk_temptable_create_cost (default 40.0) 内部myisam或innodb临时表的创建代价。</li>
<li>disk_temptable_row_cost (default 1.0) 内部myisam或innodb临时表的行代价。</li>
</ol>
<p>在MySQL 5.7中，这些操作代价的默认值都可以进行配置。为了计算出方案的总代价，还需要参考一些统计数据，如表数据量大小、元数据和索引信息等。MySQL的代价优化器模型整体如下图所示：</p>
<figure data-type="image" tabindex="2"><img src="https://q456qq520.github.io/post-images/1682065265190.jpeg" alt="" loading="lazy"></figure>
<h3 id="23-基于代价的索引选择">2.3 基于代价的索引选择</h3>
<p>还是继续拿上述的SQL select * from sync_test1 where name like 'Bobby%' and dt &gt; '2021-07-06'为例，我们看看MySQL优化器是如何根据代价模型选择索引的。首先，我们直接在建表时加入四个候选索引。</p>
<pre><code class="language-mysql">Create Table: CREATE TABLE `sync_test1` (
    `id` int(11) NOT NULL AUTO_INCREMENT,
    `cid` int(11) NOT NULL,
    `phone` int(11) NOT NULL,
    `name` varchar(10) NOT NULL,
    `address` varchar(255) DEFAULT NULL,
    `dt` datetime DEFAULT NULL,
    PRIMARY KEY (`id`),
    KEY `IX_name` (`name`),
    KEY `IX_dt` (`dt`),
    KEY `IX_dt_name` (`dt`,`name`),
    KEY `IX_name_dt` (`name`,`dt`)
    ) ENGINE=InnoDB
</code></pre>
<p>通过执行explain看出MySQL最终选择了IX_name索引。</p>
<pre><code class="language-mysql">mysql&gt; explain  select * from sync_test1 where name like 'Bobby%' and dt &gt; '2021-07-06';
+----+-------------+------------+------------+-------+-------------------------------------+---------+---------+------+------+----------+------------------------------------+
| id | select_type | table      | partitions | type  | possible_keys                       | key     | key_len | ref  | rows | filtered | Extra                              |
+----+-------------+------------+------------+-------+-------------------------------------+---------+---------+------+------+----------+------------------------------------+
|  1 | SIMPLE      | sync_test1 | NULL       | range | IX_name,IX_dt,IX_dt_name,IX_name_dt | IX_name | 12      | NULL |  572 |    36.83 | Using index condition; Using where |
+----+-------------+------------+------------+-------+-------------------------------------+---------+---------+------+------+----------+------------------------------------+
</code></pre>
<p>然后再打开MySQL追踪优化器Trace功能。可以看出，没有选择其他三个索引的原因均是因为在其他三个索引上使用range scan的代价均&gt;= IX_name。</p>
<pre><code class="language-mysql">mysql&gt; select * from INFORMATION_SCHEMA.OPTIMIZER_TRACE\G;
*************************** 1. row ***************************

TRACE: {
...
&quot;rows_estimation&quot;: [
{
&quot;table&quot;: &quot;`sync_test1`&quot;,
&quot;range_analysis&quot;: {
&quot;table_scan&quot;: {
  &quot;rows&quot;: 105084,
  &quot;cost&quot;: 21628
},
...
&quot;analyzing_range_alternatives&quot;: {
  &quot;range_scan_alternatives&quot;: [
    {
      &quot;index&quot;: &quot;IX_name&quot;,
      &quot;ranges&quot;: [
        &quot;Bobby\u0000\u0000\u0000\u0000\u0000 &lt;= name &lt;= Bobbyÿÿÿÿÿ&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 572,
      &quot;cost&quot;: 687.41,
      &quot;chosen&quot;: true
    },
    {
      &quot;index&quot;: &quot;IX_dt&quot;,
      &quot;ranges&quot;: [
        &quot;0x99aa0c0000 &lt; dt&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 38698,
      &quot;cost&quot;: 46439,
      &quot;chosen&quot;: false,
      &quot;cause&quot;: &quot;cost&quot;
    },
    {
      &quot;index&quot;: &quot;IX_dt_name&quot;,
      &quot;ranges&quot;: [
        &quot;0x99aa0c0000 &lt; dt&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 38292,
      &quot;cost&quot;: 45951,
      &quot;chosen&quot;: false,
      &quot;cause&quot;: &quot;cost&quot;
    },
    {
      &quot;index&quot;: &quot;IX_name_dt&quot;,
      &quot;ranges&quot;: [
        &quot;Bobby\u0000\u0000\u0000\u0000\u0000 &lt;= name &lt;= Bobbyÿÿÿÿÿ&quot;
      ],
      &quot;index_dives_for_eq_ranges&quot;: true,
      &quot;rowid_ordered&quot;: false,
      &quot;using_mrr&quot;: false,
      &quot;index_only&quot;: false,
      &quot;rows&quot;: 572,
      &quot;cost&quot;: 687.41,
      &quot;chosen&quot;: false,
      &quot;cause&quot;: &quot;cost&quot;
    }
  ],
  &quot;analyzing_roworder_intersect&quot;: {
    &quot;usable&quot;: false,
    &quot;cause&quot;: &quot;too_few_roworder_scans&quot;
  }
},
&quot;chosen_range_access_summary&quot;: {
  &quot;range_access_plan&quot;: {
    &quot;type&quot;: &quot;range_scan&quot;,
    &quot;index&quot;: &quot;IX_name&quot;,
    &quot;rows&quot;: 572,
    &quot;ranges&quot;: [
      &quot;Bobby\u0000\u0000\u0000\u0000\u0000 &lt;= name &lt;= Bobbyÿÿÿÿÿ&quot;
    ]
  },
  &quot;rows_for_plan&quot;: 572,
  &quot;cost_for_plan&quot;: 687.41,
  &quot;chosen&quot;: true
}
...
}
</code></pre>
<p>下面我们根据代价模型来推演一下代价的计算过程：</p>
<ol>
<li>走全表扫描的代价：io_cost + cpu_cost = （数据页个数 * io_block_read_cost）+ (数据行数 * row_evaluate_cost + 1.1) = （data_length / block_size + 1）+ (rows * 0.2 + 1.1) = (9977856 / 16384 + 1) + (105084 * 0.2 + 1.1) = 21627.9。</li>
<li>走二级索引IX_name的代价：io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (572 * 1 + 1) + (572*0.2 + 0.01) = 687.41。</li>
<li>走二级索引IX_dt的代价：io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (38698 * 1 + 1) + (38698*0.2 + 0.01) = 46438.61。</li>
<li>走二级索引IX_dt_name的代价: io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (38292 * 1 + 1) + (38292 * 0.2 + 0.01) = 45951.41。</li>
<li>走二级索引IX_name_dt的代价：io_cost + cpu_cost = (预估范围行数 * io_block_read_cost + 1) + (数据行数 * row_evaluate_cost + 0.01) = (572 * 1 + 1) + (572*0.2 + 0.01) = 687.41。</li>
</ol>
<p>补充说明</p>
<ol>
<li>计算结果在小数上有偏差，因为MySQL使用%g打印浮点数，小数会以最短的方式输出。</li>
<li>除“+1.1 +1”这种调节值外，Cost计算还会出现+0.01, 它是为了避免index scan和range scan出现Cost的竞争。</li>
<li>Cost计算是基于MySQL的默认参数配置，如果Cost Model参数改变，optimizer_switch的选项不同，数据分布不同都会导致最终Cost的计算结果不同。</li>
<li>data_length可查询information_schema.tables，block_size默认16K。</li>
</ol>
<h3 id="24-基于代价的索引推荐思路">2.4 基于代价的索引推荐思路</h3>
<p>如果想借助MySQL优化器给慢查询计算出最佳索引，那么需要真实地在业务表上添加所有候选索引。对于线上业务来说，直接添加索引的时间空间成本太高，是不可接受的。MySQL优化器选最佳索引用到的数据是索引元数据和统计数据，所以我们想是否可以通过给它提供候选索引的这些数据，而非真实添加索引的这种方式来实现。</p>
<p>通过深入调研MySQL的代码结构和优化器流程，我们发现是可行的：一部分存在于Server层的frm文件中，比如索引定义；另一部分存在于Engine层中，或者通过调用Engine层的接口函数来获取，比如索引中某个列的不同值个数、索引占据的页面大小等。索引相关的信息，如下图所示：</p>
<figure data-type="image" tabindex="3"><img src="https://q456qq520.github.io/post-images/1682067083614.jpeg" alt="" loading="lazy"></figure>
<p>因为MySQL本身就支持自定义存储引擎，所以索引推荐思路是构建一个支持虚假索引的存储引擎，在它上面建立包含候选索引的空表，再采集样本数据，计算出统计数据提供给优化器，让优化器选出最优索引，整个调用关系如下图所示：</p>
<figure data-type="image" tabindex="4"><img src="https://q456qq520.github.io/post-images/1682067095473.jpeg" alt="" loading="lazy"></figure>
<h2 id="3-索引推荐实现">3 索引推荐实现</h2>
<p>因为存储引擎本身并不具备对外提供服务的能力，直接在MySQL Server层修改也难以维护，所以我们将整个索引推荐系统拆分成支持虚假索引的Fakeindex存储引擎和对外提供服务的Go-Server两部分，整体架构图如下：</p>
<figure data-type="image" tabindex="5"><img src="https://q456qq520.github.io/post-images/1682067368398.jpeg" alt="" loading="lazy"></figure>
]]></content>
    </entry>
</feed>